{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "191ae575",
   "metadata": {},
   "source": [
    "# Training TopKSAE Model\n",
    "\n",
    "This notebook demonstrates how to:\n",
    "1. Load a language model and dataset\n",
    "2. Save activations from a specific layer\n",
    "3. Train a TopK Sparse Autoencoder (TopKSAE) on those activations using the new `SaeTrainer` composite class\n",
    "4. Save the trained TopKSAE model\n",
    "\n",
    "The training uses overcomplete's `train_sae` functions via the `SaeTrainer` composite class, which is automatically available on all SAE instances via `sae.trainer`.\n",
    "\n",
    "All files (trained TopKSAE model, training metadata, activations) will be saved under `store/{model_id}/` for organized, model-specific storage.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "21ea60d2efb9b766",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T20:50:54.226648Z",
     "start_time": "2025-11-10T20:50:54.197013Z"
    }
   },
   "source": [
    "# Setup and imports\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "import os\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "# Silence Hugging Face tokenizers fork/parallelism warnings\n",
    "os.environ.setdefault(\"TOKENIZERS_PARALLELISM\", \"false\")\n",
    "\n",
    "from amber.store.store import LocalStore\n",
    "from amber.adapters import TextDataset\n",
    "from amber.core.language_model import LanguageModel\n",
    "from amber.mechanistic.sae.modules.topk_sae import TopKSae, TopKSAETrainingConfig\n",
    "\n",
    "print(\"‚úÖ Imports completed\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "‚úÖ Imports completed\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "id": "8d87fd502ea77c3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T20:50:54.256425Z",
     "start_time": "2025-11-10T20:50:54.231823Z"
    }
   },
   "source": [
    "# Configuration\n",
    "MODEL_ID = \"sshleifer/tiny-gpt2\"  # Small model for quick experimentation\n",
    "HF_DATASET = \"roneneldan/TinyStories\"\n",
    "DATA_SPLIT = \"train\"\n",
    "TEXT_FIELD = \"text\"\n",
    "DATA_LIMIT = 1000  # Number of text samples to use\n",
    "MAX_LENGTH = 64  # Maximum sequence length\n",
    "BATCH_SIZE_SAVE = 16  # Batch size for saving activations\n",
    "BATCH_SIZE_TRAIN = 32  # Batch size for SAE training\n",
    "\n",
    "# TopKSAE configuration\n",
    "TOP_K = 8  # Number of top activations to keep (sparsity parameter)\n",
    "\n",
    "# Choose which layer to hook - you can inspect available layers with model.layers.print_layer_names()\n",
    "LAYER_SIGNATURE = 'gpt2lmheadmodel_transformer_h_0_attn_c_attn'  # Attention layer (better activations)\n",
    "\n",
    "# Storage locations - will be updated after model loading to use model_id\n",
    "STORE_DIR = Path(\"store\")\n",
    "CACHE_DIR = Path(\"store/cache\")\n",
    "RUN_ID = f\"topk_sae_training_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "# Model-specific paths will be set after loading the model\n",
    "SAE_MODEL_PATH = None  # Will be set to store/{model_id}/topk_sae_model.pt\n",
    "METADATA_PATH = None  # Will be set to store/{model_id}/training_metadata.json\n",
    "\n",
    "# Device configuration\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "DTYPE = torch.float16 if torch.cuda.is_available() else None  # Use half precision on GPU\n",
    "\n",
    "print(\"üöÄ Starting TopKSAE Training Example\")\n",
    "print(f\"üì± Using device: {DEVICE}\")\n",
    "print(f\"üîß Model: {MODEL_ID}\")\n",
    "print(f\"üìä Dataset: {HF_DATASET}\")\n",
    "print(f\"üéØ Target layer: {LAYER_SIGNATURE}\")\n",
    "print(f\"üî¢ TopK parameter: {TOP_K}\")\n",
    "print()\n",
    "\n",
    "# Create output directories\n",
    "CACHE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "STORE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "print(\"‚úÖ Output directories created\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starting TopKSAE Training Example\n",
      "üì± Using device: cpu\n",
      "üîß Model: sshleifer/tiny-gpt2\n",
      "üìä Dataset: roneneldan/TinyStories\n",
      "üéØ Target layer: gpt2lmheadmodel_transformer_h_0_attn_c_attn\n",
      "üî¢ TopK parameter: 8\n",
      "\n",
      "‚úÖ Output directories created\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "id": "7f4f2e75",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T20:50:55.350031Z",
     "start_time": "2025-11-10T20:50:54.264214Z"
    }
   },
   "source": [
    "# Step 1: Load language model with context\n",
    "print(\"üì• Loading language model...\")\n",
    "\n",
    "# Load model first to get model_id\n",
    "lm = LanguageModel.from_huggingface(MODEL_ID)\n",
    "lm.model.to(DEVICE)\n",
    "\n",
    "# Create model-specific directory for organizing all files\n",
    "MODEL_DIR = STORE_DIR / lm.model_id\n",
    "MODEL_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Create store under model-specific directory (so activations are also organized by model)\n",
    "store = LocalStore(MODEL_DIR)\n",
    "\n",
    "# Set the store we want to use (overrides default)\n",
    "lm.context.store = store\n",
    "\n",
    "# Update paths to use model-specific directory\n",
    "SAE_MODEL_PATH = MODEL_DIR / \"topk_sae_model.pt\"\n",
    "METADATA_PATH = MODEL_DIR / \"training_metadata.json\"\n",
    "\n",
    "# Print available layers for reference\n",
    "print(\"üîç Available layers:\")\n",
    "lm.layers.print_layer_names()\n",
    "print(f\"‚úÖ Model loaded: {lm.model_id}\")\n",
    "print(f\"üì± Device: {DEVICE}\")\n",
    "print(f\"üìÅ Store base: {STORE_DIR}\")\n",
    "print(f\"üìÅ Model directory: {MODEL_DIR}\")\n",
    "print(f\"üìÅ Store location: {lm.context.store.base_path}\")\n",
    "print(f\"üíæ SAE model will be saved to: {SAE_MODEL_PATH}\")\n",
    "print(f\"üíæ Metadata will be saved to: {METADATA_PATH}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì• Loading language model...\n",
      "üîç Available layers:\n",
      "gpt2lmheadmodel_transformer: No weight\n",
      "gpt2lmheadmodel_transformer_wte: torch.Size([50257, 2])\n",
      "gpt2lmheadmodel_transformer_wpe: torch.Size([1024, 2])\n",
      "gpt2lmheadmodel_transformer_drop: No weight\n",
      "gpt2lmheadmodel_transformer_h: No weight\n",
      "gpt2lmheadmodel_transformer_h_0: No weight\n",
      "gpt2lmheadmodel_transformer_h_0_ln_1: torch.Size([2])\n",
      "gpt2lmheadmodel_transformer_h_0_attn: No weight\n",
      "gpt2lmheadmodel_transformer_h_0_attn_c_attn: torch.Size([2, 6])\n",
      "gpt2lmheadmodel_transformer_h_0_attn_c_proj: torch.Size([2, 2])\n",
      "gpt2lmheadmodel_transformer_h_0_attn_attn_dropout: No weight\n",
      "gpt2lmheadmodel_transformer_h_0_attn_resid_dropout: No weight\n",
      "gpt2lmheadmodel_transformer_h_0_ln_2: torch.Size([2])\n",
      "gpt2lmheadmodel_transformer_h_0_mlp: No weight\n",
      "gpt2lmheadmodel_transformer_h_0_mlp_c_fc: torch.Size([2, 8])\n",
      "gpt2lmheadmodel_transformer_h_0_mlp_c_proj: torch.Size([8, 2])\n",
      "gpt2lmheadmodel_transformer_h_0_mlp_act: No weight\n",
      "gpt2lmheadmodel_transformer_h_0_mlp_dropout: No weight\n",
      "gpt2lmheadmodel_transformer_h_1: No weight\n",
      "gpt2lmheadmodel_transformer_h_1_ln_1: torch.Size([2])\n",
      "gpt2lmheadmodel_transformer_h_1_attn: No weight\n",
      "gpt2lmheadmodel_transformer_h_1_attn_c_attn: torch.Size([2, 6])\n",
      "gpt2lmheadmodel_transformer_h_1_attn_c_proj: torch.Size([2, 2])\n",
      "gpt2lmheadmodel_transformer_h_1_attn_attn_dropout: No weight\n",
      "gpt2lmheadmodel_transformer_h_1_attn_resid_dropout: No weight\n",
      "gpt2lmheadmodel_transformer_h_1_ln_2: torch.Size([2])\n",
      "gpt2lmheadmodel_transformer_h_1_mlp: No weight\n",
      "gpt2lmheadmodel_transformer_h_1_mlp_c_fc: torch.Size([2, 8])\n",
      "gpt2lmheadmodel_transformer_h_1_mlp_c_proj: torch.Size([8, 2])\n",
      "gpt2lmheadmodel_transformer_h_1_mlp_act: No weight\n",
      "gpt2lmheadmodel_transformer_h_1_mlp_dropout: No weight\n",
      "gpt2lmheadmodel_transformer_ln_f: torch.Size([2])\n",
      "gpt2lmheadmodel_lm_head: torch.Size([50257, 2])\n",
      "‚úÖ Model loaded: sshleifer_tiny-gpt2\n",
      "üì± Device: cpu\n",
      "üìÅ Store base: store\n",
      "üìÅ Model directory: store/sshleifer_tiny-gpt2\n",
      "üìÅ Store location: store/sshleifer_tiny-gpt2\n",
      "üíæ SAE model will be saved to: store/sshleifer_tiny-gpt2/topk_sae_model.pt\n",
      "üíæ Metadata will be saved to: store/sshleifer_tiny-gpt2/training_metadata.json\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "id": "6d926cb0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T20:50:57.203344Z",
     "start_time": "2025-11-10T20:50:55.370828Z"
    }
   },
   "source": [
    "# Step 2: Load dataset\n",
    "print(\"üì• Loading dataset...\")\n",
    "dataset = TextDataset.from_huggingface(\n",
    "    HF_DATASET,\n",
    "    split=DATA_SPLIT,\n",
    "    cache_dir=str(CACHE_DIR),\n",
    "    text_field=TEXT_FIELD,\n",
    "    limit=DATA_LIMIT,\n",
    ")\n",
    "print(f\"‚úÖ Loaded {len(dataset)} text samples\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì• Loading dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1000/1000 [00:00<00:00, 380954.04 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded 1000 text samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "id": "cae06f7e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T20:51:04.809738Z",
     "start_time": "2025-11-10T20:50:57.218659Z"
    }
   },
   "source": [
    "# Step 3: Save activations\n",
    "print(\"üíæ Saving activations...\")\n",
    "\n",
    "# Use the store that was set on the language model\n",
    "lm.activations.infer_and_save(\n",
    "    dataset,\n",
    "    layer_signature=LAYER_SIGNATURE,\n",
    "    run_name=RUN_ID,\n",
    "    store=lm.context.store,  # Use the store from language model\n",
    "    batch_size=BATCH_SIZE_SAVE,\n",
    "    autocast=False,  # Disable autocast for consistency\n",
    ")\n",
    "\n",
    "# Verify activations were saved\n",
    "batches = lm.context.store.list_run_batches(RUN_ID)\n",
    "print(f\"‚úÖ Saved {len(batches)} batches of activations\")\n",
    "print(f\"üìÅ Run ID: {RUN_ID}\")\n",
    "print(f\"üìÅ Store location: {lm.context.store.base_path}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Saving activations...\n",
      "‚úÖ Saved 63 batches of activations\n",
      "üìÅ Run ID: topk_sae_training_20251110_215054\n",
      "üìÅ Store location: store/sshleifer_tiny-gpt2\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "id": "a451d6d9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T20:51:04.849993Z",
     "start_time": "2025-11-10T20:51:04.824880Z"
    }
   },
   "source": [
    "# Step 4: Create TopKSAE model\n",
    "print(\"üèóÔ∏è Creating TopKSAE model...\")\n",
    "\n",
    "# Get the hidden dimension from the first batch\n",
    "first_batch = lm.context.store.get_run_batch(RUN_ID, 0)\n",
    "if isinstance(first_batch, dict):\n",
    "    activations = first_batch[\"activations\"]\n",
    "else:\n",
    "    activations = first_batch[0]  # Assume first tensor is activations\n",
    "\n",
    "hidden_dim = activations.shape[-1]  # Last dimension is hidden size\n",
    "print(f\"üìè Hidden dimension: {hidden_dim}\")\n",
    "\n",
    "sae = TopKSae(\n",
    "    n_latents=hidden_dim * 4,\n",
    "    n_inputs=hidden_dim,\n",
    "    k=TOP_K,\n",
    "    device=DEVICE,\n",
    ")\n",
    "\n",
    "print(f\"üß† TopKSAE architecture: {hidden_dim} ‚Üí {sae.context.n_latents} ‚Üí {hidden_dim}\")\n",
    "print(f\"üî¢ TopK parameter: {sae.k}\")\n",
    "print(f\"üîß Device: {DEVICE}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèóÔ∏è Creating TopKSAE model...\n",
      "üìè Hidden dimension: 6\n",
      "üß† TopKSAE architecture: 6 ‚Üí 24 ‚Üí 6\n",
      "üî¢ TopK parameter: 8\n",
      "üîß Device: cpu\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "id": "b3dd61f7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T20:51:08.050577Z",
     "start_time": "2025-11-10T20:51:04.858119Z"
    }
   },
   "source": [
    "# Step 5: Train TopKSAE using SaeTrainer\n",
    "print(\"üèãÔ∏è Training TopKSAE...\")\n",
    "print(\"üìù Note: Training uses overcomplete's train_sae functions via the SaeTrainer composite class\")\n",
    "print(f\"üîß Trainer available at: sae.trainer (type: {type(sae.trainer).__name__})\")\n",
    "print()\n",
    "\n",
    "# Configure training parameters\n",
    "# Note: TopKSAETrainingConfig is an alias for SaeTrainingConfig\n",
    "# You can also use SaeTrainingConfig directly from sae_trainer module\n",
    "config = TopKSAETrainingConfig(\n",
    "    epochs=100,\n",
    "    batch_size=BATCH_SIZE_TRAIN,\n",
    "    lr=1e-3,\n",
    "    l1_lambda=1e-4,  # L1 sparsity penalty\n",
    "    device=DEVICE,\n",
    "    dtype=DTYPE,\n",
    "    max_batches_per_epoch=50,  # Limit batches per epoch for quick training\n",
    "    verbose=True,  # Enable progress logging\n",
    "    use_amp=True,\n",
    "    amp_dtype=DTYPE,\n",
    "    clip_grad=1.0,  # Gradient clipping (overcomplete parameter)\n",
    "    monitoring=2,  # Detailed monitoring (0=silent, 1=basic, 2=detailed)\n",
    ")\n",
    "\n",
    "# Train using TopKSAE's train method (which delegates to sae.trainer.train())\n",
    "# The trainer uses overcomplete's train_sae_amp or train_sae functions internally\n",
    "history = sae.train(lm.context.store, RUN_ID, config)\n",
    "\n",
    "print()\n",
    "print(\"‚úÖ Training completed!\")\n",
    "print(f\"üìà Final loss: {history['loss'][-1]:.6f}\")\n",
    "print(f\"üìà Final reconstruction MSE: {history['recon_mse'][-1]:.6f}\")\n",
    "print(f\"üìà Final L1 penalty: {history['l1'][-1]:.6f}\")\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-10 21:51:04,882 [INFO] amber.mechanistic.sae.sae_trainer: [SaeTrainer] Starting training run_id=topk_sae_training_20251110_215054 epochs=100 batch_size=32 device=cpu use_amp=True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèãÔ∏è Training TopKSAE...\n",
      "üìù Note: Training uses overcomplete's train_sae functions via the SaeTrainer composite class\n",
      "üîß Trainer available at: sae.trainer (type: SaeTrainer)\n",
      "\n",
      "Epoch[1/100], Loss: 0.0736, R2: -95.7907, L0: 8.0000, Dead Features: 62.5%, Time: 0.0339 seconds\n",
      "Epoch[2/100], Loss: 0.0255, R2: -32.5938, L0: 8.0000, Dead Features: 58.3%, Time: 0.0315 seconds\n",
      "Epoch[3/100], Loss: 0.0078, R2: -9.2731, L0: 8.0000, Dead Features: 58.3%, Time: 0.0303 seconds\n",
      "Epoch[4/100], Loss: 0.0023, R2: -2.0103, L0: 8.0000, Dead Features: 58.3%, Time: 0.0323 seconds\n",
      "Epoch[5/100], Loss: 0.0007, R2: 0.0273, L0: 8.0000, Dead Features: 58.3%, Time: 0.0349 seconds\n",
      "Epoch[6/100], Loss: 0.0003, R2: 0.6162, L0: 8.0000, Dead Features: 62.5%, Time: 0.0331 seconds\n",
      "Epoch[7/100], Loss: 0.0002, R2: 0.7070, L0: 8.0000, Dead Features: 58.3%, Time: 0.0296 seconds\n",
      "Epoch[8/100], Loss: 0.0001, R2: 0.8129, L0: 8.0000, Dead Features: 62.5%, Time: 0.0296 seconds\n",
      "Epoch[9/100], Loss: 0.0001, R2: 0.8143, L0: 8.0000, Dead Features: 62.5%, Time: 0.0334 seconds\n",
      "Epoch[10/100], Loss: 0.0001, R2: 0.8308, L0: 8.0000, Dead Features: 62.5%, Time: 0.0354 seconds\n",
      "Epoch[11/100], Loss: 0.0001, R2: 0.8404, L0: 8.0000, Dead Features: 62.5%, Time: 0.0356 seconds\n",
      "Epoch[12/100], Loss: 0.0001, R2: 0.8397, L0: 8.0000, Dead Features: 58.3%, Time: 0.0341 seconds\n",
      "Epoch[13/100], Loss: 0.0001, R2: 0.8458, L0: 8.0000, Dead Features: 58.3%, Time: 0.0344 seconds\n",
      "Epoch[14/100], Loss: 0.0001, R2: 0.8620, L0: 8.0000, Dead Features: 58.3%, Time: 0.0332 seconds\n",
      "Epoch[15/100], Loss: 0.0001, R2: 0.8789, L0: 8.0000, Dead Features: 58.3%, Time: 0.0312 seconds\n",
      "Epoch[16/100], Loss: 0.0001, R2: 0.8877, L0: 8.0000, Dead Features: 62.5%, Time: 0.0298 seconds\n",
      "Epoch[17/100], Loss: 0.0001, R2: 0.8927, L0: 8.0000, Dead Features: 58.3%, Time: 0.0260 seconds\n",
      "Epoch[18/100], Loss: 0.0001, R2: 0.9012, L0: 8.0000, Dead Features: 58.3%, Time: 0.0292 seconds\n",
      "Epoch[19/100], Loss: 0.0001, R2: 0.9068, L0: 8.0000, Dead Features: 58.3%, Time: 0.0326 seconds\n",
      "Epoch[20/100], Loss: 0.0001, R2: 0.9154, L0: 8.0000, Dead Features: 58.3%, Time: 0.0307 seconds\n",
      "Epoch[21/100], Loss: 0.0001, R2: 0.9162, L0: 8.0000, Dead Features: 58.3%, Time: 0.0324 seconds\n",
      "Epoch[22/100], Loss: 0.0001, R2: 0.9289, L0: 8.0000, Dead Features: 62.5%, Time: 0.0279 seconds\n",
      "Epoch[23/100], Loss: 0.0001, R2: 0.9336, L0: 8.0000, Dead Features: 58.3%, Time: 0.0335 seconds\n",
      "Epoch[24/100], Loss: 0.0001, R2: 0.9360, L0: 8.0000, Dead Features: 58.3%, Time: 0.0358 seconds\n",
      "Epoch[25/100], Loss: 0.0001, R2: 0.9394, L0: 8.0000, Dead Features: 58.3%, Time: 0.0372 seconds\n",
      "Epoch[26/100], Loss: 0.0001, R2: 0.9443, L0: 8.0000, Dead Features: 62.5%, Time: 0.0350 seconds\n",
      "Epoch[27/100], Loss: 0.0000, R2: 0.9466, L0: 8.0000, Dead Features: 58.3%, Time: 0.0331 seconds\n",
      "Epoch[28/100], Loss: 0.0000, R2: 0.9485, L0: 8.0000, Dead Features: 58.3%, Time: 0.0339 seconds\n",
      "Epoch[29/100], Loss: 0.0000, R2: 0.9504, L0: 8.0000, Dead Features: 58.3%, Time: 0.0333 seconds\n",
      "Epoch[30/100], Loss: 0.0000, R2: 0.9522, L0: 8.0000, Dead Features: 58.3%, Time: 0.0348 seconds\n",
      "Epoch[31/100], Loss: 0.0000, R2: 0.9528, L0: 8.0000, Dead Features: 58.3%, Time: 0.0334 seconds\n",
      "Epoch[32/100], Loss: 0.0000, R2: 0.9550, L0: 8.0000, Dead Features: 58.3%, Time: 0.0353 seconds\n",
      "Epoch[33/100], Loss: 0.0000, R2: 0.9563, L0: 8.0000, Dead Features: 58.3%, Time: 0.0329 seconds\n",
      "Epoch[34/100], Loss: 0.0000, R2: 0.9569, L0: 8.0000, Dead Features: 58.3%, Time: 0.0287 seconds\n",
      "Epoch[35/100], Loss: 0.0000, R2: 0.9587, L0: 8.0000, Dead Features: 58.3%, Time: 0.0317 seconds\n",
      "Epoch[36/100], Loss: 0.0000, R2: 0.9596, L0: 8.0000, Dead Features: 58.3%, Time: 0.0278 seconds\n",
      "Epoch[37/100], Loss: 0.0000, R2: 0.9613, L0: 8.0000, Dead Features: 58.3%, Time: 0.0298 seconds\n",
      "Epoch[38/100], Loss: 0.0000, R2: 0.9615, L0: 8.0000, Dead Features: 58.3%, Time: 0.0296 seconds\n",
      "Epoch[39/100], Loss: 0.0000, R2: 0.9637, L0: 8.0000, Dead Features: 58.3%, Time: 0.0300 seconds\n",
      "Epoch[40/100], Loss: 0.0000, R2: 0.9639, L0: 8.0000, Dead Features: 58.3%, Time: 0.0307 seconds\n",
      "Epoch[41/100], Loss: 0.0000, R2: 0.9659, L0: 8.0000, Dead Features: 58.3%, Time: 0.0273 seconds\n",
      "Epoch[42/100], Loss: 0.0000, R2: 0.9673, L0: 8.0000, Dead Features: 58.3%, Time: 0.0274 seconds\n",
      "Epoch[43/100], Loss: 0.0000, R2: 0.9678, L0: 8.0000, Dead Features: 58.3%, Time: 0.0289 seconds\n",
      "Epoch[44/100], Loss: 0.0000, R2: 0.9690, L0: 8.0000, Dead Features: 58.3%, Time: 0.0299 seconds\n",
      "Epoch[45/100], Loss: 0.0000, R2: 0.9686, L0: 8.0000, Dead Features: 58.3%, Time: 0.0280 seconds\n",
      "Epoch[46/100], Loss: 0.0000, R2: 0.9724, L0: 8.0000, Dead Features: 62.5%, Time: 0.0280 seconds\n",
      "Epoch[47/100], Loss: 0.0000, R2: 0.9723, L0: 8.0000, Dead Features: 58.3%, Time: 0.0282 seconds\n",
      "Epoch[48/100], Loss: 0.0000, R2: 0.9721, L0: 8.0000, Dead Features: 58.3%, Time: 0.0313 seconds\n",
      "Epoch[49/100], Loss: 0.0000, R2: 0.9737, L0: 8.0000, Dead Features: 58.3%, Time: 0.0306 seconds\n",
      "Epoch[50/100], Loss: 0.0000, R2: 0.9750, L0: 8.0000, Dead Features: 62.5%, Time: 0.0285 seconds\n",
      "Epoch[51/100], Loss: 0.0000, R2: 0.9748, L0: 8.0000, Dead Features: 58.3%, Time: 0.0294 seconds\n",
      "Epoch[52/100], Loss: 0.0000, R2: 0.9751, L0: 8.0000, Dead Features: 58.3%, Time: 0.0286 seconds\n",
      "Epoch[53/100], Loss: 0.0000, R2: 0.9777, L0: 8.0000, Dead Features: 62.5%, Time: 0.0301 seconds\n",
      "Epoch[54/100], Loss: 0.0000, R2: 0.9771, L0: 8.0000, Dead Features: 58.3%, Time: 0.0284 seconds\n",
      "Epoch[55/100], Loss: 0.0000, R2: 0.9796, L0: 8.0000, Dead Features: 62.5%, Time: 0.0260 seconds\n",
      "Epoch[56/100], Loss: 0.0000, R2: 0.9787, L0: 8.0000, Dead Features: 58.3%, Time: 0.0290 seconds\n",
      "Epoch[57/100], Loss: 0.0000, R2: 0.9807, L0: 8.0000, Dead Features: 62.5%, Time: 0.0293 seconds\n",
      "Epoch[58/100], Loss: 0.0000, R2: 0.9802, L0: 8.0000, Dead Features: 58.3%, Time: 0.0302 seconds\n",
      "Epoch[59/100], Loss: 0.0000, R2: 0.9818, L0: 8.0000, Dead Features: 58.3%, Time: 0.0271 seconds\n",
      "Epoch[60/100], Loss: 0.0000, R2: 0.9821, L0: 8.0000, Dead Features: 58.3%, Time: 0.0291 seconds\n",
      "Epoch[61/100], Loss: 0.0000, R2: 0.9807, L0: 8.0000, Dead Features: 54.2%, Time: 0.0297 seconds\n",
      "Epoch[62/100], Loss: 0.0000, R2: 0.9832, L0: 8.0000, Dead Features: 62.5%, Time: 0.0314 seconds\n",
      "Epoch[63/100], Loss: 0.0000, R2: 0.9830, L0: 8.0000, Dead Features: 58.3%, Time: 0.0301 seconds\n",
      "Epoch[64/100], Loss: 0.0000, R2: 0.9843, L0: 8.0000, Dead Features: 62.5%, Time: 0.0283 seconds\n",
      "Epoch[65/100], Loss: 0.0000, R2: 0.9836, L0: 8.0000, Dead Features: 58.3%, Time: 0.0296 seconds\n",
      "Epoch[66/100], Loss: 0.0000, R2: 0.9851, L0: 8.0000, Dead Features: 62.5%, Time: 0.0289 seconds\n",
      "Epoch[67/100], Loss: 0.0000, R2: 0.9849, L0: 8.0000, Dead Features: 58.3%, Time: 0.0278 seconds\n",
      "Epoch[68/100], Loss: 0.0000, R2: 0.9858, L0: 8.0000, Dead Features: 58.3%, Time: 0.0272 seconds\n",
      "Epoch[69/100], Loss: 0.0000, R2: 0.9865, L0: 8.0000, Dead Features: 58.3%, Time: 0.0323 seconds\n",
      "Epoch[70/100], Loss: 0.0000, R2: 0.9872, L0: 8.0000, Dead Features: 58.3%, Time: 0.0290 seconds\n",
      "Epoch[71/100], Loss: 0.0000, R2: 0.9875, L0: 8.0000, Dead Features: 58.3%, Time: 0.0288 seconds\n",
      "Epoch[72/100], Loss: 0.0000, R2: 0.9881, L0: 8.0000, Dead Features: 58.3%, Time: 0.0282 seconds\n",
      "Epoch[73/100], Loss: 0.0000, R2: 0.9887, L0: 8.0000, Dead Features: 58.3%, Time: 0.0313 seconds\n",
      "Epoch[74/100], Loss: 0.0000, R2: 0.9862, L0: 8.0000, Dead Features: 54.2%, Time: 0.0318 seconds\n",
      "Epoch[75/100], Loss: 0.0000, R2: 0.9900, L0: 8.0000, Dead Features: 58.3%, Time: 0.0283 seconds\n",
      "Epoch[76/100], Loss: 0.0000, R2: 0.9899, L0: 8.0000, Dead Features: 58.3%, Time: 0.0330 seconds\n",
      "Epoch[77/100], Loss: 0.0000, R2: 0.9906, L0: 8.0000, Dead Features: 62.5%, Time: 0.0367 seconds\n",
      "Epoch[78/100], Loss: 0.0000, R2: 0.9907, L0: 8.0000, Dead Features: 58.3%, Time: 0.0342 seconds\n",
      "Epoch[79/100], Loss: 0.0000, R2: 0.9919, L0: 8.0000, Dead Features: 62.5%, Time: 0.0333 seconds\n",
      "Epoch[80/100], Loss: 0.0000, R2: 0.9920, L0: 8.0000, Dead Features: 58.3%, Time: 0.0348 seconds\n",
      "Epoch[81/100], Loss: 0.0000, R2: 0.9923, L0: 8.0000, Dead Features: 58.3%, Time: 0.0356 seconds\n",
      "Epoch[82/100], Loss: 0.0000, R2: 0.9921, L0: 8.0000, Dead Features: 54.2%, Time: 0.0346 seconds\n",
      "Epoch[83/100], Loss: 0.0000, R2: 0.9927, L0: 8.0000, Dead Features: 54.2%, Time: 0.0339 seconds\n",
      "Epoch[84/100], Loss: 0.0000, R2: 0.9938, L0: 8.0000, Dead Features: 58.3%, Time: 0.0350 seconds\n",
      "Epoch[85/100], Loss: 0.0000, R2: 0.9943, L0: 8.0000, Dead Features: 62.5%, Time: 0.0335 seconds\n",
      "Epoch[86/100], Loss: 0.0000, R2: 0.9945, L0: 8.0000, Dead Features: 58.3%, Time: 0.0309 seconds\n",
      "Epoch[87/100], Loss: 0.0000, R2: 0.9950, L0: 8.0000, Dead Features: 58.3%, Time: 0.0343 seconds\n",
      "Epoch[88/100], Loss: 0.0000, R2: 0.9950, L0: 8.0000, Dead Features: 58.3%, Time: 0.0359 seconds\n",
      "Epoch[89/100], Loss: 0.0000, R2: 0.9956, L0: 8.0000, Dead Features: 58.3%, Time: 0.0364 seconds\n",
      "Epoch[90/100], Loss: 0.0000, R2: 0.9961, L0: 8.0000, Dead Features: 58.3%, Time: 0.0344 seconds\n",
      "Epoch[91/100], Loss: 0.0000, R2: 0.9964, L0: 8.0000, Dead Features: 45.8%, Time: 0.0340 seconds\n",
      "Epoch[92/100], Loss: 0.0000, R2: 0.9973, L0: 8.0000, Dead Features: 54.2%, Time: 0.0343 seconds\n",
      "Epoch[93/100], Loss: 0.0000, R2: 0.9976, L0: 8.0000, Dead Features: 54.2%, Time: 0.0369 seconds\n",
      "Epoch[94/100], Loss: 0.0000, R2: 0.9983, L0: 8.0000, Dead Features: 58.3%, Time: 0.0334 seconds\n",
      "Epoch[95/100], Loss: 0.0000, R2: 0.9985, L0: 8.0000, Dead Features: 54.2%, Time: 0.0316 seconds\n",
      "Epoch[96/100], Loss: 0.0000, R2: 0.9985, L0: 8.0000, Dead Features: 54.2%, Time: 0.0286 seconds\n",
      "Epoch[97/100], Loss: 0.0000, R2: 0.9990, L0: 8.0000, Dead Features: 58.3%, Time: 0.0315 seconds\n",
      "Epoch[98/100], Loss: 0.0000, R2: 0.9991, L0: 8.0000, Dead Features: 58.3%, Time: 0.0326 seconds\n",
      "Epoch[99/100], Loss: 0.0000, R2: 0.9991, L0: 8.0000, Dead Features: 54.2%, Time: 0.0345 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-10 21:51:08,045 [INFO] amber.mechanistic.sae.sae_trainer: [SaeTrainer] Completed training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[100/100], Loss: 0.0000, R2: 0.9994, L0: 8.0000, Dead Features: 66.7%, Time: 0.0344 seconds\n",
      "\n",
      "‚úÖ Training completed!\n",
      "üìà Final loss: 0.000009\n",
      "üìà Final reconstruction MSE: 0.000630\n",
      "üìà Final L1 penalty: 0.000000\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "id": "e2c17d61",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T20:52:22.698138Z",
     "start_time": "2025-11-10T20:52:22.651659Z"
    }
   },
   "source": [
    "# Step 6: Save trained TopKSAE\n",
    "print(\"üíæ Saving trained TopKSAE...\")\n",
    "\n",
    "# Save using TopKSAE's save method (saves overcomplete model + our metadata)\n",
    "sae.save(\n",
    "    name=\"topk_sae_model\",\n",
    "    path=SAE_MODEL_PATH.parent\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ TopKSAE saved to: {SAE_MODEL_PATH}\")\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-10 21:52:22,683 [INFO] amber.mechanistic.sae.modules.topk_sae: Saved TopKSAE to store/sshleifer_tiny-gpt2/topk_sae_model.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Saving trained TopKSAE...\n",
      "‚úÖ TopKSAE saved to: store/sshleifer_tiny-gpt2/topk_sae_model.pt\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T20:53:10.615286Z",
     "start_time": "2025-11-10T20:53:10.580882Z"
    }
   },
   "cell_type": "code",
   "source": "lm.layers.register_hook(LAYER_SIGNATURE, sae)",
   "id": "535b3b268d95fe2d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'206ad0d9-4afd-4259-8eb4-9848be6d92cf'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "a028ef6a3f544970"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
