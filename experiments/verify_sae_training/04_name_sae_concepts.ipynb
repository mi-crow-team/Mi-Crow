{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export Top Texts for SAE Concepts\n",
    "\n",
    "This notebook:\n",
    "1. Loads the trained SAE model\n",
    "2. Attaches it to the language model\n",
    "3. Enables text tracking\n",
    "4. Runs inference to collect top texts for each neuron\n",
    "5. Exports the top texts to JSON"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-12T19:29:19.426079Z",
     "start_time": "2025-12-12T19:29:19.350414Z"
    }
   },
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "from pathlib import Path\n",
    "\n",
    "from amber.datasets import TextDataset\n",
    "from amber.language_model.language_model import LanguageModel\n",
    "from amber.mechanistic.sae.modules.topk_sae import TopKSae\n",
    "from amber.store.local_store import LocalStore"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-12T19:29:19.453127Z",
     "start_time": "2025-12-12T19:29:19.429495Z"
    }
   },
   "source": [
    "MODEL_ID = \"speakleash/Bielik-1.5B-v3.0-Instruct\"\n",
    "HF_DATASET = \"roneneldan/TinyStories\"\n",
    "DATA_SPLIT = \"train\"\n",
    "TEXT_FIELD = \"text\"\n",
    "DATA_LIMIT = 32\n",
    "MAX_LENGTH = 128\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "STORE_DIR = Path(\"./store\")\n",
    "TOP_TEXTS_FILE = STORE_DIR / \"runs\" / \"training_20251212_184640\" / \"top_texts.json\"\n",
    "SAE_MODEL_PATH = STORE_DIR / \"runs\" / \"training_20251212_184640\" / \"model.pt\"\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "print(f\"ğŸ“± Using device: {DEVICE}\")\n",
    "print(f\"ğŸ”§ Model: {MODEL_ID}\")\n",
    "print(f\"ğŸ“Š Dataset: {HF_DATASET}\")\n",
    "print(f\"ğŸ’¾ SAE model: {SAE_MODEL_PATH}\")\n",
    "print(f\"ğŸ’¾ Output file: {TOP_TEXTS_FILE}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“± Using device: cpu\n",
      "ğŸ”§ Model: speakleash/Bielik-1.5B-v3.0-Instruct\n",
      "ğŸ“Š Dataset: roneneldan/TinyStories\n",
      "ğŸ’¾ SAE model: store/runs/training_20251212_184640/model.pt\n",
      "ğŸ’¾ Output file: store/runs/training_20251212_184640/top_texts.json\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-12T19:29:23.321612Z",
     "start_time": "2025-12-12T19:29:19.457079Z"
    }
   },
   "source": [
    "print(\"ğŸ“¥ Loading language model...\")\n",
    "store = LocalStore(base_path=STORE_DIR)\n",
    "lm = LanguageModel.from_huggingface(MODEL_ID, store=store)\n",
    "lm.model.to(DEVICE)\n",
    "\n",
    "print(f\"âœ… Model loaded: {lm.model_id}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¥ Loading language model...\n",
      "âœ… Model loaded: speakleash_Bielik-1.5B-v3.0-Instruct\n"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-12T19:29:23.371305Z",
     "start_time": "2025-12-12T19:29:23.344931Z"
    }
   },
   "source": [
    "run_id_file = STORE_DIR / \"run_id.txt\"\n",
    "with open(run_id_file, 'r') as f:\n",
    "    RUN_ID = f.read().strip()\n",
    "\n",
    "meta = store.get_run_metadata(RUN_ID)\n",
    "layer_signatures = meta.get('layer_signatures', [])\n",
    "layer_signature = layer_signatures[0] if layer_signatures else None\n",
    "\n",
    "print(f\"ğŸ“ Run ID: {RUN_ID}\")\n",
    "print(f\"ğŸ¯ Layer: {layer_signature}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“ Run ID: activations_20251212_172220\n",
      "ğŸ¯ Layer: llamaforcausallm_model_layers_16_post_attention_layernorm\n"
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-12T19:29:23.478992Z",
     "start_time": "2025-12-12T19:29:23.376337Z"
    }
   },
   "source": [
    "print(\"ğŸ“¥ Loading SAE model...\")\n",
    "sae = TopKSae.load(SAE_MODEL_PATH)\n",
    "sae.context.device = DEVICE\n",
    "sae.sae_engine.to(DEVICE)\n",
    "\n",
    "if layer_signature is None and sae.context.lm_layer_signature is not None:\n",
    "    layer_signature = sae.context.lm_layer_signature\n",
    "    print(f\"ğŸ“ Using layer signature from SAE context: {layer_signature}\")\n",
    "\n",
    "print(f\"âœ… SAE loaded\")\n",
    "print(f\"   Input dimension: {sae.context.n_inputs}\")\n",
    "print(f\"   Latent dimension: {sae.context.n_latents}\")\n",
    "print(f\"   TopK: {sae.k}\")\n",
    "print(f\"   Layer signature: {layer_signature}\")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-12 20:29:23,476 [INFO] amber.mechanistic.sae.modules.topk_sae: \n",
      "Loaded TopKSAE from store/runs/training_20251212_184640/model.pt\n",
      "n_latents=6144, n_inputs=1536, k=8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¥ Loading SAE model...\n",
      "âœ… SAE loaded\n",
      "   Input dimension: 1536\n",
      "   Latent dimension: 6144\n",
      "   TopK: 8\n",
      "   Layer signature: llamaforcausallm_model_layers_16_post_attention_layernorm\n"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-12T19:29:23.507626Z",
     "start_time": "2025-12-12T19:29:23.484321Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"ğŸ”— Attaching SAE to language model...\")\n",
    "if layer_signature is None:\n",
    "    print(\"âŒ Error: Layer signature is None. Cannot attach SAE.\")\n",
    "else:\n",
    "    hook_id = lm.layers.register_hook(layer_signature, sae)\n",
    "    print(f\"âœ… SAE attached to layer: {layer_signature}\")\n",
    "    print(f\"   Hook ID: {hook_id}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”— Attaching SAE to language model...\n",
      "âœ… SAE attached to layer: llamaforcausallm_model_layers_16_post_attention_layernorm\n",
      "   Hook ID: 7e75ef61-a099-4457-85a5-4c32211b85cf\n"
     ]
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-12T19:29:23.533114Z",
     "start_time": "2025-12-12T19:29:23.511811Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"ğŸ“Š Enabling text tracking...\")\n",
    "sae.concepts.enable_text_tracking()\n",
    "print(\"âœ… Text tracking enabled\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š Enabling text tracking...\n",
      "âœ… Text tracking enabled\n"
     ]
    }
   ],
   "execution_count": 40
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-12T19:29:30.962376Z",
     "start_time": "2025-12-12T19:29:23.536337Z"
    }
   },
   "source": [
    "print(\"ğŸ“¥ Loading dataset...\")\n",
    "dataset = TextDataset.from_huggingface(\n",
    "    HF_DATASET,\n",
    "    split=DATA_SPLIT,\n",
    "    store=store,\n",
    "    text_field=TEXT_FIELD,\n",
    "    limit=DATA_LIMIT,\n",
    ")\n",
    "print(f\"âœ… Loaded {len(dataset)} text samples\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¥ Loading dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:00<00:00, 12306.78 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Loaded 32 text samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 41
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-12T19:29:50.481207Z",
     "start_time": "2025-12-12T19:29:30.972683Z"
    }
   },
   "source": [
    "print(\"ğŸš€ Running inference to collect top texts...\")\n",
    "print(f\"   Processing {len(dataset)} samples in batches of {BATCH_SIZE}\")\n",
    "\n",
    "with torch.inference_mode():\n",
    "    for batch_idx, batch in enumerate(dataset.iter_batches(BATCH_SIZE)):\n",
    "        texts = dataset.extract_texts_from_batch(batch)\n",
    "        lm.forwards(\n",
    "            texts,\n",
    "            tok_kwargs={\n",
    "                \"max_length\": MAX_LENGTH,\n",
    "                \"padding\": True,\n",
    "                \"truncation\": True,\n",
    "                \"add_special_tokens\": True\n",
    "            },\n",
    "            autocast=False,\n",
    "        )\n",
    "\n",
    "        print(f\"   Processed {batch_idx + 1} batches...\")\n",
    "\n",
    "print(\"âœ… Inference completed\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ Running inference to collect top texts...\n",
      "   Processing 32 samples in batches of 16\n",
      "   Processed 1 batches...\n",
      "   Processed 2 batches...\n",
      "âœ… Inference completed\n"
     ]
    }
   ],
   "execution_count": 42
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-12T19:30:08.861464Z",
     "start_time": "2025-12-12T19:30:00.633614Z"
    }
   },
   "source": [
    "print(\"ğŸ’¾ Exporting top texts...\")\n",
    "exported_path = sae.concepts.export_top_texts_to_json(TOP_TEXTS_FILE)\n",
    "print(f\"âœ… Top texts exported to: {exported_path}\")\n",
    "\n",
    "all_top_texts = sae.concepts.get_all_top_texts()\n",
    "neurons_with_texts = sum(1 for texts in all_top_texts if texts)\n",
    "total_texts = sum(len(texts) for texts in all_top_texts)\n",
    "\n",
    "print(f\"ğŸ“Š Statistics:\")\n",
    "print(f\"   Neurons with texts: {neurons_with_texts} / {sae.context.n_latents}\")\n",
    "print(f\"   Total texts collected: {total_texts}\")\n",
    "print(f\"   Average texts per neuron: {total_texts / sae.context.n_latents:.2f}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ’¾ Exporting top texts...\n",
      "âœ… Top texts exported to: store/runs/training_20251212_184640/top_texts.json\n",
      "ğŸ“Š Statistics:\n",
      "   Neurons with texts: 6144 / 6144\n",
      "   Total texts collected: 30720\n",
      "   Average texts per neuron: 5.00\n"
     ]
    }
   ],
   "execution_count": 44
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
