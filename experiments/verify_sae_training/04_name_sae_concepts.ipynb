{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export Top Texts for SAE Concepts\n",
    "\n",
    "This notebook:\n",
    "1. Loads the trained SAE model\n",
    "2. Attaches it to the language model\n",
    "3. Enables text tracking\n",
    "4. Runs inference to collect top texts for each neuron\n",
    "5. Exports the top texts to JSON"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-13T22:13:47.268287Z",
     "start_time": "2025-12-13T22:13:47.238013Z"
    }
   },
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "from pathlib import Path\n",
    "\n",
    "from mi_crow.datasets import TextDataset\n",
    "from mi_crow.language_model.language_model import LanguageModel\n",
    "from mi_crow.mechanistic.sae.modules.topk_sae import TopKSae\n",
    "from mi_crow.store.local_store import LocalStore"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-13T22:13:47.299396Z",
     "start_time": "2025-12-13T22:13:47.273217Z"
    }
   },
   "source": [
    "MODEL_ID = \"speakleash/Bielik-1.5B-v3.0-Instruct\"\n",
    "HF_DATASET = \"roneneldan/TinyStories\"\n",
    "DATA_SPLIT = \"train\"\n",
    "TEXT_FIELD = \"text\"\n",
    "DATA_LIMIT = 32\n",
    "MAX_LENGTH = 128\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "STORE_DIR = Path(\"./store\")\n",
    "TOP_TEXTS_FILE = STORE_DIR / \"runs\" / \"training_20251213_005514\" / \"top_texts.json\"\n",
    "SAE_MODEL_PATH = STORE_DIR / \"runs\" / \"training_20251213_005514\" / \"model.pt\"\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "print(f\"ğŸ“± Using device: {DEVICE}\")\n",
    "print(f\"ğŸ”§ Model: {MODEL_ID}\")\n",
    "print(f\"ğŸ“Š Dataset: {HF_DATASET}\")\n",
    "print(f\"ğŸ’¾ SAE model: {SAE_MODEL_PATH}\")\n",
    "print(f\"ğŸ’¾ Output file: {TOP_TEXTS_FILE}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“± Using device: cpu\n",
      "ğŸ”§ Model: speakleash/Bielik-1.5B-v3.0-Instruct\n",
      "ğŸ“Š Dataset: roneneldan/TinyStories\n",
      "ğŸ’¾ SAE model: store/runs/training_20251213_005514/model.pt\n",
      "ğŸ’¾ Output file: store/runs/training_20251213_005514/top_texts.json\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-13T22:13:49.102957Z",
     "start_time": "2025-12-13T22:13:47.303375Z"
    }
   },
   "source": [
    "print(\"ğŸ“¥ Loading language model...\")\n",
    "store = LocalStore(base_path=STORE_DIR)\n",
    "lm = LanguageModel.from_huggingface(MODEL_ID, store=store)\n",
    "lm.model.to(DEVICE)\n",
    "\n",
    "print(f\"âœ… Model loaded: {lm.model_id}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¥ Loading language model...\n",
      "âœ… Model loaded: speakleash_Bielik-1.5B-v3.0-Instruct\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-13T22:13:49.219123Z",
     "start_time": "2025-12-13T22:13:49.155520Z"
    }
   },
   "source": [
    "run_id_file = STORE_DIR / \"run_id.txt\"\n",
    "with open(run_id_file, 'r') as f:\n",
    "    RUN_ID = f.read().strip()\n",
    "\n",
    "meta = store.get_run_metadata(RUN_ID)\n",
    "layer_signatures = meta.get('layer_signatures', [])\n",
    "layer_signature = layer_signatures[0] if layer_signatures else None\n",
    "\n",
    "print(f\"ğŸ“ Run ID: {RUN_ID}\")\n",
    "print(f\"ğŸ¯ Layer: {layer_signature}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“ Run ID: activations_20251212_172220\n",
      "ğŸ¯ Layer: llamaforcausallm_model_layers_16_post_attention_layernorm\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-13T22:13:51.053995Z",
     "start_time": "2025-12-13T22:13:49.266008Z"
    }
   },
   "source": [
    "print(\"ğŸ“¥ Loading SAE model...\")\n",
    "sae = TopKSae.load(SAE_MODEL_PATH)\n",
    "sae.context.device = DEVICE\n",
    "sae.sae_engine.to(DEVICE)\n",
    "\n",
    "if layer_signature is None and sae.context.lm_layer_signature is not None:\n",
    "    layer_signature = sae.context.lm_layer_signature\n",
    "    print(f\"ğŸ“ Using layer signature from SAE context: {layer_signature}\")\n",
    "\n",
    "print(f\"âœ… SAE loaded\")\n",
    "print(f\"   Input dimension: {sae.context.n_inputs}\")\n",
    "print(f\"   Latent dimension: {sae.context.n_latents}\")\n",
    "print(f\"   TopK: {sae.k}\")\n",
    "print(f\"   Layer signature: {layer_signature}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¥ Loading SAE model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-13 23:13:51,046 [INFO] amber.mechanistic.sae.modules.topk_sae: \n",
      "Loaded TopKSAE from store/runs/training_20251213_005514/model.pt\n",
      "n_latents=6144, n_inputs=1536, k=8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… SAE loaded\n",
      "   Input dimension: 1536\n",
      "   Latent dimension: 6144\n",
      "   TopK: 8\n",
      "   Layer signature: llamaforcausallm_model_layers_16_post_attention_layernorm\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-13T22:13:51.084656Z",
     "start_time": "2025-12-13T22:13:51.063301Z"
    }
   },
   "source": [
    "print(\"ğŸ”— Attaching SAE to language model...\")\n",
    "if layer_signature is None:\n",
    "    print(\"âŒ Error: Layer signature is None. Cannot attach SAE.\")\n",
    "else:\n",
    "    hook_id = lm.layers.register_hook(layer_signature, sae)\n",
    "    print(f\"âœ… SAE attached to layer: {layer_signature}\")\n",
    "    print(f\"   Hook ID: {hook_id}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”— Attaching SAE to language model...\n",
      "âœ… SAE attached to layer: llamaforcausallm_model_layers_16_post_attention_layernorm\n",
      "   Hook ID: 547adbd3-be2c-4ef3-a7c0-821c4c1a4ecb\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-13T22:13:51.109877Z",
     "start_time": "2025-12-13T22:13:51.088390Z"
    }
   },
   "source": [
    "print(\"ğŸ“Š Enabling text tracking...\")\n",
    "sae.concepts.enable_text_tracking()\n",
    "print(\"âœ… Text tracking enabled\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š Enabling text tracking...\n",
      "âœ… Text tracking enabled\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-13T22:13:54.207692Z",
     "start_time": "2025-12-13T22:13:51.113572Z"
    }
   },
   "source": [
    "print(\"ğŸ“¥ Loading dataset...\")\n",
    "dataset = TextDataset.from_huggingface(\n",
    "    HF_DATASET,\n",
    "    split=DATA_SPLIT,\n",
    "    store=store,\n",
    "    text_field=TEXT_FIELD,\n",
    "    limit=DATA_LIMIT,\n",
    ")\n",
    "print(f\"âœ… Loaded {len(dataset)} text samples\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¥ Loading dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:00<00:00, 16155.24 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Loaded 32 text samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-13T22:14:15.350424Z",
     "start_time": "2025-12-13T22:13:54.217151Z"
    }
   },
   "source": [
    "print(\"ğŸš€ Running inference to collect top texts...\")\n",
    "print(f\"   Processing {len(dataset)} samples in batches of {BATCH_SIZE}\")\n",
    "\n",
    "with torch.inference_mode():\n",
    "    for batch_idx, batch in enumerate(dataset.iter_batches(BATCH_SIZE)):\n",
    "        texts = dataset.extract_texts_from_batch(batch)\n",
    "        lm.forwards(\n",
    "            texts,\n",
    "            tok_kwargs={\n",
    "                \"max_length\": MAX_LENGTH,\n",
    "                \"padding\": True,\n",
    "                \"truncation\": True,\n",
    "                \"add_special_tokens\": True\n",
    "            },\n",
    "            autocast=False,\n",
    "        )\n",
    "\n",
    "        print(f\"   Processed {batch_idx + 1} batches...\")\n",
    "\n",
    "print(\"âœ… Inference completed\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ Running inference to collect top texts...\n",
      "   Processing 32 samples in batches of 16\n",
      "   Processed 1 batches...\n",
      "   Processed 2 batches...\n",
      "âœ… Inference completed\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-13T22:14:23.618999Z",
     "start_time": "2025-12-13T22:14:15.364230Z"
    }
   },
   "source": [
    "print(\"ğŸ’¾ Exporting top texts...\")\n",
    "exported_path = sae.concepts.export_top_texts_to_json(TOP_TEXTS_FILE)\n",
    "print(f\"âœ… Top texts exported to: {exported_path}\")\n",
    "\n",
    "all_top_texts = sae.concepts.get_all_top_texts()\n",
    "neurons_with_texts = sum(1 for texts in all_top_texts if texts)\n",
    "total_texts = sum(len(texts) for texts in all_top_texts)\n",
    "\n",
    "print(f\"ğŸ“Š Statistics:\")\n",
    "print(f\"   Neurons with texts: {neurons_with_texts} / {sae.context.n_latents}\")\n",
    "print(f\"   Total texts collected: {total_texts}\")\n",
    "print(f\"   Average texts per neuron: {total_texts / sae.context.n_latents:.2f}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ’¾ Exporting top texts...\n",
      "âœ… Top texts exported to: store/runs/training_20251213_005514/top_texts.json\n",
      "ğŸ“Š Statistics:\n",
      "   Neurons with texts: 6144 / 6144\n",
      "   Total texts collected: 30720\n",
      "   Average texts per neuron: 5.00\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-13T22:14:23.632081Z",
     "start_time": "2025-12-13T22:14:23.630185Z"
    }
   },
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
