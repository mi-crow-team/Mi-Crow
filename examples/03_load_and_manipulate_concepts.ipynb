{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 3: Load Concepts and Demonstrate Neuron Manipulation\n",
    "\n",
    "This notebook demonstrates how to:\n",
    "1. Load the language model and trained SAE from previous examples\n",
    "2. Load curated concepts from the manual curation process\n",
    "3. Attach the concept dictionary to the SAE\n",
    "4. Demonstrate inference with manipulated neurons using the concepts\n",
    "\n",
    "This example shows how to use the curated concepts to understand and manipulate what each neuron represents in the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-26T21:21:55.653899Z",
     "start_time": "2025-10-26T21:21:55.630808Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "âœ… Imports completed\n"
     ]
    }
   ],
   "source": [
    "# Setup and imports\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "import json\n",
    "import csv\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "from amber.store import LocalStore\n",
    "from amber.adapters.text_snippet_dataset import TextSnippetDataset\n",
    "from amber.core.language_model import LanguageModel\n",
    "from amber.mechanistic.autoencoder.autoencoder import Autoencoder\n",
    "from amber.mechanistic.autoencoder.concepts.concept_dictionary import ConceptDictionary, Concept\n",
    "\n",
    "print(\"âœ… Imports completed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-26T21:21:55.676484Z",
     "start_time": "2025-10-26T21:21:55.658473Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Starting Concept Loading and Neuron Manipulation Example\n",
      "ðŸ”§ Model: sshleifer/tiny-gpt2\n",
      "ðŸŽ¯ Target layer: gpt2lmheadmodel_transformer_h_0_attn_c_attn\n",
      "ðŸ§  SAE model: outputs/sae_model.pt\n",
      "ðŸ“Š Curated concepts: outputs/curated_concepts.csv\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "print(\"ðŸš€ Starting Concept Loading and Neuron Manipulation Example\")\n",
    "\n",
    "# Load metadata from previous examples\n",
    "training_metadata_path = Path(\"outputs/training_metadata.json\")\n",
    "attachment_metadata_path = Path(\"outputs/attachment_metadata.json\")\n",
    "\n",
    "if not training_metadata_path.exists():\n",
    "    print(\"âŒ Error: training_metadata.json not found!\")\n",
    "    print(\"   Please run 01_train_sae_model.ipynb first\")\n",
    "    raise FileNotFoundError(\"training_metadata.json not found\")\n",
    "\n",
    "if not attachment_metadata_path.exists():\n",
    "    print(\"âŒ Error: attachment_metadata.json not found!\")\n",
    "    print(\"   Please run 02_attach_sae_and_save_texts.ipynb first\")\n",
    "    raise FileNotFoundError(\"attachment_metadata.json not found\")\n",
    "\n",
    "# Load metadata\n",
    "with open(training_metadata_path, \"r\") as f:\n",
    "    training_metadata = json.load(f)\n",
    "\n",
    "with open(attachment_metadata_path, \"r\") as f:\n",
    "    attachment_metadata = json.load(f)\n",
    "\n",
    "# Configuration from metadata\n",
    "MODEL_ID = training_metadata[\"model_id\"]\n",
    "LAYER_SIGNATURE = training_metadata[\"layer_signature\"]\n",
    "SAE_MODEL_PATH = Path(training_metadata[\"sae_model_path\"])\n",
    "CACHE_DIR = Path(training_metadata[\"cache_dir\"])\n",
    "STORE_DIR = Path(training_metadata[\"store_dir\"])\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Check for curated concepts\n",
    "CURATED_CONCEPTS_CSV = Path(\"outputs/curated_concepts.csv\")\n",
    "CURATED_CONCEPTS_JSON = Path(\"outputs/curated_concepts.json\")\n",
    "\n",
    "if not CURATED_CONCEPTS_CSV.exists() and not CURATED_CONCEPTS_JSON.exists():\n",
    "    print(\"âš ï¸ Warning: No curated concepts found!\")\n",
    "    print(\"   Please run the manual curation process first\")\n",
    "    print(\"   You can create a simple CSV with format: neuron_idx,concept_name,score\")\n",
    "\n",
    "print(f\"ðŸ”§ Model: {MODEL_ID}\")\n",
    "print(f\"ðŸŽ¯ Target layer: {LAYER_SIGNATURE}\")\n",
    "print(f\"ðŸ§  SAE model: {SAE_MODEL_PATH}\")\n",
    "print(f\"ðŸ“Š Curated concepts: {CURATED_CONCEPTS_CSV if CURATED_CONCEPTS_CSV.exists() else CURATED_CONCEPTS_JSON}\")\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-26T21:21:56.747886Z",
     "start_time": "2025-10-26T21:21:55.681294Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“¥ Loading language model...\n",
      "âœ… Model loaded: sshleifer/tiny-gpt2\n",
      "ðŸ“± Device: cpu\n",
      "ðŸ”§ Context: sae_attachment/attachment_20251026_222155\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Load language model\n",
    "print(\"ðŸ“¥ Loading language model...\")\n",
    "\n",
    "# Load model and move to device\n",
    "model = LanguageModel.from_huggingface(MODEL_ID)\n",
    "model.model.to(DEVICE)\n",
    "\n",
    "# Optional: set experiment metadata\n",
    "model.context.experiment_name = \"sae_attachment\"\n",
    "model.context.run_id = f\"attachment_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "model.context.max_length = 64\n",
    "\n",
    "print(f\"âœ… Model loaded: {model.model_id}\")\n",
    "print(f\"ðŸ“± Device: {DEVICE}\")\n",
    "print(f\"ðŸ”§ Context: {model.context.experiment_name}/{model.context.run_id}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-26T21:21:56.786847Z",
     "start_time": "2025-10-26T21:21:56.765288Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-26 22:21:56,785 [INFO] amber.mechanistic.autoencoder.autoencoder: \n",
      "Loaded model from outputs/sae_model.pt\n",
      "n_latents=24, n_inputs=6, activation=TopK_8, tied=False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“¥ Loading trained SAE...\n",
      "âœ… SAE loaded: 6 â†’ 24 â†’ 6\n",
      "ðŸ”§ Context: concept_manipulation/manipulation_20251026_222156\n",
      "ðŸ“Š Dataset normalization: False\n",
      "âœ… Trained SAE loaded\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Load trained SAE\n",
    "print(\"ðŸ“¥ Loading trained SAE...\")\n",
    "if not SAE_MODEL_PATH.exists():\n",
    "    print(f\"âŒ Error: SAE model not found at {SAE_MODEL_PATH}\")\n",
    "    print(\"   Please run 01_train_sae_model.ipynb first\")\n",
    "    raise FileNotFoundError(f\"SAE model not found at {SAE_MODEL_PATH}\")\n",
    "\n",
    "sae, dataset_normalize, dataset_target_norm, dataset_mean = Autoencoder.load_model(SAE_MODEL_PATH)\n",
    "sae.to(DEVICE)\n",
    "\n",
    "# Update SAE context with current experiment info\n",
    "sae.context.experiment_name = \"concept_manipulation\"\n",
    "sae.context.run_id = f\"manipulation_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "\n",
    "print(\n",
    "    f\"âœ… SAE loaded: {training_metadata['hidden_dim']} â†’ {training_metadata['n_latents']} â†’ {training_metadata['hidden_dim']}\")\n",
    "print(f\"ðŸ”§ Context: {sae.context.experiment_name}/{sae.context.run_id}\")\n",
    "print(f\"ðŸ“Š Dataset normalization: {dataset_normalize}\")\n",
    "print(\"âœ… Trained SAE loaded\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-26T21:21:56.809814Z",
     "start_time": "2025-10-26T21:21:56.790548Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“¥ Loading curated concepts...\n",
      "ðŸ“„ Loading from CSV: outputs/curated_concepts.csv\n",
      "âœ… Loaded concept dictionary with 24 neurons\n",
      "ðŸ“Š Total concepts: 60\n",
      "\n",
      "ðŸ” Sample concepts:\n",
      "   Neuron 0: 10 concepts\n",
      "     1. 'family relationships' (score: 0.900)\n",
      "     2. 'parent-child interactions' (score: 0.800)\n",
      "   Neuron 1: 10 concepts\n",
      "     1. 'nature and outdoors' (score: 0.900)\n",
      "     2. 'animals and wildlife' (score: 0.800)\n",
      "   Neuron 2: 10 concepts\n",
      "     1. 'problem solving' (score: 0.900)\n",
      "     2. 'logical thinking' (score: 0.800)\n",
      "   Neuron 3: 10 concepts\n",
      "     1. 'Mummy and Daddy were picking flowers in the garden. Mummy picked a red daisy, Daddy picked a purple ' (score: 0.006)\n",
      "     2. 'Once there was a generous bear. He liked to help others and was always very kind. But he had one hab' (score: 0.006)\n",
      "   Neuron 4: 10 concepts\n",
      "     1. 'Mummy and Daddy were picking flowers in the garden. Mummy picked a red daisy, Daddy picked a purple ' (score: 0.062)\n",
      "     2. 'Once there was a generous bear. He liked to help others and was always very kind. But he had one hab' (score: 0.062)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Load curated concepts\n",
    "print(\"ðŸ“¥ Loading curated concepts...\")\n",
    "\n",
    "# Try to load from CSV first, then JSON\n",
    "if CURATED_CONCEPTS_CSV.exists():\n",
    "    print(f\"ðŸ“„ Loading from CSV: {CURATED_CONCEPTS_CSV}\")\n",
    "    concept_dict = ConceptDictionary.from_csv(CURATED_CONCEPTS_CSV, n_size=training_metadata[\"n_latents\"])\n",
    "elif CURATED_CONCEPTS_JSON.exists():\n",
    "    print(f\"ðŸ“„ Loading from JSON: {CURATED_CONCEPTS_JSON}\")\n",
    "    concept_dict = ConceptDictionary.from_directory(CURATED_CONCEPTS_JSON.parent)\n",
    "else:\n",
    "    print(\"âš ï¸ No curated concepts found, creating example concepts...\")\n",
    "    # Create some example concepts for demonstration\n",
    "    concept_dict = ConceptDictionary(n_size=training_metadata[\"n_latents\"], max_concepts=5)\n",
    "\n",
    "    # Add some example concepts\n",
    "    concept_dict.add(0, \"family relationships\", 0.9)\n",
    "    concept_dict.add(0, \"parent-child interactions\", 0.8)\n",
    "    concept_dict.add(1, \"nature and outdoors\", 0.9)\n",
    "    concept_dict.add(1, \"animals and wildlife\", 0.8)\n",
    "    concept_dict.add(2, \"problem solving\", 0.9)\n",
    "    concept_dict.add(2, \"logical thinking\", 0.8)\n",
    "    concept_dict.add(3, \"emotional expressions\", 0.9)\n",
    "    concept_dict.add(3, \"feelings and moods\", 0.8)\n",
    "\n",
    "print(f\"âœ… Loaded concept dictionary with {concept_dict.n_size} neurons\")\n",
    "print(f\"ðŸ“Š Total concepts: {sum(len(concept_dict.get(i)) for i in range(concept_dict.n_size))}\")\n",
    "\n",
    "# Show some concepts\n",
    "print(\"\\nðŸ” Sample concepts:\")\n",
    "for neuron_idx in range(min(5, concept_dict.n_size)):\n",
    "    concepts = concept_dict.get(neuron_idx)\n",
    "    if concepts:\n",
    "        print(f\"   Neuron {neuron_idx}: {len(concepts)} concepts\")\n",
    "        for i, concept in enumerate(concepts[:2]):\n",
    "            print(f\"     {i + 1}. '{concept.name}' (score: {concept.score:.3f})\")\n",
    "    else:\n",
    "        print(f\"   Neuron {neuron_idx}: no concepts\")\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-26T21:21:56.832925Z",
     "start_time": "2025-10-26T21:21:56.813250Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”— Attaching concept dictionary to SAE...\n",
      "âœ… Concept dictionary attached to SAE\n",
      "ðŸ”§ SAE now has access to 60 concepts\n",
      "ðŸ“Š Concepts available for 6 neurons\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Attach concept dictionary to SAE\n",
    "print(\"ðŸ”— Attaching concept dictionary to SAE...\")\n",
    "\n",
    "# Set the language model and layer signature on the SAE's context\n",
    "sae.context.lm = model\n",
    "sae.context.lm_layer_signature = LAYER_SIGNATURE\n",
    "\n",
    "# Attach the concept dictionary to the SAE\n",
    "sae.concepts.dictionary = concept_dict\n",
    "\n",
    "print(\"âœ… Concept dictionary attached to SAE\")\n",
    "print(f\"ðŸ”§ SAE now has access to {sum(len(concept_dict.get(i)) for i in range(concept_dict.n_size))} concepts\")\n",
    "print(f\"ðŸ“Š Concepts available for {sum(1 for i in range(concept_dict.n_size) if concept_dict.get(i))} neurons\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-26T21:27:30.225692Z",
     "start_time": "2025-10-26T21:27:30.200574Z"
    }
   },
   "outputs": [],
   "source": [
    "test_texts = [\n",
    "    \"The family went to the park together.\",\n",
    "    \"The cat sat on the tree branch.\",\n",
    "    \"She solved the math problem quickly.\",\n",
    "    \"The child felt happy and excited.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-26T21:21:56.868255Z",
     "start_time": "2025-10-26T21:21:56.836027Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ¯ Demonstrating neuron manipulation using sae.concepts methods...\n",
      "ðŸ“ Test texts:\n",
      "   1. \"The family went to the park together.\"\n",
      "   2. \"The cat sat on the tree branch.\"\n",
      "   3. \"She solved the math problem quickly.\"\n",
      "   4. \"The child felt happy and excited.\"\n",
      "\n",
      "ðŸ” Running baseline inference...\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'gpt2lmheadmodel_transformer_h_0_attn_c_attn'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[70]\u001b[39m\u001b[32m, line 23\u001b[39m\n\u001b[32m     20\u001b[39m baseline_output, baseline_activations = model.forwards(test_texts)\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# Get SAE activations for the target layer\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m sae_input = \u001b[43mbaseline_activations\u001b[49m\u001b[43m[\u001b[49m\u001b[43mLAYER_SIGNATURE\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     24\u001b[39m sae_output = sae(sae_input)\n\u001b[32m     25\u001b[39m baseline_sae_activations = sae_output[\u001b[32m1\u001b[39m]  \u001b[38;5;66;03m# Get latent activations\u001b[39;00m\n",
      "\u001b[31mKeyError\u001b[39m: 'gpt2lmheadmodel_transformer_h_0_attn_c_attn'"
     ]
    }
   ],
   "source": [
    "# Step 5: Demonstrate neuron manipulation using sae.concepts methods\n",
    "print(\"ðŸŽ¯ Demonstrating neuron manipulation using sae.concepts methods...\")\n",
    "\n",
    "# Test texts for inference\n",
    "\n",
    "\n",
    "print(f\"ðŸ“ Test texts:\")\n",
    "for i, text in enumerate(test_texts):\n",
    "    print(f\"   {i+1}. \\\"{text}\\\"\")\n",
    "print()\n",
    "\n",
    "# Run inference to get baseline activations\n",
    "print(\"ðŸ” Running baseline inference...\")\n",
    "with torch.no_grad():\n",
    "    baseline_output, baseline_activations = model.forwards(test_texts)\n",
    "\n",
    "    # Get SAE activations for the target layer\n",
    "    sae_input = baseline_activations[LAYER_SIGNATURE]\n",
    "    sae_output = sae(sae_input)\n",
    "    baseline_sae_activations = sae_output[1]  # Get latent activations\n",
    "\n",
    "print(f\"âœ… Baseline inference completed\")\n",
    "print(f\"ðŸ“Š SAE activations shape: {baseline_sae_activations.shape}\")\n",
    "print()\n",
    "\n",
    "# Show which neurons are most active for each text\n",
    "print(\"ðŸ§  Most active neurons for each text:\")\n",
    "for i, text in enumerate(test_texts):\n",
    "    activations = baseline_sae_activations[i]\n",
    "    top_neurons = torch.topk(activations, k=3)\n",
    "\n",
    "    print(f\"   Text {i+1}: \\\"{text}\\\"\")\n",
    "    for j, (neuron_idx, activation) in enumerate(zip(top_neurons.indices, top_neurons.values)):\n",
    "        concepts = concept_dict.get(neuron_idx.item())\n",
    "        concept_names = [c.name for c in concepts] if concepts else [\"no concepts\"]\n",
    "        print(f\"     {j+1}. Neuron {neuron_idx.item()}: {activation:.4f} - {concept_names}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-26T21:27:02.675931Z",
     "start_time": "2025-10-26T21:27:02.626459Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”§ Demonstrating concept manipulation using multiply_concept method...\n",
      "\n",
      "ðŸ“ˆ Using multiply_concept to manipulate concepts\n",
      "   ðŸŽ¯ Boosting neuron 0 (family concepts) by 2.0x using multiply_concept\n",
      "   ðŸŽ¯ Boosting neuron 1 (nature concepts) by 3.0x using multiply_concept\n",
      "   ðŸŽ¯ Suppressing neuron 2 (problem concepts) by 0.5x using multiply_concept\n",
      "   ðŸŽ¯ Boosting neuron 3 (emotional concepts) by 1.5x using multiply_concept\n",
      "\n",
      "ðŸ” Running inference with multiply_concept manipulation...\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'gpt2lmheadmodel_transformer_h_0_attn_c_attn'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[71]\u001b[39m\u001b[32m, line 36\u001b[39m\n\u001b[32m     33\u001b[39m manipulated_output, manipulated_activations = model.forwards(test_texts)\n\u001b[32m     35\u001b[39m \u001b[38;5;66;03m# Get SAE activations for the target layer\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m sae_input = \u001b[43mmanipulated_activations\u001b[49m\u001b[43m[\u001b[49m\u001b[43mLAYER_SIGNATURE\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     37\u001b[39m sae_output = sae(sae_input)\n\u001b[32m     38\u001b[39m manipulated_sae_activations = sae_output[\u001b[32m1\u001b[39m]  \u001b[38;5;66;03m# Get latent activations\u001b[39;00m\n",
      "\u001b[31mKeyError\u001b[39m: 'gpt2lmheadmodel_transformer_h_0_attn_c_attn'"
     ]
    }
   ],
   "source": [
    "# Step 6: Concept manipulation using manipulate_concept method\n",
    "print(\"ðŸ”§ Demonstrating concept manipulation using manipulate_concept method...\")\n",
    "\n",
    "# Method: Using manipulate_concept to boost/suppress specific concepts\n",
    "print(\"\\nðŸ“ˆ Using manipulate_concept to manipulate concepts\")\n",
    "\n",
    "# Reset multiplication to 1.0 for all neurons\n",
    "sae.concepts.multiplication.data.fill_(1.0)\n",
    "\n",
    "# Boost family-related concepts (neuron 0)\n",
    "family_boost = 2.0\n",
    "sae.concepts.manipulate_concept(0, multiplier=family_boost)\n",
    "print(f\"   ðŸŽ¯ Boosting neuron 0 (family concepts) by {family_boost}x using manipulate_concept\")\n",
    "\n",
    "# Boost nature-related concepts (neuron 1) \n",
    "nature_boost = 3.0\n",
    "sae.concepts.manipulate_concept(1, multiplier=nature_boost)\n",
    "print(f\"   ðŸŽ¯ Boosting neuron 1 (nature concepts) by {nature_boost}x using manipulate_concept\")\n",
    "\n",
    "# Suppress problem-solving concepts (neuron 2)\n",
    "problem_suppress = 0.5\n",
    "sae.concepts.manipulate_concept(2, multiplier=problem_suppress)\n",
    "print(f\"   ðŸŽ¯ Suppressing neuron 2 (problem concepts) by {problem_suppress}x using manipulate_concept\")\n",
    "\n",
    "# Boost emotional concepts (neuron 3)\n",
    "emotional_boost = 1.5\n",
    "sae.concepts.manipulate_concept(3, multiplier=emotional_boost)\n",
    "print(f\"   ðŸŽ¯ Boosting neuron 3 (emotional concepts) by {emotional_boost}x using manipulate_concept\")\n",
    "\n",
    "# Run inference with manipulated concepts\n",
    "print(\"\\nðŸ” Running inference with manipulate_concept manipulation...\")\n",
    "with torch.no_grad():\n",
    "    manipulated_output, manipulated_activations = model.forwards(test_texts)\n",
    "    \n",
    "    # Get SAE activations for the target layer\n",
    "    sae_input = manipulated_activations[LAYER_SIGNATURE]\n",
    "    sae_output = sae(sae_input)\n",
    "    manipulated_sae_activations = sae_output[1]  # Get latent activations\n",
    "\n",
    "print(f\"âœ… manipulate_concept manipulation inference completed\")\n",
    "\n",
    "# Compare original vs manipulated activations\n",
    "print(\"\\nðŸ“Š Comparison: Original vs manipulate_concept Manipulated\")\n",
    "for i, text in enumerate(test_texts):\n",
    "    print(f\"\\n   Text {i+1}: \\\"{text}\\\"\")\n",
    "    \n",
    "    # Original activations\n",
    "    original_activations = baseline_sae_activations[i]\n",
    "    top_original = torch.topk(original_activations, k=3)\n",
    "    \n",
    "    print(f\"   ðŸ“ˆ Original top neurons:\")\n",
    "    for j, (neuron_idx, activation) in enumerate(zip(top_original.indices, top_original.values)):\n",
    "        concepts = concept_dict.get(neuron_idx.item())\n",
    "        concept_names = [c.name for c in concepts] if concepts else [\"no concepts\"]\n",
    "        print(f\"     {j+1}. Neuron {neuron_idx.item()}: {activation:.4f} - {concept_names}\")\n",
    "    \n",
    "    # Manipulated activations\n",
    "    manipulated_activations_text = manipulated_sae_activations[i]\n",
    "    top_manipulated = torch.topk(manipulated_activations_text, k=3)\n",
    "    \n",
    "    print(f\"   ðŸš€ manipulate_concept manipulated top neurons:\")\n",
    "    for j, (neuron_idx, activation) in enumerate(zip(top_manipulated.indices, top_manipulated.values)):\n",
    "        concepts = concept_dict.get(neuron_idx.item())\n",
    "        concept_names = [c.name for c in concepts] if concepts else [\"no concepts\"]\n",
    "        print(f\"     {j+1}. Neuron {neuron_idx.item()}: {activation:.4f} - {concept_names}\")\n",
    "    \n",
    "    # Show changes\n",
    "    activation_changes = (manipulated_activations_text - original_activations).abs()\n",
    "    top_changes = torch.topk(activation_changes, k=3)\n",
    "    print(f\"   ðŸ”„ Biggest changes:\")\n",
    "    for j, (neuron_idx, change) in enumerate(zip(top_changes.indices, top_changes.values)):\n",
    "        concepts = concept_dict.get(neuron_idx.item())\n",
    "        concept_names = [c.name for c in concepts] if concepts else [\"no concepts\"]\n",
    "        print(f\"     {j+1}. Neuron {neuron_idx.item()}: +{change:.4f} - {concept_names}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: Advanced manipulate_concept scenarios\n",
    "print(\"\\nðŸ”§ Advanced manipulate_concept scenarios\")\n",
    "\n",
    "# Reset multiplication to 1.0 for all neurons\n",
    "sae.concepts.multiplication.data.fill_(1.0)\n",
    "\n",
    "# Scenario 1: Boost multiple related concepts\n",
    "print(\"\\nðŸ“ˆ Scenario 1: Boost multiple related concepts\")\n",
    "sae.concepts.manipulate_concept(0, multiplier=2.5)  # Family concepts\n",
    "sae.concepts.manipulate_concept(1, multiplier=2.0)  # Nature concepts\n",
    "print(\"   ðŸŽ¯ Boosted family and nature concepts together\")\n",
    "\n",
    "# Run inference for scenario 1\n",
    "print(\"\\nðŸ” Running inference for scenario 1...\")\n",
    "with torch.no_grad():\n",
    "    scenario1_output, scenario1_activations = model.forwards(test_texts)\n",
    "    sae_input = scenario1_activations[LAYER_SIGNATURE]\n",
    "    sae_output = sae(sae_input)\n",
    "    scenario1_sae_activations = sae_output[1]\n",
    "\n",
    "# Scenario 2: Suppress specific concepts\n",
    "print(\"\\nðŸ“‰ Scenario 2: Suppress specific concepts\")\n",
    "sae.concepts.multiplication.data.fill_(1.0)  # Reset\n",
    "sae.concepts.manipulate_concept(2, multiplier=0.3)  # Suppress problem-solving\n",
    "sae.concepts.manipulate_concept(3, multiplier=0.4)  # Suppress emotional\n",
    "print(\"   ðŸŽ¯ Suppressed problem-solving and emotional concepts\")\n",
    "\n",
    "# Run inference for scenario 2\n",
    "print(\"\\nðŸ” Running inference for scenario 2...\")\n",
    "with torch.no_grad():\n",
    "    scenario2_output, scenario2_activations = model.forwards(test_texts)\n",
    "    sae_input = scenario2_activations[LAYER_SIGNATURE]\n",
    "    sae_output = sae(sae_input)\n",
    "    scenario2_sae_activations = sae_output[1]\n",
    "\n",
    "# Scenario 3: Mixed boost/suppress\n",
    "print(\"\\nðŸŽ›ï¸ Scenario 3: Mixed boost/suppress\")\n",
    "sae.concepts.multiplication.data.fill_(1.0)  # Reset\n",
    "sae.concepts.manipulate_concept(0, multiplier=3.0)  # Strong boost family\n",
    "sae.concepts.manipulate_concept(1, multiplier=0.2)  # Strong suppress nature\n",
    "sae.concepts.manipulate_concept(2, multiplier=1.5)  # Moderate boost problem-solving\n",
    "sae.concepts.manipulate_concept(3, multiplier=0.8)  # Slight suppress emotional\n",
    "print(\"   ðŸŽ¯ Mixed manipulation: boost family/problem, suppress nature/emotional\")\n",
    "\n",
    "# Run inference for scenario 3\n",
    "print(\"\\nðŸ” Running inference for scenario 3...\")\n",
    "with torch.no_grad():\n",
    "    scenario3_output, scenario3_activations = model.forwards(test_texts)\n",
    "    sae_input = scenario3_activations[LAYER_SIGNATURE]\n",
    "    sae_output = sae(sae_input)\n",
    "    scenario3_sae_activations = sae_output[1]\n",
    "\n",
    "print(f\"âœ… All manipulate_concept scenarios completed\")\n",
    "\n",
    "# Show results for each scenario\n",
    "print(\"\\nðŸ“Š Results Summary:\")\n",
    "scenarios = [\n",
    "    (\"Baseline\", baseline_sae_activations),\n",
    "    (\"Scenario 1: Boost family+nature\", scenario1_sae_activations),\n",
    "    (\"Scenario 2: Suppress problem+emotional\", scenario2_sae_activations),\n",
    "    (\"Scenario 3: Mixed manipulation\", scenario3_sae_activations)\n",
    "]\n",
    "\n",
    "for scenario_name, activations in scenarios:\n",
    "    print(f\"\\n   {scenario_name}:\")\n",
    "    for i, text in enumerate(test_texts):\n",
    "        text_activations = activations[i]\n",
    "        top_neurons = torch.topk(text_activations, k=2)\n",
    "        \n",
    "        print(f\"     Text {i+1}: \\\"{text[:30]}...\\\"\")\n",
    "        for j, (neuron_idx, activation) in enumerate(zip(top_neurons.indices, top_neurons.values)):\n",
    "            concepts = concept_dict.get(neuron_idx.item())\n",
    "            concept_names = [c.name for c in concepts] if concepts else [\"no concepts\"]\n",
    "            print(f\"       {j+1}. Neuron {neuron_idx.item()}: {activation:.4f} - {concept_names}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 8: multiply_concept parameter inspection and summary\n",
    "print(\"\\nðŸ”§ multiply_concept parameter inspection and summary\")\n",
    "\n",
    "# Show current concept manipulation parameters\n",
    "print(\"\\nðŸ“Š Current multiply_concept parameters:\")\n",
    "print(\"   ðŸŽ›ï¸ Multiplication parameters:\")\n",
    "for i in range(min(8, sae.concepts.multiplication.shape[0])):\n",
    "    concepts = concept_dict.get(i)\n",
    "    concept_names = [c.name for c in concepts] if concepts else [\"no concepts\"]\n",
    "    mult_val = sae.concepts.multiplication.data[i].item()\n",
    "    print(f\"     Neuron {i}: {mult_val:.2f}x - {concept_names}\")\n",
    "\n",
    "# Demonstrate resetting parameters\n",
    "print(\"\\nðŸ”„ Resetting all multiply_concept parameters to 1.0...\")\n",
    "sae.concepts.multiplication.data.fill_(1.0)\n",
    "\n",
    "print(\"   âœ… All parameters reset to 1.0 (no manipulation)\")\n",
    "\n",
    "# Show reset parameters\n",
    "print(\"\\nðŸ“Š Reset multiply_concept parameters:\")\n",
    "for i in range(min(8, sae.concepts.multiplication.shape[0])):\n",
    "    concepts = concept_dict.get(i)\n",
    "    concept_names = [c.name for c in concepts] if concepts else [\"no concepts\"]\n",
    "    mult_val = sae.concepts.multiplication.data[i].item()\n",
    "    print(f\"     Neuron {i}: {mult_val:.2f}x - {concept_names}\")\n",
    "\n",
    "print(\"\\nâœ… multiply_concept demonstration completed!\")\n",
    "print(\"ðŸ’¡ This shows how you can use multiply_concept to:\")\n",
    "print(\"   1. Boost specific concepts by multiplying activations (multiplier > 1.0)\")\n",
    "print(\"   2. Suppress specific concepts by reducing activations (multiplier < 1.0)\")\n",
    "print(\"   3. Apply different multipliers to different neurons simultaneously\")\n",
    "print(\"   4. Reset all parameters to 1.0 to return to baseline behavior\")\n",
    "print(\"   5. Use this for fine-grained control of model behavior based on concepts\")\n",
    "print(\"   6. Manipulate model outputs for interpretability and controlled generation\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
