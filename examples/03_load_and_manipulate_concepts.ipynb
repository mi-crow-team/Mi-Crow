{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 3: Load Concepts and Demonstrate Activation Manipulation\n",
    "\n",
    "This notebook demonstrates how to:\n",
    "1. Load the language model and trained SAE from previous examples\n",
    "2. Load curated concepts from the manual curation process\n",
    "3. Attach the concept dictionary to the SAE\n",
    "4. Demonstrate inference with manipulated activations\n",
    "5. Create custom activation controllers to amplify or suppress specific concepts\n",
    "\n",
    "This example shows how to use curated concepts to understand and control what the model generates.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-01T00:19:11.995198Z",
     "start_time": "2025-11-01T00:19:11.969724Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "‚úÖ Imports completed\n"
     ]
    }
   ],
   "source": [
    "# Setup and imports\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "import json\n",
    "import csv\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "from amber.store import LocalStore\n",
    "from amber.adapters.text_snippet_dataset import TextSnippetDataset\n",
    "from amber.core.language_model import LanguageModel\n",
    "from amber.mechanistic.autoencoder.autoencoder import Autoencoder\n",
    "from amber.mechanistic.autoencoder.concepts.concept_dictionary import ConceptDictionary, Concept\n",
    "from amber.hooks import Controller, HookType\n",
    "\n",
    "print(\"‚úÖ Imports completed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-01T00:19:12.021999Z",
     "start_time": "2025-11-01T00:19:12.000453Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starting Concept Loading and Neuron Manipulation Example\n",
      "üîß Model: sshleifer/tiny-gpt2\n",
      "üéØ Target layer: gpt2lmheadmodel_transformer_h_0_attn_c_attn\n",
      "üß† SAE model: outputs/sae_model.pt\n",
      "üìä Curated concepts: outputs/curated_concepts.csv\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "print(\"üöÄ Starting Concept Loading and Neuron Manipulation Example\")\n",
    "\n",
    "# Load metadata from previous examples\n",
    "training_metadata_path = Path(\"outputs/training_metadata.json\")\n",
    "attachment_metadata_path = Path(\"outputs/attachment_metadata.json\")\n",
    "\n",
    "if not training_metadata_path.exists():\n",
    "    print(\"‚ùå Error: training_metadata.json not found!\")\n",
    "    print(\"   Please run 01_train_sae_model.ipynb first\")\n",
    "    raise FileNotFoundError(\"training_metadata.json not found\")\n",
    "\n",
    "if not attachment_metadata_path.exists():\n",
    "    print(\"‚ùå Error: attachment_metadata.json not found!\")\n",
    "    print(\"   Please run 02_attach_sae_and_save_texts.ipynb first\")\n",
    "    raise FileNotFoundError(\"attachment_metadata.json not found\")\n",
    "\n",
    "# Load metadata\n",
    "with open(training_metadata_path, \"r\") as f:\n",
    "    training_metadata = json.load(f)\n",
    "\n",
    "with open(attachment_metadata_path, \"r\") as f:\n",
    "    attachment_metadata = json.load(f)\n",
    "\n",
    "# Configuration from metadata\n",
    "MODEL_ID = training_metadata[\"model_id\"]\n",
    "LAYER_SIGNATURE = training_metadata[\"layer_signature\"]\n",
    "SAE_MODEL_PATH = Path(training_metadata[\"sae_model_path\"])\n",
    "CACHE_DIR = Path(training_metadata[\"cache_dir\"])\n",
    "STORE_DIR = Path(training_metadata[\"store_dir\"])\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Check for curated concepts\n",
    "CURATED_CONCEPTS_CSV = Path(\"outputs/curated_concepts.csv\")\n",
    "\n",
    "if not CURATED_CONCEPTS_CSV.exists() and not CURATED_CONCEPTS_JSON.exists():\n",
    "    print(\"‚ö†Ô∏è Warning: No curated concepts found!\")\n",
    "    print(\"   Please run the manual curation process first\")\n",
    "    print(\"   You can create a simple CSV with format: neuron_idx,concept_name,score\")\n",
    "\n",
    "print(f\"üîß Model: {MODEL_ID}\")\n",
    "print(f\"üéØ Target layer: {LAYER_SIGNATURE}\")\n",
    "print(f\"üß† SAE model: {SAE_MODEL_PATH}\")\n",
    "print(f\"üìä Curated concepts: {CURATED_CONCEPTS_CSV if CURATED_CONCEPTS_CSV.exists() else CURATED_CONCEPTS_JSON}\")\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-01T00:19:13.014208Z",
     "start_time": "2025-11-01T00:19:12.026287Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì• Loading language model...\n",
      "‚úÖ Model loaded: sshleifer_tiny-gpt2\n",
      "üì± Device: cpu\n",
      "üîß Context: sae_attachment/attachment_20251101_011913\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Load language model\n",
    "print(\"üì• Loading language model...\")\n",
    "\n",
    "# Load model and move to device\n",
    "model = LanguageModel.from_huggingface(MODEL_ID)\n",
    "model.model.to(DEVICE)\n",
    "\n",
    "# Optional: set experiment metadata\n",
    "model.context.experiment_name = \"sae_attachment\"\n",
    "model.context.run_id = f\"attachment_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "model.context.max_length = 64\n",
    "\n",
    "print(f\"‚úÖ Model loaded: {model.model_id}\")\n",
    "print(f\"üì± Device: {DEVICE}\")\n",
    "print(f\"üîß Context: {model.context.experiment_name}/{model.context.run_id}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-01T00:19:13.056629Z",
     "start_time": "2025-11-01T00:19:13.032795Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-01 01:19:13,054 [INFO] amber.mechanistic.autoencoder.autoencoder: \n",
      "Loaded model from outputs/sae_model.pt\n",
      "n_latents=24, n_inputs=6, activation=TopK_8, tied=False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì• Loading trained SAE...\n",
      "‚úÖ SAE loaded: 6 ‚Üí 24 ‚Üí 6\n",
      "üîß Context: concept_manipulation/manipulation_20251101_011913\n",
      "üìä Dataset normalization: False\n",
      "‚úÖ Trained SAE loaded\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Load trained SAE\n",
    "print(\"üì• Loading trained SAE...\")\n",
    "if not SAE_MODEL_PATH.exists():\n",
    "    print(f\"‚ùå Error: SAE model not found at {SAE_MODEL_PATH}\")\n",
    "    print(\"   Please run 01_train_sae_model.ipynb first\")\n",
    "    raise FileNotFoundError(f\"SAE model not found at {SAE_MODEL_PATH}\")\n",
    "\n",
    "sae, dataset_normalize, dataset_target_norm, dataset_mean = Autoencoder.load_model(SAE_MODEL_PATH)\n",
    "sae.to(DEVICE)\n",
    "\n",
    "# Update SAE context with current experiment info\n",
    "sae.context.experiment_name = \"concept_manipulation\"\n",
    "sae.context.run_id = f\"manipulation_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "\n",
    "print(\n",
    "    f\"‚úÖ SAE loaded: {training_metadata['hidden_dim']} ‚Üí {training_metadata['n_latents']} ‚Üí {training_metadata['hidden_dim']}\")\n",
    "print(f\"üîß Context: {sae.context.experiment_name}/{sae.context.run_id}\")\n",
    "print(f\"üìä Dataset normalization: {dataset_normalize}\")\n",
    "print(\"‚úÖ Trained SAE loaded\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-01T00:19:13.080805Z",
     "start_time": "2025-11-01T00:19:13.061440Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì• Loading curated concepts...\n",
      "üìÑ Loading from CSV: outputs/curated_concepts.csv\n",
      "‚úÖ Loaded concept dictionary with 24 neurons\n",
      "üìä Total concepts: 60\n",
      "\n",
      "üîç Sample concepts:\n",
      "   Neuron 0: 10 concepts\n",
      "     1. 'family relationships' (score: 0.900)\n",
      "     2. 'parent-child interactions' (score: 0.800)\n",
      "   Neuron 1: 10 concepts\n",
      "     1. 'nature and outdoors' (score: 0.900)\n",
      "     2. 'animals and wildlife' (score: 0.800)\n",
      "   Neuron 2: 10 concepts\n",
      "     1. 'problem solving' (score: 0.900)\n",
      "     2. 'logical thinking' (score: 0.800)\n",
      "   Neuron 3: 10 concepts\n",
      "     1. 'Mummy and Daddy were picking flowers in the garden. Mummy picked a red daisy, Daddy picked a purple ' (score: 0.006)\n",
      "     2. 'Once there was a generous bear. He liked to help others and was always very kind. But he had one hab' (score: 0.006)\n",
      "   Neuron 4: 10 concepts\n",
      "     1. 'Mummy and Daddy were picking flowers in the garden. Mummy picked a red daisy, Daddy picked a purple ' (score: 0.062)\n",
      "     2. 'Once there was a generous bear. He liked to help others and was always very kind. But he had one hab' (score: 0.062)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Load curated concepts\n",
    "print(\"üì• Loading curated concepts...\")\n",
    "\n",
    "# Try to load from CSV first, then JSON\n",
    "if CURATED_CONCEPTS_CSV.exists():\n",
    "    print(f\"üìÑ Loading from CSV: {CURATED_CONCEPTS_CSV}\")\n",
    "    concept_dict = ConceptDictionary.from_csv(CURATED_CONCEPTS_CSV, n_size=training_metadata[\"n_latents\"])\n",
    "else:\n",
    "    print(f\"CSV not found\")\n",
    "print(f\"‚úÖ Loaded concept dictionary with {concept_dict.n_size} neurons\")\n",
    "print(f\"üìä Total concepts: {sum(len(concept_dict.get(i)) for i in range(concept_dict.n_size))}\")\n",
    "\n",
    "# Show some concepts\n",
    "print(\"\\nüîç Sample concepts:\")\n",
    "for neuron_idx in range(min(5, concept_dict.n_size)):\n",
    "    concepts = concept_dict.get(neuron_idx)\n",
    "    if concepts:\n",
    "        print(f\"   Neuron {neuron_idx}: {len(concepts)} concepts\")\n",
    "        for i, concept in enumerate(concepts[:2]):\n",
    "            print(f\"     {i + 1}. '{concept.name}' (score: {concept.score:.3f})\")\n",
    "    else:\n",
    "        print(f\"   Neuron {neuron_idx}: no concepts\")\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-01T00:19:13.101936Z",
     "start_time": "2025-11-01T00:19:13.084707Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîó Attaching concept dictionary to SAE...\n",
      "‚úÖ Concept dictionary attached to SAE\n",
      "üîß SAE now has access to 60 concepts\n",
      "üìä Concepts available for 6 neurons\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Attach concept dictionary to SAE\n",
    "print(\"üîó Attaching concept dictionary to SAE...\")\n",
    "\n",
    "# Set the language model and layer signature on the SAE's context\n",
    "sae.context.lm = model\n",
    "sae.context.lm_layer_signature = LAYER_SIGNATURE\n",
    "\n",
    "# Attach the concept dictionary to the SAE\n",
    "sae.concepts.dictionary = concept_dict\n",
    "\n",
    "print(\"‚úÖ Concept dictionary attached to SAE\")\n",
    "print(f\"üîß SAE now has access to {sum(len(concept_dict.get(i)) for i in range(concept_dict.n_size))} concepts\")\n",
    "print(f\"üìä Concepts available for {sum(1 for i in range(concept_dict.n_size) if concept_dict.get(i))} neurons\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-01T00:19:13.123034Z",
     "start_time": "2025-11-01T00:19:13.105624Z"
    }
   },
   "outputs": [],
   "source": [
    "test_texts = [\n",
    "    \"The family went to the park together.\",\n",
    "    \"The cat sat on the tree branch.\",\n",
    "    \"She solved the math problem quickly.\",\n",
    "    \"The child felt happy and excited.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-01T00:19:13.127201Z",
     "start_time": "2025-11-01T00:19:13.125893Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
