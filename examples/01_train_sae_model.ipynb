{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 1: Training TopKSAE Model\n",
    "\n",
    "This notebook demonstrates how to:\n",
    "1. Load a language model and dataset\n",
    "2. Save activations from a specific layer\n",
    "3. Train a TopK Sparse Autoencoder (TopKSAE) on those activations using the new `SaeTrainer` composite class\n",
    "4. Save the trained TopKSAE model\n",
    "\n",
    "The training uses overcomplete's `train_sae` functions via the `SaeTrainer` composite class, which is automatically available on all SAE instances via `sae.trainer`.\n",
    "\n",
    "All files (trained TopKSAE model, training metadata, activations) will be saved under `store/{model_id}/` for organized, model-specific storage.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T20:20:17.192711Z",
     "start_time": "2025-11-10T20:20:17.050834Z"
    }
   },
   "source": [
    "# Setup and imports\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "from amber.store import LocalStore\n",
    "from amber.adapters import TextDataset\n",
    "from amber.core.language_model import LanguageModel\n",
    "from amber.mechanistic.autoencoder.modules.topk_sae import TopKSae, TopKSAETrainingConfig\n",
    "from amber.mechanistic.autoencoder.sae_trainer import SaeTrainingConfig  # Can also use SaeTrainingConfig directly\n",
    "\n",
    "print(\"‚úÖ Imports completed\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "‚úÖ Imports completed\n"
     ]
    }
   ],
   "execution_count": 107
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T20:20:17.226979Z",
     "start_time": "2025-11-10T20:20:17.197383Z"
    }
   },
   "source": [
    "# Configuration\n",
    "MODEL_ID = \"sshleifer/tiny-gpt2\"  # Small model for quick experimentation\n",
    "HF_DATASET = \"roneneldan/TinyStories\"\n",
    "DATA_SPLIT = \"train\"\n",
    "TEXT_FIELD = \"text\"\n",
    "DATA_LIMIT = 1000  # Number of text samples to use\n",
    "MAX_LENGTH = 64  # Maximum sequence length\n",
    "BATCH_SIZE_SAVE = 16  # Batch size for saving activations\n",
    "BATCH_SIZE_TRAIN = 32  # Batch size for SAE training\n",
    "\n",
    "# TopKSAE configuration\n",
    "TOP_K = 8  # Number of top activations to keep (sparsity parameter)\n",
    "\n",
    "# Choose which layer to hook - you can inspect available layers with model.layers.print_layer_names()\n",
    "LAYER_SIGNATURE = 'gpt2lmheadmodel_transformer_h_0_attn_c_attn'  # Attention layer (better activations)\n",
    "\n",
    "# Storage locations - will be updated after model loading to use model_id\n",
    "STORE_DIR = Path(\"store\")\n",
    "CACHE_DIR = Path(\"store/cache\")\n",
    "RUN_ID = f\"topk_sae_training_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "# Model-specific paths will be set after loading the model\n",
    "SAE_MODEL_PATH = None  # Will be set to store/{model_id}/topk_sae_model.pt\n",
    "METADATA_PATH = None  # Will be set to store/{model_id}/training_metadata.json\n",
    "\n",
    "# Device configuration\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "DTYPE = torch.float16 if torch.cuda.is_available() else None  # Use half precision on GPU\n",
    "\n",
    "print(\"üöÄ Starting TopKSAE Training Example\")\n",
    "print(f\"üì± Using device: {DEVICE}\")\n",
    "print(f\"üîß Model: {MODEL_ID}\")\n",
    "print(f\"üìä Dataset: {HF_DATASET}\")\n",
    "print(f\"üéØ Target layer: {LAYER_SIGNATURE}\")\n",
    "print(f\"üî¢ TopK parameter: {TOP_K}\")\n",
    "print()\n",
    "\n",
    "# Create output directories\n",
    "CACHE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "STORE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "print(\"‚úÖ Output directories created\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starting TopKSAE Training Example\n",
      "üì± Using device: cpu\n",
      "üîß Model: sshleifer/tiny-gpt2\n",
      "üìä Dataset: roneneldan/TinyStories\n",
      "üéØ Target layer: gpt2lmheadmodel_transformer_h_0_attn_c_attn\n",
      "üî¢ TopK parameter: 8\n",
      "\n",
      "‚úÖ Output directories created\n"
     ]
    }
   ],
   "execution_count": 108
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T20:20:18.323071Z",
     "start_time": "2025-11-10T20:20:17.230514Z"
    }
   },
   "source": [
    "# Step 1: Load language model with context\n",
    "print(\"üì• Loading language model...\")\n",
    "\n",
    "# Load model first to get model_id\n",
    "lm = LanguageModel.from_huggingface(MODEL_ID)\n",
    "lm.model.to(DEVICE)\n",
    "\n",
    "# Create model-specific directory for organizing all files\n",
    "MODEL_DIR = STORE_DIR / lm.model_id\n",
    "MODEL_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Create store under model-specific directory (so activations are also organized by model)\n",
    "store = LocalStore(MODEL_DIR)\n",
    "\n",
    "# Set the store we want to use (overrides default)\n",
    "lm.context.store = store\n",
    "\n",
    "# Update paths to use model-specific directory\n",
    "SAE_MODEL_PATH = MODEL_DIR / \"topk_sae_model.pt\"\n",
    "METADATA_PATH = MODEL_DIR / \"training_metadata.json\"\n",
    "\n",
    "# Print available layers for reference\n",
    "print(\"üîç Available layers:\")\n",
    "lm.layers.print_layer_names()\n",
    "print(f\"‚úÖ Model loaded: {lm.model_id}\")\n",
    "print(f\"üì± Device: {DEVICE}\")\n",
    "print(f\"üìÅ Store base: {STORE_DIR}\")\n",
    "print(f\"üìÅ Model directory: {MODEL_DIR}\")\n",
    "print(f\"üìÅ Store location: {lm.context.store.base_path}\")\n",
    "print(f\"üíæ SAE model will be saved to: {SAE_MODEL_PATH}\")\n",
    "print(f\"üíæ Metadata will be saved to: {METADATA_PATH}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì• Loading language model...\n",
      "üîç Available layers:\n",
      "gpt2lmheadmodel_transformer: No weight\n",
      "gpt2lmheadmodel_transformer_wte: torch.Size([50257, 2])\n",
      "gpt2lmheadmodel_transformer_wpe: torch.Size([1024, 2])\n",
      "gpt2lmheadmodel_transformer_drop: No weight\n",
      "gpt2lmheadmodel_transformer_h: No weight\n",
      "gpt2lmheadmodel_transformer_h_0: No weight\n",
      "gpt2lmheadmodel_transformer_h_0_ln_1: torch.Size([2])\n",
      "gpt2lmheadmodel_transformer_h_0_attn: No weight\n",
      "gpt2lmheadmodel_transformer_h_0_attn_c_attn: torch.Size([2, 6])\n",
      "gpt2lmheadmodel_transformer_h_0_attn_c_proj: torch.Size([2, 2])\n",
      "gpt2lmheadmodel_transformer_h_0_attn_attn_dropout: No weight\n",
      "gpt2lmheadmodel_transformer_h_0_attn_resid_dropout: No weight\n",
      "gpt2lmheadmodel_transformer_h_0_ln_2: torch.Size([2])\n",
      "gpt2lmheadmodel_transformer_h_0_mlp: No weight\n",
      "gpt2lmheadmodel_transformer_h_0_mlp_c_fc: torch.Size([2, 8])\n",
      "gpt2lmheadmodel_transformer_h_0_mlp_c_proj: torch.Size([8, 2])\n",
      "gpt2lmheadmodel_transformer_h_0_mlp_act: No weight\n",
      "gpt2lmheadmodel_transformer_h_0_mlp_dropout: No weight\n",
      "gpt2lmheadmodel_transformer_h_1: No weight\n",
      "gpt2lmheadmodel_transformer_h_1_ln_1: torch.Size([2])\n",
      "gpt2lmheadmodel_transformer_h_1_attn: No weight\n",
      "gpt2lmheadmodel_transformer_h_1_attn_c_attn: torch.Size([2, 6])\n",
      "gpt2lmheadmodel_transformer_h_1_attn_c_proj: torch.Size([2, 2])\n",
      "gpt2lmheadmodel_transformer_h_1_attn_attn_dropout: No weight\n",
      "gpt2lmheadmodel_transformer_h_1_attn_resid_dropout: No weight\n",
      "gpt2lmheadmodel_transformer_h_1_ln_2: torch.Size([2])\n",
      "gpt2lmheadmodel_transformer_h_1_mlp: No weight\n",
      "gpt2lmheadmodel_transformer_h_1_mlp_c_fc: torch.Size([2, 8])\n",
      "gpt2lmheadmodel_transformer_h_1_mlp_c_proj: torch.Size([8, 2])\n",
      "gpt2lmheadmodel_transformer_h_1_mlp_act: No weight\n",
      "gpt2lmheadmodel_transformer_h_1_mlp_dropout: No weight\n",
      "gpt2lmheadmodel_transformer_ln_f: torch.Size([2])\n",
      "gpt2lmheadmodel_lm_head: torch.Size([50257, 2])\n",
      "‚úÖ Model loaded: sshleifer_tiny-gpt2\n",
      "üì± Device: cpu\n",
      "üìÅ Store base: store\n",
      "üìÅ Model directory: store/sshleifer_tiny-gpt2\n",
      "üìÅ Store location: store/sshleifer_tiny-gpt2\n",
      "üíæ SAE model will be saved to: store/sshleifer_tiny-gpt2/topk_sae_model.pt\n",
      "üíæ Metadata will be saved to: store/sshleifer_tiny-gpt2/training_metadata.json\n"
     ]
    }
   ],
   "execution_count": 109
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T20:20:20.070784Z",
     "start_time": "2025-11-10T20:20:18.334869Z"
    }
   },
   "source": [
    "# Step 2: Load dataset\n",
    "print(\"üì• Loading dataset...\")\n",
    "dataset = TextDataset.from_huggingface(\n",
    "    HF_DATASET,\n",
    "    split=DATA_SPLIT,\n",
    "    cache_dir=str(CACHE_DIR),\n",
    "    text_field=TEXT_FIELD,\n",
    "    limit=DATA_LIMIT,\n",
    ")\n",
    "print(f\"‚úÖ Loaded {len(dataset)} text samples\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì• Loading dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1000/1000 [00:00<00:00, 538836.59 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded 1000 text samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 110
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T20:20:28.742872Z",
     "start_time": "2025-11-10T20:20:20.089624Z"
    }
   },
   "source": [
    "# Step 3: Save activations\n",
    "print(\"üíæ Saving activations...\")\n",
    "\n",
    "# Use the store that was set on the language model\n",
    "lm.activations.infer_and_save(\n",
    "    dataset,\n",
    "    layer_signature=LAYER_SIGNATURE,\n",
    "    run_name=RUN_ID,\n",
    "    store=lm.context.store,  # Use the store from language model\n",
    "    batch_size=BATCH_SIZE_SAVE,\n",
    "    autocast=False,  # Disable autocast for consistency\n",
    ")\n",
    "\n",
    "# Verify activations were saved\n",
    "batches = lm.context.store.list_run_batches(RUN_ID)\n",
    "print(f\"‚úÖ Saved {len(batches)} batches of activations\")\n",
    "print(f\"üìÅ Run ID: {RUN_ID}\")\n",
    "print(f\"üìÅ Store location: {lm.context.store.base_path}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Saving activations...\n",
      "‚úÖ Saved 63 batches of activations\n",
      "üìÅ Run ID: topk_sae_training_20251110_212017\n",
      "üìÅ Store location: store/sshleifer_tiny-gpt2\n"
     ]
    }
   ],
   "execution_count": 111
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T20:20:28.785553Z",
     "start_time": "2025-11-10T20:20:28.758155Z"
    }
   },
   "source": [
    "# Step 4: Create TopKSAE model\n",
    "print(\"üèóÔ∏è Creating TopKSAE model...\")\n",
    "\n",
    "# Get the hidden dimension from the first batch\n",
    "first_batch = lm.context.store.get_run_batch(RUN_ID, 0)\n",
    "if isinstance(first_batch, dict):\n",
    "    activations = first_batch[\"activations\"]\n",
    "else:\n",
    "    activations = first_batch[0]  # Assume first tensor is activations\n",
    "\n",
    "hidden_dim = activations.shape[-1]  # Last dimension is hidden size\n",
    "print(f\"üìè Hidden dimension: {hidden_dim}\")\n",
    "\n",
    "sae = TopKSae(\n",
    "    n_latents=hidden_dim * 4,\n",
    "    n_inputs=hidden_dim,\n",
    "    k=TOP_K,\n",
    "    device=DEVICE,\n",
    ")\n",
    "\n",
    "print(f\"üß† TopKSAE architecture: {hidden_dim} ‚Üí {sae.context.n_latents} ‚Üí {hidden_dim}\")\n",
    "print(f\"üî¢ TopK parameter: {sae.k}\")\n",
    "print(f\"üîß Device: {DEVICE}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèóÔ∏è Creating TopKSAE model...\n",
      "üìè Hidden dimension: 6\n",
      "üß† TopKSAE architecture: 6 ‚Üí 24 ‚Üí 6\n",
      "üî¢ TopK parameter: 8\n",
      "üîß Device: cpu\n"
     ]
    }
   ],
   "execution_count": 112
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T20:20:31.929628Z",
     "start_time": "2025-11-10T20:20:28.790176Z"
    }
   },
   "source": [
    "# Step 5: Train TopKSAE using SaeTrainer\n",
    "print(\"üèãÔ∏è Training TopKSAE...\")\n",
    "print(\"üìù Note: Training uses overcomplete's train_sae functions via the SaeTrainer composite class\")\n",
    "print(f\"üîß Trainer available at: sae.trainer (type: {type(sae.trainer).__name__})\")\n",
    "print()\n",
    "\n",
    "# Configure training parameters\n",
    "# Note: TopKSAETrainingConfig is an alias for SaeTrainingConfig\n",
    "# You can also use SaeTrainingConfig directly from sae_trainer module\n",
    "config = TopKSAETrainingConfig(\n",
    "    epochs=100,\n",
    "    batch_size=BATCH_SIZE_TRAIN,\n",
    "    lr=1e-3,\n",
    "    l1_lambda=1e-4,  # L1 sparsity penalty\n",
    "    device=DEVICE,\n",
    "    dtype=DTYPE,\n",
    "    max_batches_per_epoch=50,  # Limit batches per epoch for quick training\n",
    "    verbose=True,  # Enable progress logging\n",
    "    use_amp=True,\n",
    "    amp_dtype=DTYPE,\n",
    "    clip_grad=1.0,  # Gradient clipping (overcomplete parameter)\n",
    "    monitoring=2,  # Detailed monitoring (0=silent, 1=basic, 2=detailed)\n",
    ")\n",
    "\n",
    "# Train using TopKSAE's train method (which delegates to sae.trainer.train())\n",
    "# The trainer uses overcomplete's train_sae_amp or train_sae functions internally\n",
    "history = sae.train(lm.context.store, RUN_ID, config)\n",
    "\n",
    "print()\n",
    "print(\"‚úÖ Training completed!\")\n",
    "print(f\"üìà Final loss: {history['loss'][-1]:.6f}\")\n",
    "print(f\"üìà Final reconstruction MSE: {history['recon_mse'][-1]:.6f}\")\n",
    "print(f\"üìà Final L1 penalty: {history['l1'][-1]:.6f}\")\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-10 21:20:28,814 [INFO] amber.mechanistic.autoencoder.sae_trainer: [SaeTrainer] Starting training run_id=topk_sae_training_20251110_212017 epochs=100 batch_size=32 device=cpu use_amp=True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèãÔ∏è Training TopKSAE...\n",
      "üìù Note: Training uses overcomplete's train_sae functions via the SaeTrainer composite class\n",
      "üîß Trainer available at: sae.trainer (type: SaeTrainer)\n",
      "\n",
      "Epoch[1/100], Loss: 0.0464, R2: -59.9130, L0: 8.0000, Dead Features: 54.2%, Time: 0.0319 seconds\n",
      "Epoch[2/100], Loss: 0.0137, R2: -16.9208, L0: 8.0000, Dead Features: 37.5%, Time: 0.0327 seconds\n",
      "Epoch[3/100], Loss: 0.0022, R2: -1.8770, L0: 8.0000, Dead Features: 41.7%, Time: 0.0328 seconds\n",
      "Epoch[4/100], Loss: 0.0005, R2: 0.3043, L0: 8.0000, Dead Features: 45.8%, Time: 0.0342 seconds\n",
      "Epoch[5/100], Loss: 0.0002, R2: 0.7058, L0: 8.0000, Dead Features: 45.8%, Time: 0.0357 seconds\n",
      "Epoch[6/100], Loss: 0.0001, R2: 0.8554, L0: 8.0000, Dead Features: 45.8%, Time: 0.0343 seconds\n",
      "Epoch[7/100], Loss: 0.0001, R2: 0.9212, L0: 8.0000, Dead Features: 45.8%, Time: 0.0323 seconds\n",
      "Epoch[8/100], Loss: 0.0000, R2: 0.9499, L0: 8.0000, Dead Features: 45.8%, Time: 0.0318 seconds\n",
      "Epoch[9/100], Loss: 0.0000, R2: 0.9656, L0: 8.0000, Dead Features: 45.8%, Time: 0.0318 seconds\n",
      "Epoch[10/100], Loss: 0.0000, R2: 0.9761, L0: 8.0000, Dead Features: 50.0%, Time: 0.0302 seconds\n",
      "Epoch[11/100], Loss: 0.0000, R2: 0.9823, L0: 8.0000, Dead Features: 45.8%, Time: 0.0333 seconds\n",
      "Epoch[12/100], Loss: 0.0000, R2: 0.9864, L0: 8.0000, Dead Features: 45.8%, Time: 0.0322 seconds\n",
      "Epoch[13/100], Loss: 0.0000, R2: 0.9890, L0: 8.0000, Dead Features: 45.8%, Time: 0.0303 seconds\n",
      "Epoch[14/100], Loss: 0.0000, R2: 0.9901, L0: 8.0000, Dead Features: 50.0%, Time: 0.0269 seconds\n",
      "Epoch[15/100], Loss: 0.0000, R2: 0.9909, L0: 8.0000, Dead Features: 45.8%, Time: 0.0276 seconds\n",
      "Epoch[16/100], Loss: 0.0000, R2: 0.9925, L0: 8.0000, Dead Features: 45.8%, Time: 0.0298 seconds\n",
      "Epoch[17/100], Loss: 0.0000, R2: 0.9933, L0: 8.0000, Dead Features: 50.0%, Time: 0.0269 seconds\n",
      "Epoch[18/100], Loss: 0.0000, R2: 0.9935, L0: 8.0000, Dead Features: 45.8%, Time: 0.0283 seconds\n",
      "Epoch[19/100], Loss: 0.0000, R2: 0.9940, L0: 8.0000, Dead Features: 50.0%, Time: 0.0282 seconds\n",
      "Epoch[20/100], Loss: 0.0000, R2: 0.9944, L0: 8.0000, Dead Features: 50.0%, Time: 0.0300 seconds\n",
      "Epoch[21/100], Loss: 0.0000, R2: 0.9943, L0: 8.0000, Dead Features: 50.0%, Time: 0.0259 seconds\n",
      "Epoch[22/100], Loss: 0.0000, R2: 0.9944, L0: 8.0000, Dead Features: 50.0%, Time: 0.0291 seconds\n",
      "Epoch[23/100], Loss: 0.0000, R2: 0.9946, L0: 8.0000, Dead Features: 50.0%, Time: 0.0284 seconds\n",
      "Epoch[24/100], Loss: 0.0000, R2: 0.9942, L0: 8.0000, Dead Features: 41.7%, Time: 0.0282 seconds\n",
      "Epoch[25/100], Loss: 0.0000, R2: 0.9948, L0: 8.0000, Dead Features: 45.8%, Time: 0.0289 seconds\n",
      "Epoch[26/100], Loss: 0.0000, R2: 0.9948, L0: 8.0000, Dead Features: 45.8%, Time: 0.0268 seconds\n",
      "Epoch[27/100], Loss: 0.0000, R2: 0.9951, L0: 8.0000, Dead Features: 45.8%, Time: 0.0291 seconds\n",
      "Epoch[28/100], Loss: 0.0000, R2: 0.9950, L0: 8.0000, Dead Features: 45.8%, Time: 0.0307 seconds\n",
      "Epoch[29/100], Loss: 0.0000, R2: 0.9952, L0: 8.0000, Dead Features: 41.7%, Time: 0.0301 seconds\n",
      "Epoch[30/100], Loss: 0.0000, R2: 0.9957, L0: 8.0000, Dead Features: 41.7%, Time: 0.0274 seconds\n",
      "Epoch[31/100], Loss: 0.0000, R2: 0.9959, L0: 8.0000, Dead Features: 41.7%, Time: 0.0316 seconds\n",
      "Epoch[32/100], Loss: 0.0000, R2: 0.9966, L0: 8.0000, Dead Features: 41.7%, Time: 0.0293 seconds\n",
      "Epoch[33/100], Loss: 0.0000, R2: 0.9962, L0: 8.0000, Dead Features: 45.8%, Time: 0.0301 seconds\n",
      "Epoch[34/100], Loss: 0.0000, R2: 0.9967, L0: 8.0000, Dead Features: 45.8%, Time: 0.0304 seconds\n",
      "Epoch[35/100], Loss: 0.0000, R2: 0.9972, L0: 8.0000, Dead Features: 41.7%, Time: 0.0315 seconds\n",
      "Epoch[36/100], Loss: 0.0000, R2: 0.9976, L0: 8.0000, Dead Features: 41.7%, Time: 0.0304 seconds\n",
      "Epoch[37/100], Loss: 0.0000, R2: 0.9979, L0: 8.0000, Dead Features: 41.7%, Time: 0.0301 seconds\n",
      "Epoch[38/100], Loss: 0.0000, R2: 0.9980, L0: 8.0000, Dead Features: 45.8%, Time: 0.0306 seconds\n",
      "Epoch[39/100], Loss: 0.0000, R2: 0.9983, L0: 8.0000, Dead Features: 50.0%, Time: 0.0317 seconds\n",
      "Epoch[40/100], Loss: 0.0000, R2: 0.9984, L0: 8.0000, Dead Features: 45.8%, Time: 0.0317 seconds\n",
      "Epoch[41/100], Loss: 0.0000, R2: 0.9987, L0: 8.0000, Dead Features: 50.0%, Time: 0.0302 seconds\n",
      "Epoch[42/100], Loss: 0.0000, R2: 0.9988, L0: 8.0000, Dead Features: 45.8%, Time: 0.0308 seconds\n",
      "Epoch[43/100], Loss: 0.0000, R2: 0.9986, L0: 8.0000, Dead Features: 58.3%, Time: 0.0323 seconds\n",
      "Epoch[44/100], Loss: 0.0000, R2: 0.9989, L0: 8.0000, Dead Features: 45.8%, Time: 0.0299 seconds\n",
      "Epoch[45/100], Loss: 0.0000, R2: 0.9991, L0: 8.0000, Dead Features: 41.7%, Time: 0.0307 seconds\n",
      "Epoch[46/100], Loss: 0.0000, R2: 0.9990, L0: 8.0000, Dead Features: 54.2%, Time: 0.0297 seconds\n",
      "Epoch[47/100], Loss: 0.0000, R2: 0.9990, L0: 8.0000, Dead Features: 41.7%, Time: 0.0312 seconds\n",
      "Epoch[48/100], Loss: 0.0000, R2: 0.9989, L0: 8.0000, Dead Features: 50.0%, Time: 0.0309 seconds\n",
      "Epoch[49/100], Loss: 0.0000, R2: 0.9990, L0: 8.0000, Dead Features: 54.2%, Time: 0.0340 seconds\n",
      "Epoch[50/100], Loss: 0.0000, R2: 0.9992, L0: 8.0000, Dead Features: 41.7%, Time: 0.0328 seconds\n",
      "Epoch[51/100], Loss: 0.0000, R2: 0.9993, L0: 8.0000, Dead Features: 41.7%, Time: 0.0327 seconds\n",
      "Epoch[52/100], Loss: 0.0000, R2: 0.9993, L0: 8.0000, Dead Features: 50.0%, Time: 0.0323 seconds\n",
      "Epoch[53/100], Loss: 0.0000, R2: 0.9991, L0: 8.0000, Dead Features: 50.0%, Time: 0.0305 seconds\n",
      "Epoch[54/100], Loss: 0.0000, R2: 0.9993, L0: 8.0000, Dead Features: 50.0%, Time: 0.0311 seconds\n",
      "Epoch[55/100], Loss: 0.0000, R2: 0.9991, L0: 8.0000, Dead Features: 45.8%, Time: 0.0307 seconds\n",
      "Epoch[56/100], Loss: 0.0000, R2: 0.9993, L0: 8.0000, Dead Features: 58.3%, Time: 0.0308 seconds\n",
      "Epoch[57/100], Loss: 0.0000, R2: 0.9993, L0: 8.0000, Dead Features: 54.2%, Time: 0.0303 seconds\n",
      "Epoch[58/100], Loss: 0.0000, R2: 0.9994, L0: 8.0000, Dead Features: 58.3%, Time: 0.0320 seconds\n",
      "Epoch[59/100], Loss: 0.0000, R2: 0.9994, L0: 8.0000, Dead Features: 62.5%, Time: 0.0332 seconds\n",
      "Epoch[60/100], Loss: 0.0000, R2: 0.9993, L0: 8.0000, Dead Features: 62.5%, Time: 0.0316 seconds\n",
      "Epoch[61/100], Loss: 0.0000, R2: 0.9992, L0: 8.0000, Dead Features: 62.5%, Time: 0.0328 seconds\n",
      "Epoch[62/100], Loss: 0.0000, R2: 0.9991, L0: 7.8794, Dead Features: 58.3%, Time: 0.0327 seconds\n",
      "Epoch[63/100], Loss: 0.0000, R2: 0.9988, L0: 7.8400, Dead Features: 66.7%, Time: 0.0313 seconds\n",
      "Epoch[64/100], Loss: 0.0000, R2: 0.9992, L0: 7.8931, Dead Features: 62.5%, Time: 0.0312 seconds\n",
      "Epoch[65/100], Loss: 0.0000, R2: 0.9993, L0: 7.7850, Dead Features: 62.5%, Time: 0.0304 seconds\n",
      "Epoch[66/100], Loss: 0.0000, R2: 0.9993, L0: 7.8675, Dead Features: 62.5%, Time: 0.0308 seconds\n",
      "Epoch[67/100], Loss: 0.0000, R2: 0.9993, L0: 7.8094, Dead Features: 66.7%, Time: 0.0301 seconds\n",
      "Epoch[68/100], Loss: 0.0000, R2: 0.9994, L0: 7.8250, Dead Features: 66.7%, Time: 0.0299 seconds\n",
      "Epoch[69/100], Loss: 0.0000, R2: 0.9993, L0: 7.8569, Dead Features: 66.7%, Time: 0.0312 seconds\n",
      "Epoch[70/100], Loss: 0.0000, R2: 0.9991, L0: 7.8375, Dead Features: 58.3%, Time: 0.0307 seconds\n",
      "Epoch[71/100], Loss: 0.0000, R2: 0.9989, L0: 7.8506, Dead Features: 66.7%, Time: 0.0301 seconds\n",
      "Epoch[72/100], Loss: 0.0000, R2: 0.9996, L0: 7.8863, Dead Features: 66.7%, Time: 0.0299 seconds\n",
      "Epoch[73/100], Loss: 0.0000, R2: 0.9997, L0: 7.9219, Dead Features: 66.7%, Time: 0.0304 seconds\n",
      "Epoch[74/100], Loss: 0.0000, R2: 0.9997, L0: 7.8725, Dead Features: 66.7%, Time: 0.0301 seconds\n",
      "Epoch[75/100], Loss: 0.0000, R2: 0.9996, L0: 7.8481, Dead Features: 66.7%, Time: 0.0309 seconds\n",
      "Epoch[76/100], Loss: 0.0000, R2: 0.9995, L0: 7.8506, Dead Features: 66.7%, Time: 0.0305 seconds\n",
      "Epoch[77/100], Loss: 0.0000, R2: 0.9996, L0: 7.8438, Dead Features: 66.7%, Time: 0.0336 seconds\n",
      "Epoch[78/100], Loss: 0.0000, R2: 0.9990, L0: 7.8369, Dead Features: 66.7%, Time: 0.0337 seconds\n",
      "Epoch[79/100], Loss: 0.0000, R2: 0.9990, L0: 7.8850, Dead Features: 66.7%, Time: 0.0321 seconds\n",
      "Epoch[80/100], Loss: 0.0000, R2: 0.9993, L0: 7.8794, Dead Features: 66.7%, Time: 0.0329 seconds\n",
      "Epoch[81/100], Loss: 0.0000, R2: 0.9994, L0: 7.8825, Dead Features: 66.7%, Time: 0.0322 seconds\n",
      "Epoch[82/100], Loss: 0.0000, R2: 0.9991, L0: 7.8394, Dead Features: 66.7%, Time: 0.0344 seconds\n",
      "Epoch[83/100], Loss: 0.0000, R2: 0.9979, L0: 7.8600, Dead Features: 62.5%, Time: 0.0317 seconds\n",
      "Epoch[84/100], Loss: 0.0000, R2: 0.9990, L0: 7.8381, Dead Features: 66.7%, Time: 0.0330 seconds\n",
      "Epoch[85/100], Loss: 0.0000, R2: 0.9987, L0: 7.8150, Dead Features: 62.5%, Time: 0.0316 seconds\n",
      "Epoch[86/100], Loss: 0.0000, R2: 0.9990, L0: 7.9019, Dead Features: 66.7%, Time: 0.0341 seconds\n",
      "Epoch[87/100], Loss: 0.0000, R2: 0.9990, L0: 7.8625, Dead Features: 66.7%, Time: 0.0332 seconds\n",
      "Epoch[88/100], Loss: 0.0000, R2: 0.9992, L0: 7.9019, Dead Features: 66.7%, Time: 0.0317 seconds\n",
      "Epoch[89/100], Loss: 0.0000, R2: 0.9994, L0: 7.8637, Dead Features: 66.7%, Time: 0.0315 seconds\n",
      "Epoch[90/100], Loss: 0.0000, R2: 0.9992, L0: 7.8613, Dead Features: 66.7%, Time: 0.0320 seconds\n",
      "Epoch[91/100], Loss: 0.0000, R2: 0.9992, L0: 7.8513, Dead Features: 66.7%, Time: 0.0319 seconds\n",
      "Epoch[92/100], Loss: 0.0000, R2: 0.9991, L0: 7.8700, Dead Features: 62.5%, Time: 0.0305 seconds\n",
      "Epoch[93/100], Loss: 0.0000, R2: 0.9946, L0: 7.8881, Dead Features: 62.5%, Time: 0.0303 seconds\n",
      "Epoch[94/100], Loss: 0.0000, R2: 0.9989, L0: 7.8625, Dead Features: 66.7%, Time: 0.0306 seconds\n",
      "Epoch[95/100], Loss: 0.0000, R2: 0.9949, L0: 7.8544, Dead Features: 62.5%, Time: 0.0312 seconds\n",
      "Epoch[96/100], Loss: 0.0000, R2: 0.9993, L0: 7.9463, Dead Features: 66.7%, Time: 0.0319 seconds\n",
      "Epoch[97/100], Loss: 0.0000, R2: 0.9992, L0: 7.9506, Dead Features: 66.7%, Time: 0.0322 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-10 21:20:31,923 [INFO] amber.mechanistic.autoencoder.sae_trainer: [SaeTrainer] Completed training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[98/100], Loss: 0.0000, R2: 0.9988, L0: 7.9481, Dead Features: 66.7%, Time: 0.0312 seconds\n",
      "Epoch[99/100], Loss: 0.0000, R2: 0.9977, L0: 7.9994, Dead Features: 62.5%, Time: 0.0300 seconds\n",
      "Epoch[100/100], Loss: 0.0000, R2: 0.9957, L0: 7.9400, Dead Features: 62.5%, Time: 0.0298 seconds\n",
      "\n",
      "‚úÖ Training completed!\n",
      "üìà Final loss: 0.000010\n",
      "üìà Final reconstruction MSE: 0.004320\n",
      "üìà Final L1 penalty: 0.000000\n"
     ]
    }
   ],
   "execution_count": 113
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T20:20:31.967395Z",
     "start_time": "2025-11-10T20:20:31.941325Z"
    }
   },
   "source": [
    "# Step 6: Save trained TopKSAE\n",
    "print(\"üíæ Saving trained TopKSAE...\")\n",
    "\n",
    "# Save using TopKSAE's save method (saves overcomplete model + our metadata)\n",
    "sae.save(\n",
    "    name=\"topk_sae_model\",\n",
    "    path=SAE_MODEL_PATH.parent\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ TopKSAE saved to: {SAE_MODEL_PATH}\")\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-10 21:20:31,965 [INFO] amber.mechanistic.autoencoder.modules.topk_sae: Saved TopKSAE to store/sshleifer_tiny-gpt2/topk_sae_model.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Saving trained TopKSAE...\n",
      "‚úÖ TopKSAE saved to: store/sshleifer_tiny-gpt2/topk_sae_model.pt\n"
     ]
    }
   ],
   "execution_count": 114
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T20:20:32.001524Z",
     "start_time": "2025-11-10T20:20:31.974370Z"
    }
   },
   "source": [
    "# Step 7: Save run metadata for next example\n",
    "import json\n",
    "\n",
    "run_metadata = {\n",
    "    \"run_id\": RUN_ID,\n",
    "    \"layer_signature\": LAYER_SIGNATURE,\n",
    "    \"hidden_dim\": hidden_dim,\n",
    "    \"n_latents\": sae.context.n_latents,\n",
    "    \"k\": sae.k,\n",
    "    \"model_id\": MODEL_ID,\n",
    "    \"model_dir\": str(MODEL_DIR),\n",
    "    \"dataset\": HF_DATASET,\n",
    "    \"data_limit\": DATA_LIMIT,\n",
    "    \"sae_model_path\": str(SAE_MODEL_PATH),\n",
    "    \"store_dir\": str(STORE_DIR),\n",
    "    \"cache_dir\": str(CACHE_DIR),\n",
    "    \"training_history\": history,\n",
    "}\n",
    "\n",
    "# Save metadata to model-specific directory\n",
    "with open(METADATA_PATH, \"w\") as f:\n",
    "    json.dump(run_metadata, f, indent=2)\n",
    "\n",
    "print(f\"üìã Training metadata saved to: {METADATA_PATH}\")\n",
    "print()\n",
    "print(\"üéâ TopKSAE training completed successfully!\")\n",
    "print(f\"üìÅ All files saved under model directory: {MODEL_DIR}\")\n",
    "print(\"üìù Next: Run 02_attach_sae_and_save_texts.ipynb to attach the TopKSAE and collect top texts\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìã Training metadata saved to: store/sshleifer_tiny-gpt2/training_metadata.json\n",
      "\n",
      "üéâ TopKSAE training completed successfully!\n",
      "üìÅ All files saved under model directory: store/sshleifer_tiny-gpt2\n",
      "üìù Next: Run 02_attach_sae_and_save_texts.ipynb to attach the TopKSAE and collect top texts\n"
     ]
    }
   ],
   "execution_count": 115
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T20:20:32.005818Z",
     "start_time": "2025-11-10T20:20:32.004202Z"
    }
   },
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
