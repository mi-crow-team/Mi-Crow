{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 1: Training TopKSAE Model\n",
    "\n",
    "This notebook demonstrates how to:\n",
    "1. Load a language model and dataset\n",
    "2. Save activations from a specific layer\n",
    "3. Train a TopK Sparse Autoencoder (TopKSAE) on those activations using the new `SaeTrainer` composite class\n",
    "4. Save the trained TopKSAE model\n",
    "\n",
    "The training uses overcomplete's `train_sae` functions via the `SaeTrainer` composite class, which is automatically available on all SAE instances via `sae.trainer`.\n",
    "\n",
    "All files (trained TopKSAE model, training metadata, activations) will be saved under `store/{model_id}/` for organized, model-specific storage.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T23:08:45.942318Z",
     "start_time": "2025-11-13T23:08:35.784894Z"
    }
   },
   "source": [
    "# Setup and imports\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "from amber.adapters import TextDataset\n",
    "from amber.core.language_model import LanguageModel\n",
    "from amber.mechanistic.sae.modules.topk_sae import TopKSae, TopKSAETrainingConfig\n",
    "from amber.store.local_store import LocalStore\n",
    "\n",
    "print(\"‚úÖ Imports completed\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "‚úÖ Imports completed\n"
     ]
    }
   ],
   "execution_count": 83
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T23:08:45.942507Z",
     "start_time": "2025-11-13T23:08:35.830744Z"
    }
   },
   "source": [
    "# Configuration\n",
    "MODEL_ID = \"sshleifer/tiny-gpt2\"  # Small model for quick experimentation\n",
    "HF_DATASET = \"roneneldan/TinyStories\"\n",
    "DATA_SPLIT = \"train\"\n",
    "TEXT_FIELD = \"text\"\n",
    "DATA_LIMIT = 1000  # Number of text samples to use\n",
    "MAX_LENGTH = 64  # Maximum sequence length\n",
    "BATCH_SIZE_SAVE = 16  # Batch size for saving activations\n",
    "BATCH_SIZE_TRAIN = 32  # Batch size for SAE training\n",
    "\n",
    "# TopKSAE configuration\n",
    "TOP_K = 8  # Number of top activations to keep (sparsity parameter)\n",
    "\n",
    "# Choose which layer to hook - you can inspect available layers with model.layers.print_layer_names()\n",
    "LAYER_SIGNATURE = 'gpt2lmheadmodel_transformer_h_0_attn_c_attn'  # Attention layer (better activations)\n",
    "\n",
    "# Storage locations - will be updated after model loading to use model_id\n",
    "STORE_DIR = Path(\"store\")\n",
    "CACHE_DIR = Path(\"store/cache\")\n",
    "RUN_ID = f\"topk_sae_training_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "# Model-specific paths will be set after loading the model\n",
    "SAE_MODEL_PATH = None  # Will be set to store/{model_id}/topk_sae_model.pt\n",
    "METADATA_PATH = None  # Will be set to store/{model_id}/training_metadata.json\n",
    "\n",
    "# Device configuration\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "DTYPE = torch.float16 if torch.cuda.is_available() else None  # Use half precision on GPU\n",
    "\n",
    "print(\"üöÄ Starting TopKSAE Training Example\")\n",
    "print(f\"üì± Using device: {DEVICE}\")\n",
    "print(f\"üîß Model: {MODEL_ID}\")\n",
    "print(f\"üìä Dataset: {HF_DATASET}\")\n",
    "print(f\"üéØ Target layer: {LAYER_SIGNATURE}\")\n",
    "print(f\"üî¢ TopK parameter: {TOP_K}\")\n",
    "print()\n",
    "\n",
    "# Create output directories\n",
    "CACHE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "STORE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "print(\"‚úÖ Output directories created\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starting TopKSAE Training Example\n",
      "üì± Using device: cpu\n",
      "üîß Model: sshleifer/tiny-gpt2\n",
      "üìä Dataset: roneneldan/TinyStories\n",
      "üéØ Target layer: gpt2lmheadmodel_transformer_h_0_attn_c_attn\n",
      "üî¢ TopK parameter: 8\n",
      "\n",
      "‚úÖ Output directories created\n"
     ]
    }
   ],
   "execution_count": 84
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T23:08:45.942689Z",
     "start_time": "2025-11-13T23:08:35.857527Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Step 1: Load language model with context\n",
    "print(\"üì• Loading language model...\")\n",
    "\n",
    "store = LocalStore(STORE_DIR)\n",
    "# Load model first to get model_id\n",
    "lm = LanguageModel.from_huggingface(MODEL_ID, store=store)\n",
    "lm.model.to(DEVICE)\n",
    "\n",
    "# Create model-specific directory for organizing all files\n",
    "MODEL_DIR = STORE_DIR / lm.model_id\n",
    "\n",
    "# Create store under model-specific directory (so activations are also organized by model)\n",
    "\n",
    "# Set the store we want to use (overrides default)\n",
    "lm.context.store = store\n",
    "\n",
    "# Update paths to use model-specific directory\n",
    "SAE_MODEL_PATH = MODEL_DIR / \"topk_sae_model.pt\"\n",
    "METADATA_PATH = MODEL_DIR / \"training_metadata.json\"\n",
    "\n",
    "# Print available layers for reference\n",
    "print(\"üîç Available layers:\")\n",
    "lm.layers.print_layer_names()\n",
    "print(f\"‚úÖ Model loaded: {lm.model_id}\")\n",
    "print(f\"üì± Device: {DEVICE}\")\n",
    "print(f\"üìÅ Store base: {STORE_DIR}\")\n",
    "print(f\"üìÅ Model directory: {MODEL_DIR}\")\n",
    "print(f\"üìÅ Store location: {lm.context.store.base_path}\")\n",
    "print(f\"üíæ SAE model will be saved to: {SAE_MODEL_PATH}\")\n",
    "print(f\"üíæ Metadata will be saved to: {METADATA_PATH}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì• Loading language model...\n",
      "üîç Available layers:\n",
      "gpt2lmheadmodel_transformer: No weight\n",
      "gpt2lmheadmodel_transformer_wte: torch.Size([50257, 2])\n",
      "gpt2lmheadmodel_transformer_wpe: torch.Size([1024, 2])\n",
      "gpt2lmheadmodel_transformer_drop: No weight\n",
      "gpt2lmheadmodel_transformer_h: No weight\n",
      "gpt2lmheadmodel_transformer_h_0: No weight\n",
      "gpt2lmheadmodel_transformer_h_0_ln_1: torch.Size([2])\n",
      "gpt2lmheadmodel_transformer_h_0_attn: No weight\n",
      "gpt2lmheadmodel_transformer_h_0_attn_c_attn: torch.Size([2, 6])\n",
      "gpt2lmheadmodel_transformer_h_0_attn_c_proj: torch.Size([2, 2])\n",
      "gpt2lmheadmodel_transformer_h_0_attn_attn_dropout: No weight\n",
      "gpt2lmheadmodel_transformer_h_0_attn_resid_dropout: No weight\n",
      "gpt2lmheadmodel_transformer_h_0_ln_2: torch.Size([2])\n",
      "gpt2lmheadmodel_transformer_h_0_mlp: No weight\n",
      "gpt2lmheadmodel_transformer_h_0_mlp_c_fc: torch.Size([2, 8])\n",
      "gpt2lmheadmodel_transformer_h_0_mlp_c_proj: torch.Size([8, 2])\n",
      "gpt2lmheadmodel_transformer_h_0_mlp_act: No weight\n",
      "gpt2lmheadmodel_transformer_h_0_mlp_dropout: No weight\n",
      "gpt2lmheadmodel_transformer_h_1: No weight\n",
      "gpt2lmheadmodel_transformer_h_1_ln_1: torch.Size([2])\n",
      "gpt2lmheadmodel_transformer_h_1_attn: No weight\n",
      "gpt2lmheadmodel_transformer_h_1_attn_c_attn: torch.Size([2, 6])\n",
      "gpt2lmheadmodel_transformer_h_1_attn_c_proj: torch.Size([2, 2])\n",
      "gpt2lmheadmodel_transformer_h_1_attn_attn_dropout: No weight\n",
      "gpt2lmheadmodel_transformer_h_1_attn_resid_dropout: No weight\n",
      "gpt2lmheadmodel_transformer_h_1_ln_2: torch.Size([2])\n",
      "gpt2lmheadmodel_transformer_h_1_mlp: No weight\n",
      "gpt2lmheadmodel_transformer_h_1_mlp_c_fc: torch.Size([2, 8])\n",
      "gpt2lmheadmodel_transformer_h_1_mlp_c_proj: torch.Size([8, 2])\n",
      "gpt2lmheadmodel_transformer_h_1_mlp_act: No weight\n",
      "gpt2lmheadmodel_transformer_h_1_mlp_dropout: No weight\n",
      "gpt2lmheadmodel_transformer_ln_f: torch.Size([2])\n",
      "gpt2lmheadmodel_lm_head: torch.Size([50257, 2])\n",
      "‚úÖ Model loaded: sshleifer_tiny-gpt2\n",
      "üì± Device: cpu\n",
      "üìÅ Store base: store\n",
      "üìÅ Model directory: store/sshleifer_tiny-gpt2\n",
      "üìÅ Store location: store\n",
      "üíæ SAE model will be saved to: store/sshleifer_tiny-gpt2/topk_sae_model.pt\n",
      "üíæ Metadata will be saved to: store/sshleifer_tiny-gpt2/training_metadata.json\n"
     ]
    }
   ],
   "execution_count": 85
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T23:08:45.942899Z",
     "start_time": "2025-11-13T23:08:37.059549Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Step 2: Load dataset\n",
    "print(\"üì• Loading dataset...\")\n",
    "dataset = TextDataset.from_huggingface(\n",
    "    HF_DATASET,\n",
    "    split=DATA_SPLIT,\n",
    "    store=store,\n",
    "    text_field=TEXT_FIELD,\n",
    "    limit=DATA_LIMIT,\n",
    ")\n",
    "print(f\"‚úÖ Loaded {len(dataset)} text samples\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì• Loading dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1000/1000 [00:00<00:00, 498965.50 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded 1000 text samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 86
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T23:08:45.808907Z",
     "start_time": "2025-11-13T23:08:38.514859Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Step 3: Save activations\n",
    "print(\"üíæ Saving activations...\")\n",
    "\n",
    "# Use the store that was set on the language model\n",
    "lm.activations.save_activations_dataset(\n",
    "    dataset,\n",
    "    layer_signature=LAYER_SIGNATURE,\n",
    "    run_name=RUN_ID,\n",
    "    batch_size=BATCH_SIZE_SAVE,\n",
    "    autocast=False,  # Disable autocast for consistency\n",
    ")\n",
    "\n",
    "# Verify activations were saved\n",
    "batches = lm.context.store.list_run_batches(RUN_ID)\n",
    "print(f\"‚úÖ Saved {len(batches)} batches of activations\")\n",
    "print(f\"üìÅ Run ID: {RUN_ID}\")\n",
    "print(f\"üìÅ Store location: {lm.context.store.base_path}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Saving activations...\n",
      "‚úÖ Saved 63 batches of activations\n",
      "üìÅ Run ID: topk_sae_training_20251114_000835\n",
      "üìÅ Store location: store\n"
     ]
    }
   ],
   "execution_count": 87
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T23:08:45.846078Z",
     "start_time": "2025-11-13T23:08:45.821102Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Step 4: Create TopKSAE model\n",
    "print(\"üèóÔ∏è Creating TopKSAE model...\")\n",
    "\n",
    "# Get the hidden dimension from the first batch\n",
    "first_batch = lm.context.store.get_run_batch(RUN_ID, 0)\n",
    "if isinstance(first_batch, dict):\n",
    "    activations = first_batch[\"activations\"]\n",
    "else:\n",
    "    activations = first_batch[0]  # Assume first tensor is activations\n",
    "\n",
    "hidden_dim = activations.shape[-1]  # Last dimension is hidden size\n",
    "print(f\"üìè Hidden dimension: {hidden_dim}\")\n",
    "\n",
    "sae = TopKSae(\n",
    "    n_latents=hidden_dim * 4,\n",
    "    n_inputs=hidden_dim,\n",
    "    k=TOP_K,\n",
    "    device=DEVICE,\n",
    ")\n",
    "\n",
    "print(f\"üß† TopKSAE architecture: {hidden_dim} ‚Üí {sae.context.n_latents} ‚Üí {hidden_dim}\")\n",
    "print(f\"üî¢ TopK parameter: {sae.k}\")\n",
    "print(f\"üîß Device: {DEVICE}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèóÔ∏è Creating TopKSAE model...\n",
      "üìè Hidden dimension: 6\n",
      "üß† TopKSAE architecture: 6 ‚Üí 24 ‚Üí 6\n",
      "üî¢ TopK parameter: 8\n",
      "üîß Device: cpu\n"
     ]
    }
   ],
   "execution_count": 88
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T23:09:17.368677Z",
     "start_time": "2025-11-13T23:09:14.375889Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Step 5: Train TopKSAE using SaeTrainer\n",
    "print(\"üèãÔ∏è Training TopKSAE...\")\n",
    "print(\"üìù Note: Training uses overcomplete's train_sae functions via the SaeTrainer composite class\")\n",
    "print(f\"üîß Trainer available at: sae.trainer (type: {type(sae.trainer).__name__})\")\n",
    "print()\n",
    "\n",
    "# Configure training parameters\n",
    "# Note: TopKSAETrainingConfig is an alias for SaeTrainingConfig\n",
    "# You can also use SaeTrainingConfig directly from sae_trainer module\n",
    "config = TopKSAETrainingConfig(\n",
    "    epochs=100,\n",
    "    batch_size=BATCH_SIZE_TRAIN,\n",
    "    lr=1e-3,\n",
    "    l1_lambda=1e-4,  # L1 sparsity penalty\n",
    "    device=DEVICE,\n",
    "    dtype=DTYPE,\n",
    "    max_batches_per_epoch=50,  # Limit batches per epoch for quick training\n",
    "    verbose=True,  # Enable progress logging\n",
    "    use_amp=True,\n",
    "    amp_dtype=DTYPE,\n",
    "    clip_grad=1.0,  # Gradient clipping (overcomplete parameter)\n",
    "    monitoring=2,  # Detailed monitoring (0=silent, 1=basic, 2=detailed)\n",
    ")\n",
    "\n",
    "# Train using TopKSAE's train method (which delegates to sae.trainer.train())\n",
    "# The trainer uses overcomplete's train_sae_amp or train_sae functions internally\n",
    "history = sae.train(lm.context.store, RUN_ID, LAYER_SIGNATURE, config)\n",
    "\n",
    "print()\n",
    "print(\"‚úÖ Training completed!\")\n",
    "print(f\"üìà Final loss: {history['loss'][-1]:.6f}\")\n",
    "print(f\"üìà Final reconstruction MSE: {history['recon_mse'][-1]:.6f}\")\n",
    "print(f\"üìà Final L1 penalty: {history['l1'][-1]:.6f}\")\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-14 00:09:14,411 [INFO] amber.mechanistic.sae.sae_trainer: [SaeTrainer] Starting training run_id=topk_sae_training_20251114_000835 epochs=100 batch_size=32 device=cpu use_amp=True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèãÔ∏è Training TopKSAE...\n",
      "üìù Note: Training uses overcomplete's train_sae functions via the SaeTrainer composite class\n",
      "üîß Trainer available at: sae.trainer (type: SaeTrainer)\n",
      "\n",
      "Epoch[1/100], Loss: 0.0403, R2: -51.9342, L0: 8.0000, Dead Features: 62.5%, Time: 0.0386 seconds\n",
      "Epoch[2/100], Loss: 0.0119, R2: -14.5722, L0: 8.0000, Dead Features: 62.5%, Time: 0.0307 seconds\n",
      "Epoch[3/100], Loss: 0.0030, R2: -2.9422, L0: 8.0000, Dead Features: 66.7%, Time: 0.0295 seconds\n",
      "Epoch[4/100], Loss: 0.0008, R2: 0.0258, L0: 8.0000, Dead Features: 66.7%, Time: 0.0267 seconds\n",
      "Epoch[5/100], Loss: 0.0003, R2: 0.6259, L0: 8.0000, Dead Features: 62.5%, Time: 0.0313 seconds\n",
      "Epoch[6/100], Loss: 0.0002, R2: 0.7473, L0: 8.0000, Dead Features: 62.5%, Time: 0.0268 seconds\n",
      "Epoch[7/100], Loss: 0.0002, R2: 0.8079, L0: 8.0000, Dead Features: 66.7%, Time: 0.0321 seconds\n",
      "Epoch[8/100], Loss: 0.0001, R2: 0.8272, L0: 8.0000, Dead Features: 66.7%, Time: 0.0329 seconds\n",
      "Epoch[9/100], Loss: 0.0001, R2: 0.8428, L0: 8.0000, Dead Features: 66.7%, Time: 0.0278 seconds\n",
      "Epoch[10/100], Loss: 0.0001, R2: 0.8437, L0: 8.0000, Dead Features: 62.5%, Time: 0.0281 seconds\n",
      "Epoch[11/100], Loss: 0.0001, R2: 0.8707, L0: 8.0000, Dead Features: 66.7%, Time: 0.0248 seconds\n",
      "Epoch[12/100], Loss: 0.0001, R2: 0.8826, L0: 8.0000, Dead Features: 66.7%, Time: 0.0290 seconds\n",
      "Epoch[13/100], Loss: 0.0001, R2: 0.8861, L0: 8.0000, Dead Features: 62.5%, Time: 0.0285 seconds\n",
      "Epoch[14/100], Loss: 0.0001, R2: 0.9057, L0: 8.0000, Dead Features: 66.7%, Time: 0.0282 seconds\n",
      "Epoch[15/100], Loss: 0.0001, R2: 0.9081, L0: 8.0000, Dead Features: 62.5%, Time: 0.0315 seconds\n",
      "Epoch[16/100], Loss: 0.0001, R2: 0.9163, L0: 8.0000, Dead Features: 62.5%, Time: 0.0288 seconds\n",
      "Epoch[17/100], Loss: 0.0001, R2: 0.9331, L0: 8.0000, Dead Features: 66.7%, Time: 0.0311 seconds\n",
      "Epoch[18/100], Loss: 0.0001, R2: 0.9409, L0: 8.0000, Dead Features: 66.7%, Time: 0.0289 seconds\n",
      "Epoch[19/100], Loss: 0.0000, R2: 0.9436, L0: 8.0000, Dead Features: 62.5%, Time: 0.0303 seconds\n",
      "Epoch[20/100], Loss: 0.0000, R2: 0.9535, L0: 8.0000, Dead Features: 66.7%, Time: 0.0308 seconds\n",
      "Epoch[21/100], Loss: 0.0000, R2: 0.9588, L0: 8.0000, Dead Features: 66.7%, Time: 0.0308 seconds\n",
      "Epoch[22/100], Loss: 0.0000, R2: 0.9608, L0: 8.0000, Dead Features: 62.5%, Time: 0.0323 seconds\n",
      "Epoch[23/100], Loss: 0.0000, R2: 0.9687, L0: 8.0000, Dead Features: 66.7%, Time: 0.0313 seconds\n",
      "Epoch[24/100], Loss: 0.0000, R2: 0.9728, L0: 8.0000, Dead Features: 66.7%, Time: 0.0293 seconds\n",
      "Epoch[25/100], Loss: 0.0000, R2: 0.9764, L0: 8.0000, Dead Features: 66.7%, Time: 0.0288 seconds\n",
      "Epoch[26/100], Loss: 0.0000, R2: 0.9794, L0: 8.0000, Dead Features: 66.7%, Time: 0.0284 seconds\n",
      "Epoch[27/100], Loss: 0.0000, R2: 0.9820, L0: 8.0000, Dead Features: 66.7%, Time: 0.0288 seconds\n",
      "Epoch[28/100], Loss: 0.0000, R2: 0.9851, L0: 8.0000, Dead Features: 66.7%, Time: 0.0289 seconds\n",
      "Epoch[29/100], Loss: 0.0000, R2: 0.9869, L0: 8.0000, Dead Features: 66.7%, Time: 0.0295 seconds\n",
      "Epoch[30/100], Loss: 0.0000, R2: 0.9890, L0: 8.0000, Dead Features: 66.7%, Time: 0.0325 seconds\n",
      "Epoch[31/100], Loss: 0.0000, R2: 0.9907, L0: 8.0000, Dead Features: 66.7%, Time: 0.0330 seconds\n",
      "Epoch[32/100], Loss: 0.0000, R2: 0.9921, L0: 8.0000, Dead Features: 66.7%, Time: 0.0300 seconds\n",
      "Epoch[33/100], Loss: 0.0000, R2: 0.9937, L0: 8.0000, Dead Features: 66.7%, Time: 0.0307 seconds\n",
      "Epoch[34/100], Loss: 0.0000, R2: 0.9947, L0: 8.0000, Dead Features: 66.7%, Time: 0.0304 seconds\n",
      "Epoch[35/100], Loss: 0.0000, R2: 0.9953, L0: 8.0000, Dead Features: 66.7%, Time: 0.0311 seconds\n",
      "Epoch[36/100], Loss: 0.0000, R2: 0.9959, L0: 8.0000, Dead Features: 66.7%, Time: 0.0302 seconds\n",
      "Epoch[37/100], Loss: 0.0000, R2: 0.9969, L0: 8.0000, Dead Features: 66.7%, Time: 0.0298 seconds\n",
      "Epoch[38/100], Loss: 0.0000, R2: 0.9975, L0: 8.0000, Dead Features: 66.7%, Time: 0.0290 seconds\n",
      "Epoch[39/100], Loss: 0.0000, R2: 0.9978, L0: 8.0000, Dead Features: 66.7%, Time: 0.0279 seconds\n",
      "Epoch[40/100], Loss: 0.0000, R2: 0.9982, L0: 8.0000, Dead Features: 66.7%, Time: 0.0279 seconds\n",
      "Epoch[41/100], Loss: 0.0000, R2: 0.9986, L0: 8.0000, Dead Features: 66.7%, Time: 0.0283 seconds\n",
      "Epoch[42/100], Loss: 0.0000, R2: 0.9984, L0: 8.0000, Dead Features: 66.7%, Time: 0.0255 seconds\n",
      "Epoch[43/100], Loss: 0.0000, R2: 0.9990, L0: 8.0000, Dead Features: 66.7%, Time: 0.0248 seconds\n",
      "Epoch[44/100], Loss: 0.0000, R2: 0.9992, L0: 8.0000, Dead Features: 66.7%, Time: 0.0290 seconds\n",
      "Epoch[45/100], Loss: 0.0000, R2: 0.9993, L0: 8.0000, Dead Features: 66.7%, Time: 0.0300 seconds\n",
      "Epoch[46/100], Loss: 0.0000, R2: 0.9993, L0: 8.0000, Dead Features: 66.7%, Time: 0.0304 seconds\n",
      "Epoch[47/100], Loss: 0.0000, R2: 0.9993, L0: 8.0000, Dead Features: 66.7%, Time: 0.0315 seconds\n",
      "Epoch[48/100], Loss: 0.0000, R2: 0.9994, L0: 8.0000, Dead Features: 66.7%, Time: 0.0281 seconds\n",
      "Epoch[49/100], Loss: 0.0000, R2: 0.9992, L0: 8.0000, Dead Features: 66.7%, Time: 0.0266 seconds\n",
      "Epoch[50/100], Loss: 0.0000, R2: 0.9992, L0: 8.0000, Dead Features: 66.7%, Time: 0.0273 seconds\n",
      "Epoch[51/100], Loss: 0.0000, R2: 0.9990, L0: 8.0000, Dead Features: 66.7%, Time: 0.0301 seconds\n",
      "Epoch[52/100], Loss: 0.0000, R2: 0.9990, L0: 8.0000, Dead Features: 66.7%, Time: 0.0313 seconds\n",
      "Epoch[53/100], Loss: 0.0000, R2: 0.9988, L0: 8.0000, Dead Features: 66.7%, Time: 0.0308 seconds\n",
      "Epoch[54/100], Loss: 0.0000, R2: 0.9951, L0: 8.0000, Dead Features: 62.5%, Time: 0.0300 seconds\n",
      "Epoch[55/100], Loss: 0.0000, R2: 0.9989, L0: 8.0000, Dead Features: 66.7%, Time: 0.0300 seconds\n",
      "Epoch[56/100], Loss: 0.0000, R2: 0.9989, L0: 8.0000, Dead Features: 66.7%, Time: 0.0305 seconds\n",
      "Epoch[57/100], Loss: 0.0000, R2: 0.9993, L0: 8.0000, Dead Features: 66.7%, Time: 0.0278 seconds\n",
      "Epoch[58/100], Loss: 0.0000, R2: 0.9995, L0: 8.0000, Dead Features: 66.7%, Time: 0.0290 seconds\n",
      "Epoch[59/100], Loss: 0.0000, R2: 0.9995, L0: 8.0000, Dead Features: 66.7%, Time: 0.0293 seconds\n",
      "Epoch[60/100], Loss: 0.0000, R2: 0.9991, L0: 8.0000, Dead Features: 66.7%, Time: 0.0294 seconds\n",
      "Epoch[61/100], Loss: 0.0000, R2: 0.9989, L0: 8.0000, Dead Features: 66.7%, Time: 0.0287 seconds\n",
      "Epoch[62/100], Loss: 0.0000, R2: 0.9994, L0: 8.0000, Dead Features: 66.7%, Time: 0.0276 seconds\n",
      "Epoch[63/100], Loss: 0.0000, R2: 0.9996, L0: 8.0000, Dead Features: 66.7%, Time: 0.0271 seconds\n",
      "Epoch[64/100], Loss: 0.0000, R2: 0.9996, L0: 8.0000, Dead Features: 66.7%, Time: 0.0281 seconds\n",
      "Epoch[65/100], Loss: 0.0000, R2: 0.9992, L0: 8.0000, Dead Features: 66.7%, Time: 0.0279 seconds\n",
      "Epoch[66/100], Loss: 0.0000, R2: 0.9988, L0: 8.0000, Dead Features: 66.7%, Time: 0.0297 seconds\n",
      "Epoch[67/100], Loss: 0.0000, R2: 0.9993, L0: 8.0000, Dead Features: 66.7%, Time: 0.0329 seconds\n",
      "Epoch[68/100], Loss: 0.0000, R2: 0.9994, L0: 8.0000, Dead Features: 66.7%, Time: 0.0295 seconds\n",
      "Epoch[69/100], Loss: 0.0000, R2: 0.9994, L0: 8.0000, Dead Features: 66.7%, Time: 0.0290 seconds\n",
      "Epoch[70/100], Loss: 0.0000, R2: 0.9994, L0: 8.0000, Dead Features: 66.7%, Time: 0.0290 seconds\n",
      "Epoch[71/100], Loss: 0.0000, R2: 0.9992, L0: 8.0000, Dead Features: 66.7%, Time: 0.0273 seconds\n",
      "Epoch[72/100], Loss: 0.0000, R2: 0.9994, L0: 8.0000, Dead Features: 66.7%, Time: 0.0275 seconds\n",
      "Epoch[73/100], Loss: 0.0000, R2: 0.9996, L0: 8.0000, Dead Features: 66.7%, Time: 0.0276 seconds\n",
      "Epoch[74/100], Loss: 0.0000, R2: 0.9994, L0: 8.0000, Dead Features: 66.7%, Time: 0.0315 seconds\n",
      "Epoch[75/100], Loss: 0.0000, R2: 0.9994, L0: 8.0000, Dead Features: 66.7%, Time: 0.0296 seconds\n",
      "Epoch[76/100], Loss: 0.0000, R2: 0.9956, L0: 8.0000, Dead Features: 62.5%, Time: 0.0286 seconds\n",
      "Epoch[77/100], Loss: 0.0000, R2: 0.9991, L0: 8.0000, Dead Features: 66.7%, Time: 0.0297 seconds\n",
      "Epoch[78/100], Loss: 0.0000, R2: 0.9993, L0: 8.0000, Dead Features: 66.7%, Time: 0.0283 seconds\n",
      "Epoch[79/100], Loss: 0.0000, R2: 0.9995, L0: 8.0000, Dead Features: 66.7%, Time: 0.0292 seconds\n",
      "Epoch[80/100], Loss: 0.0000, R2: 0.9996, L0: 8.0000, Dead Features: 66.7%, Time: 0.0300 seconds\n",
      "Epoch[81/100], Loss: 0.0000, R2: 0.9995, L0: 8.0000, Dead Features: 66.7%, Time: 0.0295 seconds\n",
      "Epoch[82/100], Loss: 0.0000, R2: 0.9991, L0: 8.0000, Dead Features: 66.7%, Time: 0.0305 seconds\n",
      "Epoch[83/100], Loss: 0.0000, R2: 0.9988, L0: 8.0000, Dead Features: 66.7%, Time: 0.0282 seconds\n",
      "Epoch[84/100], Loss: 0.0000, R2: 0.9994, L0: 8.0000, Dead Features: 66.7%, Time: 0.0287 seconds\n",
      "Epoch[85/100], Loss: 0.0000, R2: 0.9993, L0: 8.0000, Dead Features: 66.7%, Time: 0.0293 seconds\n",
      "Epoch[86/100], Loss: 0.0000, R2: 0.9994, L0: 8.0000, Dead Features: 66.7%, Time: 0.0292 seconds\n",
      "Epoch[87/100], Loss: 0.0000, R2: 0.9992, L0: 8.0000, Dead Features: 66.7%, Time: 0.0294 seconds\n",
      "Epoch[88/100], Loss: 0.0000, R2: 0.9993, L0: 8.0000, Dead Features: 66.7%, Time: 0.0286 seconds\n",
      "Epoch[89/100], Loss: 0.0000, R2: 0.9997, L0: 8.0000, Dead Features: 66.7%, Time: 0.0310 seconds\n",
      "Epoch[90/100], Loss: 0.0000, R2: 0.9997, L0: 8.0000, Dead Features: 66.7%, Time: 0.0287 seconds\n",
      "Epoch[91/100], Loss: 0.0000, R2: 0.9994, L0: 8.0000, Dead Features: 66.7%, Time: 0.0298 seconds\n",
      "Epoch[92/100], Loss: 0.0000, R2: 0.9991, L0: 8.0000, Dead Features: 66.7%, Time: 0.0281 seconds\n",
      "Epoch[93/100], Loss: 0.0000, R2: 0.9995, L0: 8.0000, Dead Features: 66.7%, Time: 0.0290 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-14 00:09:17,362 [INFO] amber.mechanistic.sae.sae_trainer: [SaeTrainer] Completed training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[94/100], Loss: 0.0000, R2: 0.9997, L0: 8.0000, Dead Features: 66.7%, Time: 0.0302 seconds\n",
      "Epoch[95/100], Loss: 0.0000, R2: 0.9997, L0: 8.0000, Dead Features: 66.7%, Time: 0.0306 seconds\n",
      "Epoch[96/100], Loss: 0.0000, R2: 0.9994, L0: 8.0000, Dead Features: 66.7%, Time: 0.0304 seconds\n",
      "Epoch[97/100], Loss: 0.0000, R2: 0.9993, L0: 8.0000, Dead Features: 66.7%, Time: 0.0310 seconds\n",
      "Epoch[98/100], Loss: 0.0000, R2: 0.9973, L0: 8.0000, Dead Features: 62.5%, Time: 0.0293 seconds\n",
      "Epoch[99/100], Loss: 0.0000, R2: 0.9996, L0: 8.0000, Dead Features: 66.7%, Time: 0.0288 seconds\n",
      "Epoch[100/100], Loss: 0.0000, R2: 0.9997, L0: 8.0000, Dead Features: 66.7%, Time: 0.0293 seconds\n",
      "\n",
      "‚úÖ Training completed!\n",
      "üìà Final loss: 0.000007\n",
      "üìà Final reconstruction MSE: 0.000265\n",
      "üìà Final L1 penalty: 0.000000\n"
     ]
    }
   ],
   "execution_count": 90
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T23:09:23.842882Z",
     "start_time": "2025-11-13T23:09:23.810378Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Step 6: Save trained TopKSAE\n",
    "print(\"üíæ Saving trained TopKSAE...\")\n",
    "\n",
    "# Save using TopKSAE's save method (saves overcomplete model + our metadata)\n",
    "sae.save(\n",
    "    name=\"topk_sae_model\",\n",
    "    path=SAE_MODEL_PATH.parent\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ TopKSAE saved to: {SAE_MODEL_PATH}\")\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-14 00:09:23,841 [INFO] amber.mechanistic.sae.modules.topk_sae: Saved TopKSAE to store/sshleifer_tiny-gpt2/topk_sae_model.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Saving trained TopKSAE...\n",
      "‚úÖ TopKSAE saved to: store/sshleifer_tiny-gpt2/topk_sae_model.pt\n"
     ]
    }
   ],
   "execution_count": 91
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T23:09:57.591698Z",
     "start_time": "2025-11-13T23:09:57.555647Z"
    }
   },
   "source": [
    "# Step 7: Save run metadata for next example\n",
    "import json\n",
    "\n",
    "run_metadata = {\n",
    "    \"run_id\": RUN_ID,\n",
    "    \"layer_signature\": LAYER_SIGNATURE,\n",
    "    \"hidden_dim\": hidden_dim,\n",
    "    \"n_latents\": sae.context.n_latents,\n",
    "    \"k\": sae.k,\n",
    "    \"model_id\": MODEL_ID,\n",
    "    \"model_dir\": str(MODEL_DIR),\n",
    "    \"dataset\": HF_DATASET,\n",
    "    \"data_limit\": DATA_LIMIT,\n",
    "    \"sae_model_path\": str(SAE_MODEL_PATH),\n",
    "    \"store_dir\": str(STORE_DIR),\n",
    "    \"cache_dir\": str(CACHE_DIR),\n",
    "    \"training_history\": history,\n",
    "}\n",
    "\n",
    "# Save metadata to model-specific directory\n",
    "with open(METADATA_PATH, \"w\") as f:\n",
    "    json.dump(run_metadata, f, indent=2)\n",
    "\n",
    "print(f\"üìã Training metadata saved to: {METADATA_PATH}\")\n",
    "print()\n",
    "print(\"üéâ TopKSAE training completed successfully!\")\n",
    "print(f\"üìÅ All files saved under model directory: {MODEL_DIR}\")\n",
    "print(\"üìù Next: Run 02_attach_sae_and_save_texts.ipynb to attach the TopKSAE and collect top texts\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìã Training metadata saved to: store/sshleifer_tiny-gpt2/training_metadata.json\n",
      "\n",
      "üéâ TopKSAE training completed successfully!\n",
      "üìÅ All files saved under model directory: store/sshleifer_tiny-gpt2\n",
      "üìù Next: Run 02_attach_sae_and_save_texts.ipynb to attach the TopKSAE and collect top texts\n"
     ]
    }
   ],
   "execution_count": 92
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T23:08:45.942109Z",
     "start_time": "2025-11-13T23:02:09.920419Z"
    }
   },
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
