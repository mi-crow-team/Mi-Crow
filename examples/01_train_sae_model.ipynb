{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 1: Training SAE Model\n",
    "\n",
    "This notebook demonstrates how to:\n",
    "1. Load a language model and dataset\n",
    "2. Save activations from a specific layer\n",
    "3. Train a Sparse Autoencoder (SAE) on those activations\n",
    "4. Save the trained SAE model\n",
    "\n",
    "The trained SAE will be saved to `outputs/sae_model.pt` for use in the next example.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup and imports\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "from amber.store import LocalStore\n",
    "from amber.adapters.text_snippet_dataset import TextSnippetDataset\n",
    "from amber.core.language_model import LanguageModel\n",
    "from amber.mechanistic.autoencoder.autoencoder import Autoencoder\n",
    "from amber.mechanistic.autoencoder.train import SAETrainer, SAETrainingConfig\n",
    "\n",
    "print(\"‚úÖ Imports completed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-28T22:43:00.133452Z",
     "start_time": "2025-10-28T22:43:00.115282Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starting SAE Training Example\n",
      "üì± Using device: cpu\n",
      "üîß Model: sshleifer/tiny-gpt2\n",
      "üìä Dataset: roneneldan/TinyStories\n",
      "üéØ Target layer: gpt2lmheadmodel_transformer_h_0_attn_c_attn\n",
      "\n",
      "‚úÖ Output directories created\n"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "MODEL_ID = \"sshleifer/tiny-gpt2\"  # Small model for quick experimentation\n",
    "HF_DATASET = \"roneneldan/TinyStories\"\n",
    "DATA_SPLIT = \"train\"\n",
    "TEXT_FIELD = \"text\"\n",
    "DATA_LIMIT = 1000  # Number of text samples to use\n",
    "MAX_LENGTH = 64    # Maximum sequence length\n",
    "BATCH_SIZE_SAVE = 16  # Batch size for saving activations\n",
    "BATCH_SIZE_TRAIN = 32  # Batch size for SAE training\n",
    "\n",
    "# Choose which layer to hook - you can inspect available layers with model.layers.print_layer_names()\n",
    "LAYER_SIGNATURE = 'gpt2lmheadmodel_transformer_h_0_attn_c_attn'  # Attention layer (better activations)\n",
    "\n",
    "# Storage locations\n",
    "CACHE_DIR = Path(\"outputs/cache\")\n",
    "STORE_DIR = Path(\"outputs/store\")\n",
    "RUN_ID = f\"sae_training_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "SAE_MODEL_PATH = Path(\"outputs/sae_model.pt\")\n",
    "\n",
    "# Device configuration\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "DTYPE = torch.float16 if torch.cuda.is_available() else None  # Use half precision on GPU\n",
    "\n",
    "print(\"üöÄ Starting SAE Training Example\")\n",
    "print(f\"üì± Using device: {DEVICE}\")\n",
    "print(f\"üîß Model: {MODEL_ID}\")\n",
    "print(f\"üìä Dataset: {HF_DATASET}\")\n",
    "print(f\"üéØ Target layer: {LAYER_SIGNATURE}\")\n",
    "print()\n",
    "\n",
    "# Create output directories\n",
    "CACHE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "STORE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "print(\"‚úÖ Output directories created\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-28T22:43:01.151213Z",
     "start_time": "2025-10-28T22:43:00.140252Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì• Loading language model...\n",
      "üîç Available layers:\n",
      "gpt2lmheadmodel_transformer: No weight\n",
      "gpt2lmheadmodel_transformer_wte: torch.Size([50257, 2])\n",
      "gpt2lmheadmodel_transformer_wpe: torch.Size([1024, 2])\n",
      "gpt2lmheadmodel_transformer_drop: No weight\n",
      "gpt2lmheadmodel_transformer_h: No weight\n",
      "gpt2lmheadmodel_transformer_h_0: No weight\n",
      "gpt2lmheadmodel_transformer_h_0_ln_1: torch.Size([2])\n",
      "gpt2lmheadmodel_transformer_h_0_attn: No weight\n",
      "gpt2lmheadmodel_transformer_h_0_attn_c_attn: torch.Size([2, 6])\n",
      "gpt2lmheadmodel_transformer_h_0_attn_c_proj: torch.Size([2, 2])\n",
      "gpt2lmheadmodel_transformer_h_0_attn_attn_dropout: No weight\n",
      "gpt2lmheadmodel_transformer_h_0_attn_resid_dropout: No weight\n",
      "gpt2lmheadmodel_transformer_h_0_ln_2: torch.Size([2])\n",
      "gpt2lmheadmodel_transformer_h_0_mlp: No weight\n",
      "gpt2lmheadmodel_transformer_h_0_mlp_c_fc: torch.Size([2, 8])\n",
      "gpt2lmheadmodel_transformer_h_0_mlp_c_proj: torch.Size([8, 2])\n",
      "gpt2lmheadmodel_transformer_h_0_mlp_act: No weight\n",
      "gpt2lmheadmodel_transformer_h_0_mlp_dropout: No weight\n",
      "gpt2lmheadmodel_transformer_h_1: No weight\n",
      "gpt2lmheadmodel_transformer_h_1_ln_1: torch.Size([2])\n",
      "gpt2lmheadmodel_transformer_h_1_attn: No weight\n",
      "gpt2lmheadmodel_transformer_h_1_attn_c_attn: torch.Size([2, 6])\n",
      "gpt2lmheadmodel_transformer_h_1_attn_c_proj: torch.Size([2, 2])\n",
      "gpt2lmheadmodel_transformer_h_1_attn_attn_dropout: No weight\n",
      "gpt2lmheadmodel_transformer_h_1_attn_resid_dropout: No weight\n",
      "gpt2lmheadmodel_transformer_h_1_ln_2: torch.Size([2])\n",
      "gpt2lmheadmodel_transformer_h_1_mlp: No weight\n",
      "gpt2lmheadmodel_transformer_h_1_mlp_c_fc: torch.Size([2, 8])\n",
      "gpt2lmheadmodel_transformer_h_1_mlp_c_proj: torch.Size([8, 2])\n",
      "gpt2lmheadmodel_transformer_h_1_mlp_act: No weight\n",
      "gpt2lmheadmodel_transformer_h_1_mlp_dropout: No weight\n",
      "gpt2lmheadmodel_transformer_ln_f: torch.Size([2])\n",
      "gpt2lmheadmodel_lm_head: torch.Size([50257, 2])\n",
      "‚úÖ Model loaded: sshleifer_tiny-gpt2\n",
      "üì± Device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Load language model with context\n",
    "print(\"üì• Loading language model...\")\n",
    "\n",
    "\n",
    "# Load model using context\n",
    "lm = LanguageModel.from_huggingface(MODEL_ID)\n",
    "lm.model.to(DEVICE)\n",
    "\n",
    "# Print available layers for reference\n",
    "print(\"üîç Available layers:\")\n",
    "lm.layers.print_layer_names()\n",
    "print(f\"‚úÖ Model loaded: {lm.model_id}\")\n",
    "print(f\"üì± Device: {DEVICE}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-28T22:43:02.560703Z",
     "start_time": "2025-10-28T22:43:01.166494Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì• Loading dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1000/1000 [00:00<00:00, 487313.12 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded 1000 text samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Load dataset\n",
    "print(\"üì• Loading dataset...\")\n",
    "dataset = TextSnippetDataset.from_huggingface(\n",
    "    HF_DATASET,\n",
    "    split=DATA_SPLIT,\n",
    "    cache_dir=str(CACHE_DIR),\n",
    "    text_field=TEXT_FIELD,\n",
    "    limit=DATA_LIMIT,\n",
    ")\n",
    "print(f\"‚úÖ Loaded {len(dataset)} text samples\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-28T22:43:09.914185Z",
     "start_time": "2025-10-28T22:43:02.572469Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Saving activations...\n",
      "‚úÖ Saved 63 batches of activations\n",
      "üìÅ Run ID: sae_training_20251028_234300\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Save activations\n",
    "print(\"üíæ Saving activations...\")\n",
    "store = LocalStore(STORE_DIR)\n",
    "\n",
    "lm.activations.infer_and_save(\n",
    "    dataset,\n",
    "    layer_signature=LAYER_SIGNATURE,\n",
    "    run_name=RUN_ID,\n",
    "    store=store,\n",
    "    batch_size=BATCH_SIZE_SAVE,\n",
    "    autocast=False,  # Disable autocast for consistency\n",
    ")\n",
    "\n",
    "# Verify activations were saved\n",
    "batches = store.list_run_batches(RUN_ID)\n",
    "print(f\"‚úÖ Saved {len(batches)} batches of activations\")\n",
    "print(f\"üìÅ Run ID: {RUN_ID}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-28T22:43:09.944141Z",
     "start_time": "2025-10-28T22:43:09.923904Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèóÔ∏è Creating SAE model...\n",
      "üìè Hidden dimension: 6\n",
      "üß† SAE architecture: 6 ‚Üí 24 ‚Üí 6\n",
      "üîß Context: sae_training/sae_training_20251028_234300\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Create SAE model\n",
    "print(\"üèóÔ∏è Creating SAE model...\")\n",
    "\n",
    "# Get the hidden dimension from the first batch\n",
    "first_batch = store.get_run_batch(RUN_ID, 0)\n",
    "if isinstance(first_batch, dict):\n",
    "    activations = first_batch[\"activations\"]\n",
    "else:\n",
    "    activations = first_batch[0]  # Assume first tensor is activations\n",
    "\n",
    "hidden_dim = activations.shape[-1]  # Last dimension is hidden size\n",
    "print(f\"üìè Hidden dimension: {hidden_dim}\")\n",
    "\n",
    "# Create SAE directly (context is created internally)\n",
    "sae = Autoencoder(\n",
    "    n_latents=hidden_dim * 4,  # 4x expansion factor\n",
    "    n_inputs=hidden_dim,\n",
    "    activation=\"TopK_8\",  # TopK with k=8 for sparsity\n",
    "    tied=False,  # Untied weights for better reconstruction\n",
    "    init_method=\"kaiming\",\n",
    "    device=DEVICE,\n",
    ")\n",
    "\n",
    "print(f\"üß† SAE architecture: {hidden_dim} ‚Üí {sae.context.n_latents} ‚Üí {hidden_dim}\")\n",
    "sae.context.experiment_name = \"sae_training\"\n",
    "sae.context.run_id = RUN_ID\n",
    "print(f\"üîß Context: {sae.context.experiment_name}/{sae.context.run_id}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-28T22:43:11.113939Z",
     "start_time": "2025-10-28T22:43:09.952389Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèãÔ∏è Training SAE...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "2025-10-28 23:43:10,498 [INFO] amber.mechanistic.autoencoder.train: [SAETrainer] device=cpu dtype=None use_amp=True grad_accum_steps=1 batch_size=32 lr=0.001\n",
      "2025-10-28 23:43:10,498 [INFO] amber.mechanistic.autoencoder.train: [SAETrainer] Starting training run_id=sae_training_20251028_234300 epochs=10 batch_size=32\n",
      "Epochs: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:00<00:00, 16.52it/s, loss=0.00000, mse=0.00000, l1=0.00609]\n",
      "2025-10-28 23:43:11,105 [INFO] amber.mechanistic.autoencoder.train: [SAETrainer] Completed training\n",
      "2025-10-28 23:43:11,107 [INFO] amber.mechanistic.autoencoder.train: [SAETrainer] Saved final SAE to: outputs/store/sae_models/sae_training_20251028_234300/final.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Training completed!\n",
      "üìà Final loss: 0.000001\n",
      "üìà Final reconstruction MSE: 0.000001\n",
      "üìà Final L1 penalty: 0.006089\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Train SAE\n",
    "print(\"üèãÔ∏è Training SAE...\")\n",
    "\n",
    "config = SAETrainingConfig(\n",
    "    epochs=10,\n",
    "    batch_size=BATCH_SIZE_TRAIN,\n",
    "    lr=1e-3,\n",
    "    l1_lambda=1e-4,  # L1 sparsity penalty\n",
    "    device=DEVICE,\n",
    "    max_batches_per_epoch=50,  # Limit batches per epoch for quick training\n",
    "    project_decoder_grads=True,  # Project gradients for stability\n",
    "    renorm_decoder_every=5,  # Renormalize decoder weights\n",
    "    verbose=True,  # Enable progress logging\n",
    ")\n",
    "\n",
    "trainer = SAETrainer(sae, store, RUN_ID, config)\n",
    "history = trainer.train()\n",
    "\n",
    "print(\"‚úÖ Training completed!\")\n",
    "print(f\"üìà Final loss: {history['loss'][-1]:.6f}\")\n",
    "print(f\"üìà Final reconstruction MSE: {history['recon_mse'][-1]:.6f}\")\n",
    "print(f\"üìà Final L1 penalty: {history['l1'][-1]:.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-28T22:43:11.148536Z",
     "start_time": "2025-10-28T22:43:11.125012Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Saving trained SAE...\n",
      "‚úÖ SAE saved to: outputs/sae_model.pt\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Save trained SAE\n",
    "print(\"üíæ Saving trained SAE...\")\n",
    "\n",
    "# Add metadata about the training\n",
    "metadata = {\n",
    "    \"dataset\": HF_DATASET,\n",
    "    \"data_limit\": DATA_LIMIT,\n",
    "    \"hidden_dim\": hidden_dim,\n",
    "    \"n_latents\": sae.context.n_latents,\n",
    "    \"activation\": \"TopK_8\",\n",
    "    \"training_config\": {\n",
    "        \"epochs\": config.epochs,\n",
    "        \"batch_size\": config.batch_size,\n",
    "        \"lr\": config.lr,\n",
    "        \"l1_lambda\": config.l1_lambda,\n",
    "    },\n",
    "    \"run_id\": RUN_ID,\n",
    "    \"training_history\": history,\n",
    "}\n",
    "\n",
    "sae.save(\n",
    "    name=\"sae_model\",\n",
    "    path=SAE_MODEL_PATH.parent,\n",
    "    run_metadata=metadata,\n",
    "    layer_signature=LAYER_SIGNATURE,\n",
    "    model_id=MODEL_ID,\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ SAE saved to: {SAE_MODEL_PATH}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-28T22:43:11.171522Z",
     "start_time": "2025-10-28T22:43:11.151279Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìã Training metadata saved to: outputs/training_metadata.json\n",
      "\n",
      "üéâ SAE training completed successfully!\n",
      "üìù Next: Run 02_attach_sae_and_save_texts.ipynb to attach the SAE and collect top texts\n"
     ]
    }
   ],
   "source": [
    "# Step 7: Save run metadata for next example\n",
    "import json\n",
    "\n",
    "run_metadata = {\n",
    "    \"run_id\": RUN_ID,\n",
    "    \"layer_signature\": LAYER_SIGNATURE,\n",
    "    \"hidden_dim\": hidden_dim,\n",
    "    \"n_latents\": sae.context.n_latents,\n",
    "    \"model_id\": MODEL_ID,\n",
    "    \"dataset\": HF_DATASET,\n",
    "    \"data_limit\": DATA_LIMIT,\n",
    "    \"sae_model_path\": str(SAE_MODEL_PATH),\n",
    "    \"store_dir\": str(STORE_DIR),\n",
    "    \"cache_dir\": str(CACHE_DIR),\n",
    "}\n",
    "\n",
    "metadata_path = Path(\"outputs/training_metadata.json\")\n",
    "with open(metadata_path, \"w\") as f:\n",
    "    json.dump(run_metadata, f, indent=2)\n",
    "\n",
    "print(f\"üìã Training metadata saved to: {metadata_path}\")\n",
    "print()\n",
    "print(\"üéâ SAE training completed successfully!\")\n",
    "print(\"üìù Next: Run 02_attach_sae_and_save_texts.ipynb to attach the SAE and collect top texts\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-28T22:43:11.175547Z",
     "start_time": "2025-10-28T22:43:11.174183Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
