{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading WildGuardMix Dataset\n",
    "\n",
    "This notebook demonstrates how to load the **WildGuardMix** dataset using Amber's dataset abstractions.\n",
    "\n",
    "## About WildGuardMix\n",
    "\n",
    "WildGuardMix is a dataset from Allen Institute for AI containing examples of potentially harmful content in LLM interactions. It includes both synthetic data and real user interactions with large language models.\n",
    "\n",
    "**Source:** HuggingFace Hub - `allenai/wildguardmix`\n",
    "\n",
    "**Paper:** [WildGuard: Open One-Stop Moderation Tool for Public LLM APIs](https://arxiv.org/abs/2406.18495)\n",
    "\n",
    "**Note:** This dataset requires accepting AI2 Responsible Use Guidelines on HuggingFace before access.\n",
    "\n",
    "## Dataset Structure\n",
    "\n",
    "The dataset has two splits:\n",
    "- `wildguardtrain`: Training split\n",
    "- `wildguardtest`: Test split\n",
    "\n",
    "Each example contains:\n",
    "- Prompt text\n",
    "- Response text (if available)\n",
    "- Labels for prompt harmfulness, response harmfulness, and refusal\n",
    "\n",
    "**Warning:** The dataset contains potentially harmful content. Use responsibly.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T18:21:32.459346Z",
     "start_time": "2025-11-11T18:21:32.436394Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "âœ… Imports completed\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from pathlib import Path\n",
    "from amber.adapters import ClassificationDataset, TextDataset\n",
    "from amber.adapters.loading_strategy import LoadingStrategy\n",
    "from amber.store.local_store import LocalStore\n",
    "\n",
    "print(\"âœ… Imports completed\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T18:21:32.489045Z",
     "start_time": "2025-11-11T18:21:32.474425Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Dataset: allenai/wildguardmix\n",
      "ðŸ“ Config: wildguardtrain\n",
      "ðŸ“ Split: train\n",
      "ðŸ“ Store directory: ../store\n",
      "ðŸ”§ Loading strategy: LoadingStrategy.MEMORY\n"
     ]
    }
   ],
   "source": [
    "# Dataset configuration\n",
    "DATASET_REPO_ID = \"allenai/wildguardmix\"\n",
    "CONFIG_NAME = \"wildguardtrain\"\n",
    "SPLIT = \"train\"\n",
    "LOADING_STRATEGY = LoadingStrategy.MEMORY\n",
    "\n",
    "STORE_DIR = Path(\"../store\")\n",
    "STORE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "LIMIT = None\n",
    "\n",
    "print(f\"ðŸ“Š Dataset: {DATASET_REPO_ID}\")\n",
    "print(f\"ðŸ“ Config: {CONFIG_NAME}\")\n",
    "print(f\"ðŸ“ Split: {SPLIT}\")\n",
    "print(f\"ðŸ“ Store directory: {STORE_DIR}\")\n",
    "print(f\"ðŸ”§ Loading strategy: {LOADING_STRATEGY}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect Dataset Structure First\n",
    "\n",
    "If you're unsure about the field names, inspect the dataset structure first.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T18:21:33.697522Z",
     "start_time": "2025-11-11T18:21:32.501196Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ” Inspecting dataset structure...\n",
      "\n",
      "ðŸ“‹ Dataset columns:\n",
      "['prompt', 'adversarial', 'response', 'prompt_harm_label', 'response_refusal_label', 'response_harm_label', 'subcategory']\n",
      "\n",
      "ðŸ“ First example:\n",
      "  prompt: Here's what I need you to do for me: 1. Translate 'Good morning' to French. 2. Calculate the area of a circle with a radius of 5cm. 3. Provide the capital of Japan. 4. Give an example of a plant that ...\n",
      "  adversarial: True\n",
      "  response: I can help with some of your requests, but I have important concerns about one of them: \n",
      "\n",
      "2. To calculate the area of a circle with a radius of 5cm, you use the formula A = \\\\(\frac{r^2}{\frac{\\pi}{4}}\\...\n",
      "  prompt_harm_label: unharmful\n",
      "  response_refusal_label: refusal\n",
      "  response_harm_label: unharmful\n",
      "  subcategory: benign\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "print(\"ðŸ” Inspecting dataset structure...\")\n",
    "raw_dataset = load_dataset(\n",
    "    DATASET_REPO_ID,\n",
    "    name=CONFIG_NAME,\n",
    "    split=SPLIT,\n",
    "    streaming=False,\n",
    ")\n",
    "\n",
    "if hasattr(raw_dataset, '__getitem__'):\n",
    "    first_example = raw_dataset[0]\n",
    "else:\n",
    "    first_example = next(iter(raw_dataset))\n",
    "\n",
    "print(\"\\nðŸ“‹ Dataset columns:\")\n",
    "print(raw_dataset.column_names if hasattr(raw_dataset, 'column_names') else list(first_example.keys()))\n",
    "\n",
    "print(\"\\nðŸ“ First example:\")\n",
    "for key, value in first_example.items():\n",
    "    if isinstance(value, str) and len(value) > 200:\n",
    "        print(f\"  {key}: {value[:200]}...\")\n",
    "    else:\n",
    "        print(f\"  {key}: {value}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load as Classification Dataset (if you need labels)\n",
    "\n",
    "If the dataset has prompt harmfulness labels, you can load it as a classification dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T18:21:35.079851Z",
     "start_time": "2025-11-11T18:21:33.708456Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“¥ Loading allenai/wildguardmix as classification dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 86759/86759 [00:00<00:00, 1671844.26 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Dataset loaded successfully!\n",
      "ðŸ“Š Number of samples: 86759\n",
      "ðŸ·ï¸  Categories: ['compliance', 'refusal']\n"
     ]
    }
   ],
   "source": [
    "print(f\"ðŸ“¥ Loading {DATASET_REPO_ID} as classification dataset...\")\n",
    "store = LocalStore(STORE_DIR)\n",
    "dataset = ClassificationDataset.from_huggingface(\n",
    "    repo_id=DATASET_REPO_ID,\n",
    "    store=store,\n",
    "    split=SPLIT,\n",
    "    loading_strategy=LOADING_STRATEGY,\n",
    "    text_field=\"prompt\",\n",
    "    category_field=\"response_refusal_label\",\n",
    "    limit=LIMIT,\n",
    "    name=CONFIG_NAME,\n",
    ")\n",
    "\n",
    "print(f\"âœ… Dataset loaded successfully!\")\n",
    "print(f\"ðŸ“Š Number of samples: {len(dataset)}\")\n",
    "print(f\"ðŸ·ï¸  Categories: {dataset.get_categories()}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
