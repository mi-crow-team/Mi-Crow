{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 3: Load Concepts and Demonstrate Activation Manipulation\n",
    "\n",
    "This notebook demonstrates how to:\n",
    "1. Load the language model and trained SAE from previous examples\n",
    "2. Load curated concepts from the manual curation process\n",
    "3. Attach the concept dictionary to the SAE\n",
    "4. Demonstrate inference with manipulated activations\n",
    "5. Create custom activation controllers to amplify or suppress specific concepts\n",
    "\n",
    "This example shows how to use curated concepts to understand and control what the model generates.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-17T20:34:22.796193Z",
     "start_time": "2025-11-17T20:34:22.764971Z"
    }
   },
   "source": [
    "# Setup and imports\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "import json\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "from amber.store import LocalStore\n",
    "from amber.language_model.language_model import LanguageModel\n",
    "from amber.mechanistic.sae.modules.topk_sae import TopKSae\n",
    "from amber.mechanistic.sae.concepts.concept_dictionary import ConceptDictionary\n",
    "\n",
    "print(\"‚úÖ Imports completed\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "‚úÖ Imports completed\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-17T20:35:21.631137Z",
     "start_time": "2025-11-17T20:35:21.597801Z"
    }
   },
   "source": [
    "# Configuration\n",
    "print(\"üöÄ Starting Concept Loading and Neuron Manipulation Example\")\n",
    "\n",
    "MODEL_ID_HF = \"sshleifer/tiny-gpt2\"\n",
    "STORE_DIR = Path(\"store\")\n",
    "MODEL_DIR = STORE_DIR / MODEL_ID_HF.replace(\"/\", \"_\")\n",
    "training_metadata_path = MODEL_DIR / \"training_metadata.json\"\n",
    "attachment_metadata_path = MODEL_DIR / \"attachment_metadata.json\"\n",
    "\n",
    "if not training_metadata_path.exists():\n",
    "    print(f\"‚ùå Error: training_metadata.json not found at {training_metadata_path}!\")\n",
    "    print(\"   Please run 01_train_sae_model.ipynb first\")\n",
    "    raise FileNotFoundError(f\"training_metadata.json not found at {training_metadata_path}\")\n",
    "\n",
    "if not attachment_metadata_path.exists():\n",
    "    print(f\"‚ö†Ô∏è Warning: attachment_metadata.json not found at {attachment_metadata_path}\")\n",
    "    print(\"   This is optional - you can still load concepts without it\")\n",
    "\n",
    "# Load metadata\n",
    "with open(training_metadata_path, \"r\") as f:\n",
    "    training_metadata = json.load(f)\n",
    "\n",
    "attachment_metadata = {}\n",
    "if attachment_metadata_path.exists():\n",
    "    with open(attachment_metadata_path, \"r\") as f:\n",
    "        attachment_metadata = json.load(f)\n",
    "\n",
    "# Configuration from metadata\n",
    "MODEL_ID = training_metadata[\"model_id\"]\n",
    "LAYER_SIGNATURE = training_metadata[\"layer_signature\"]\n",
    "SAE_MODEL_PATH = Path(training_metadata[\"sae_model_path\"])\n",
    "CACHE_DIR = Path(training_metadata.get(\"cache_dir\", MODEL_DIR / \"cache\"))\n",
    "STORE_DIR = Path(training_metadata.get(\"store_dir\", STORE_DIR))\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Check for curated concepts (saved under model directory)\n",
    "CURATED_CONCEPTS_CSV = MODEL_DIR / \"curated_concepts.csv\"\n",
    "CURATED_CONCEPTS_JSON = MODEL_DIR / \"curated_concepts.json\"\n",
    "\n",
    "if not CURATED_CONCEPTS_CSV.exists() and not CURATED_CONCEPTS_JSON.exists():\n",
    "    print(\"‚ö†Ô∏è Warning: No curated concepts found!\")\n",
    "    print(f\"   Expected at: {CURATED_CONCEPTS_CSV} or {CURATED_CONCEPTS_JSON}\")\n",
    "    print(\"   Please run the manual curation process first\")\n",
    "    print(\"   You can create a simple CSV with format: neuron_idx,concept_name,score\")\n",
    "\n",
    "print(f\"üîß Model: {MODEL_ID}\")\n",
    "print(f\"üéØ Target layer: {LAYER_SIGNATURE}\")\n",
    "print(f\"üß† SAE model: {SAE_MODEL_PATH}\")\n",
    "print(\n",
    "    f\"üìä Curated concepts: {CURATED_CONCEPTS_CSV if CURATED_CONCEPTS_CSV.exists() else (CURATED_CONCEPTS_JSON if CURATED_CONCEPTS_JSON.exists() else 'Not found')}\")\n",
    "print()\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starting Concept Loading and Neuron Manipulation Example\n",
      "‚ö†Ô∏è Warning: No curated concepts found!\n",
      "   Expected at: store/sshleifer_tiny-gpt2/curated_concepts.csv or store/sshleifer_tiny-gpt2/curated_concepts.json\n",
      "   Please run the manual curation process first\n",
      "   You can create a simple CSV with format: neuron_idx,concept_name,score\n",
      "üîß Model: sshleifer/tiny-gpt2\n",
      "üéØ Target layer: gpt2lmheadmodel_transformer_h_0_attn_c_attn\n",
      "üß† SAE model: store/sshleifer_tiny-gpt2/topk_sae_model.pt\n",
      "üìä Curated concepts: Not found\n",
      "\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-17T20:35:23.963191Z",
     "start_time": "2025-11-17T20:35:22.812360Z"
    }
   },
   "source": [
    "# Step 1: Load language model\n",
    "print(\"üì• Loading language model...\")\n",
    "\n",
    "# Create LocalStore for the model\n",
    "store = LocalStore(MODEL_DIR)\n",
    "\n",
    "# Load model and move to device\n",
    "model = LanguageModel.from_huggingface(MODEL_ID, store=store)\n",
    "model.model.to(DEVICE)\n",
    "\n",
    "# Optional: set experiment metadata\n",
    "model.context.experiment_name = \"concept_manipulation\"\n",
    "model.context.run_id = f\"manipulation_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "model.context.max_length = 64\n",
    "\n",
    "print(f\"‚úÖ Model loaded: {model.model_id}\")\n",
    "print(f\"üì± Device: {DEVICE}\")\n",
    "print(f\"üîß Context: {model.context.experiment_name}/{model.context.run_id}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì• Loading language model...\n",
      "‚úÖ Model loaded: sshleifer_tiny-gpt2\n",
      "üì± Device: cpu\n",
      "üîß Context: concept_manipulation/manipulation_20251117_213523\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-17T20:35:28.393203Z",
     "start_time": "2025-11-17T20:35:28.362206Z"
    }
   },
   "source": [
    "# Step 2: Load trained SAE\n",
    "print(\"üì• Loading trained SAE...\")\n",
    "if not SAE_MODEL_PATH.exists():\n",
    "    print(f\"‚ùå Error: SAE model not found at {SAE_MODEL_PATH}\")\n",
    "    print(\"   Please run 01_train_sae_model.ipynb first\")\n",
    "    raise FileNotFoundError(f\"SAE model not found at {SAE_MODEL_PATH}\")\n",
    "\n",
    "sae = TopKSae.load(SAE_MODEL_PATH)\n",
    "\n",
    "# Update SAE context with current experiment info\n",
    "sae.context.experiment_name = \"concept_manipulation\"\n",
    "sae.context.run_id = f\"manipulation_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "\n",
    "print(\n",
    "    f\"‚úÖ SAE loaded: {training_metadata['hidden_dim']} ‚Üí {training_metadata['n_latents']} ‚Üí {training_metadata['hidden_dim']}\")\n",
    "print(f\"üîß Context: {sae.context.experiment_name}/{sae.context.run_id}\")\n",
    "print(f\"üìä TopK parameter: k={training_metadata.get('k', 'N/A')}\")\n",
    "print(\"‚úÖ Trained SAE loaded\")\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-17 21:35:28,390 [INFO] amber.mechanistic.sae.modules.topk_sae: \n",
      "Loaded TopKSAE from store/sshleifer_tiny-gpt2/topk_sae_model.pt\n",
      "n_latents=24, n_inputs=6, k=8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì• Loading trained SAE...\n",
      "‚úÖ SAE loaded: 6 ‚Üí 24 ‚Üí 6\n",
      "üîß Context: concept_manipulation/manipulation_20251117_213528\n",
      "üìä TopK parameter: k=8\n",
      "‚úÖ Trained SAE loaded\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-17T20:34:22.860535Z",
     "start_time": "2025-11-10T20:20:49.799821Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì• Loading curated concepts...\n",
      "üìÑ Loading from JSON: store/sshleifer_tiny-gpt2/curated_concepts.json\n",
      "‚úÖ Loaded concept dictionary with 24 neurons\n",
      "üìä Total concepts: 24\n",
      "\n",
      "üîç Sample concepts:\n",
      "   Neuron 0: 'family relationships' (score: 0.900)\n",
      "   Neuron 1: 'nature and outdoors' (score: 0.900)\n",
      "   Neuron 2: 'problem solving' (score: 0.900)\n",
      "   Neuron 3: 'emotional states' (score: 0.850)\n",
      "   Neuron 4: 'social interactions' (score: 0.900)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Load curated concepts\n",
    "print(\"üì• Loading curated concepts...\")\n",
    "\n",
    "# Try to load from CSV first, then JSON\n",
    "concept_dict = None\n",
    "if CURATED_CONCEPTS_CSV.exists():\n",
    "    print(f\"üìÑ Loading from CSV: {CURATED_CONCEPTS_CSV}\")\n",
    "    concept_dict = ConceptDictionary.from_csv(CURATED_CONCEPTS_CSV, n_size=training_metadata[\"n_latents\"])\n",
    "elif CURATED_CONCEPTS_JSON.exists():\n",
    "    print(f\"üìÑ Loading from JSON: {CURATED_CONCEPTS_JSON}\")\n",
    "    concept_dict = ConceptDictionary.from_json(CURATED_CONCEPTS_JSON, n_size=training_metadata[\"n_latents\"])\n",
    "else:\n",
    "    print(\"‚ùå Error: No curated concepts file found!\")\n",
    "    print(f\"   Expected at: {CURATED_CONCEPTS_CSV} or {CURATED_CONCEPTS_JSON}\")\n",
    "    raise FileNotFoundError(\"No curated concepts file found\")\n",
    "\n",
    "print(f\"‚úÖ Loaded concept dictionary with {concept_dict.n_size} neurons\")\n",
    "print(f\"üìä Total concepts: {sum(1 for i in range(concept_dict.n_size) if concept_dict.get(i) is not None)}\")\n",
    "\n",
    "# Show some concepts\n",
    "print(\"\\nüîç Sample concepts:\")\n",
    "for neuron_idx in range(min(5, concept_dict.n_size)):\n",
    "    concept = concept_dict.get(neuron_idx)\n",
    "    if concept:\n",
    "        print(f\"   Neuron {neuron_idx}: '{concept.name}' (score: {concept.score:.3f})\")\n",
    "    else:\n",
    "        print(f\"   Neuron {neuron_idx}: no concept\")\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-17T20:34:22.860850Z",
     "start_time": "2025-11-10T20:20:49.829893Z"
    }
   },
   "outputs": [],
   "source": [
    "sae.attach_dictionary(concept_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-17T20:34:22.861368Z",
     "start_time": "2025-11-10T20:20:49.857087Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 500/500 [00:00<00:00, 285365.63 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from amber.adapters import TextDataset\n",
    "\n",
    "HF_DATASET = \"roneneldan/TinyStories\"\n",
    "DATA_SPLIT = \"train\"\n",
    "TEXT_FIELD = \"text\"\n",
    "DATA_LIMIT = 500\n",
    "MAX_LENGTH = 64\n",
    "\n",
    "dataset = TextDataset.from_huggingface(\n",
    "    HF_DATASET,\n",
    "    split=DATA_SPLIT,\n",
    "    cache_dir=str(CACHE_DIR),\n",
    "    text_field=TEXT_FIELD,\n",
    "    limit=DATA_LIMIT,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-17T20:34:22.861680Z",
     "start_time": "2025-11-10T20:20:51.614015Z"
    }
   },
   "outputs": [],
   "source": [
    "for batch_index, texts in enumerate(dataset.iter_batches(32)):\n",
    "    output = model.generate(texts)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-17T20:34:22.862033Z",
     "start_time": "2025-11-10T20:20:51.824042Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
