{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 2: Attach SAE and Save Top Texts for Neurons\n",
    "\n",
    "This notebook demonstrates how to:\n",
    "1. Load a trained SAE model from the previous example\n",
    "2. Attach the SAE to a language model\n",
    "3. Enable text tracking to collect top activating texts for each neuron\n",
    "4. Run inference on new text data to collect neuron-text associations\n",
    "5. Save the collected top texts for use in the next example\n",
    "\n",
    "The top texts will be saved to `outputs/top_texts.json` for use in the next example.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-01T00:17:26.492568Z",
     "start_time": "2025-11-01T00:17:23.913841Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adam/Projects/Inzynierka/codebase/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Imports completed\n"
     ]
    }
   ],
   "source": [
    "# Setup and imports\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "import json\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "from amber.store import LocalStore\n",
    "from amber.adapters.text_snippet_dataset import TextSnippetDataset\n",
    "from amber.core.language_model import LanguageModel\n",
    "from amber.mechanistic.autoencoder.autoencoder import Autoencoder\n",
    "\n",
    "print(\"âœ… Imports completed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-01T00:17:26.527046Z",
     "start_time": "2025-11-01T00:17:26.496851Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‹ Loaded training metadata:\n",
      "   run_id: sae_training_20251101_011640\n",
      "   layer_signature: gpt2lmheadmodel_transformer_h_0_attn_c_attn\n",
      "   hidden_dim: 6\n",
      "   n_latents: 24\n",
      "   model_id: sshleifer/tiny-gpt2\n",
      "   dataset: roneneldan/TinyStories\n",
      "   data_limit: 1000\n",
      "   sae_model_path: outputs/sae_model.pt\n",
      "   store_dir: outputs/store\n",
      "   cache_dir: outputs/cache\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load metadata from previous example\n",
    "metadata_path = Path(\"outputs/training_metadata.json\")\n",
    "if not metadata_path.exists():\n",
    "    print(\"âŒ Error: training_metadata.json not found!\")\n",
    "    print(\"   Please run 01_train_sae_model.ipynb first\")\n",
    "    raise FileNotFoundError(\"training_metadata.json not found\")\n",
    "\n",
    "with open(metadata_path, \"r\") as f:\n",
    "    metadata = json.load(f)\n",
    "\n",
    "print(\"ğŸ“‹ Loaded training metadata:\")\n",
    "for key, value in metadata.items():\n",
    "    if key != \"training_history\":  # Skip large training history\n",
    "        print(f\"   {key}: {value}\")\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-01T00:17:26.549322Z",
     "start_time": "2025-11-01T00:17:26.530627Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”— Starting SAE Attachment and Text Collection Example\n",
      "ğŸ“± Using device: cpu\n",
      "ğŸ”§ Model: sshleifer/tiny-gpt2\n",
      "ğŸ“Š Dataset: roneneldan/TinyStories\n",
      "ğŸ¯ Target layer: gpt2lmheadmodel_transformer_h_0_attn_c_attn\n",
      "ğŸ§  SAE model: outputs/sae_model.pt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "MODEL_ID = metadata[\"model_id\"]\n",
    "LAYER_SIGNATURE = metadata[\"layer_signature\"]\n",
    "SAE_MODEL_PATH = Path(metadata[\"sae_model_path\"])\n",
    "CACHE_DIR = Path(metadata[\"cache_dir\"])\n",
    "STORE_DIR = Path(metadata[\"store_dir\"])\n",
    "\n",
    "# New dataset for text collection (different from training data)\n",
    "HF_DATASET = \"roneneldan/TinyStories\"\n",
    "DATA_SPLIT = \"train\"\n",
    "TEXT_FIELD = \"text\"\n",
    "DATA_LIMIT = 500  # Smaller dataset for text collection\n",
    "MAX_LENGTH = 64\n",
    "\n",
    "# Text tracking configuration\n",
    "TOP_K = 10  # Number of top texts to track per neuron\n",
    "NEGATIVE_TRACKING = False  # Track positive activations\n",
    "\n",
    "# Device configuration\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "print(\"ğŸ”— Starting SAE Attachment and Text Collection Example\")\n",
    "print(f\"ğŸ“± Using device: {DEVICE}\")\n",
    "print(f\"ğŸ”§ Model: {MODEL_ID}\")\n",
    "print(f\"ğŸ“Š Dataset: {HF_DATASET}\")\n",
    "print(f\"ğŸ¯ Target layer: {LAYER_SIGNATURE}\")\n",
    "print(f\"ğŸ§  SAE model: {SAE_MODEL_PATH}\")\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-01T00:17:27.665848Z",
     "start_time": "2025-11-01T00:17:26.556057Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¥ Loading language model...\n",
      "âœ… Model loaded: sshleifer_tiny-gpt2\n",
      "ğŸ“± Device: cpu\n",
      "ğŸ”§ Context: sae_attachment/attachment_20251101_011727\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Load language model\n",
    "print(\"ğŸ“¥ Loading language model...\")\n",
    "\n",
    "# Load model and move to device\n",
    "model = LanguageModel.from_huggingface(MODEL_ID)\n",
    "model.model.to(DEVICE)\n",
    "\n",
    "# Optional: set experiment metadata\n",
    "model.context.experiment_name = \"sae_attachment\"\n",
    "model.context.run_id = f\"attachment_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "model.context.max_length = MAX_LENGTH\n",
    "\n",
    "print(f\"âœ… Model loaded: {model.model_id}\")\n",
    "print(f\"ğŸ“± Device: {DEVICE}\")\n",
    "print(f\"ğŸ”§ Context: {model.context.experiment_name}/{model.context.run_id}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-01T00:17:27.720840Z",
     "start_time": "2025-11-01T00:17:27.697705Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-01 01:17:27,719 [INFO] amber.mechanistic.autoencoder.autoencoder: \n",
      "Loaded model from outputs/sae_model.pt\n",
      "n_latents=24, n_inputs=6, activation=TopK_8, tied=False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¥ Loading trained SAE...\n",
      "âœ… SAE loaded: 6 â†’ 24 â†’ 6\n",
      "ğŸ”§ Context: sae_attachment/attachment_20251101_011727\n",
      "ğŸ“Š Dataset normalization: False\n",
      "ğŸ“Š Target norm: False\n",
      "ğŸ“Š Dataset mean: torch.Size([6])\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Load trained SAE\n",
    "print(\"ğŸ“¥ Loading trained SAE...\")\n",
    "if not SAE_MODEL_PATH.exists():\n",
    "    print(f\"âŒ Error: SAE model not found at {SAE_MODEL_PATH}\")\n",
    "    print(\"   Please run 01_train_sae_model.ipynb first\")\n",
    "    raise FileNotFoundError(f\"SAE model not found at {SAE_MODEL_PATH}\")\n",
    "\n",
    "sae, dataset_normalize, dataset_target_norm, dataset_mean = Autoencoder.load_model(SAE_MODEL_PATH)\n",
    "sae.to(DEVICE)\n",
    "\n",
    "# Update SAE context with current experiment info\n",
    "sae.context.experiment_name = \"sae_attachment\"\n",
    "sae.context.run_id = f\"attachment_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "\n",
    "print(f\"âœ… SAE loaded: {metadata['hidden_dim']} â†’ {metadata['n_latents']} â†’ {metadata['hidden_dim']}\")\n",
    "print(f\"ğŸ”§ Context: {sae.context.experiment_name}/{sae.context.run_id}\")\n",
    "print(f\"ğŸ“Š Dataset normalization: {dataset_normalize}\")\n",
    "if dataset_target_norm is not None:\n",
    "    print(f\"ğŸ“Š Target norm: {dataset_target_norm}\")\n",
    "if dataset_mean is not None:\n",
    "    print(f\"ğŸ“Š Dataset mean: {dataset_mean.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-01T00:17:27.741999Z",
     "start_time": "2025-11-01T00:17:27.724154Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”— Using SAE's built-in concepts for text tracking...\n",
      "âœ… Text tracking enabled: top-10 positive activations\n",
      "ğŸ”§ Context: sae_attachment/attachment_20251101_011727\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Use SAE's built-in concepts for text tracking\n",
    "print(\"ğŸ”— Using SAE's built-in concepts for text tracking...\")\n",
    "\n",
    "# Set the language model and layer signature on the SAE's context\n",
    "sae.context.lm = model\n",
    "sae.context.lm_layer_signature = LAYER_SIGNATURE\n",
    "\n",
    "# Enable text tracking via the SAE helper (sets context flags)\n",
    "sae.enable_text_tracking(\n",
    "    k=TOP_K,\n",
    "    negative=NEGATIVE_TRACKING,\n",
    ")\n",
    "\n",
    "print(f\"âœ… Text tracking enabled: top-{TOP_K} {'negative' if NEGATIVE_TRACKING else 'positive'} activations\")\n",
    "print(f\"ğŸ”§ Context: {sae.context.experiment_name}/{sae.context.run_id}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-01T00:17:29.862312Z",
     "start_time": "2025-11-01T00:17:27.745404Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¥ Loading dataset for text collection...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [00:00<00:00, 224006.84 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Loaded 500 text samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Load dataset for text collection\n",
    "print(\"ğŸ“¥ Loading dataset for text collection...\")\n",
    "dataset = TextSnippetDataset.from_huggingface(\n",
    "    HF_DATASET,\n",
    "    split=DATA_SPLIT,\n",
    "    cache_dir=str(CACHE_DIR),\n",
    "    text_field=TEXT_FIELD,\n",
    "    limit=DATA_LIMIT,\n",
    ")\n",
    "print(f\"âœ… Loaded {len(dataset)} text samples\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-01T00:17:33.650523Z",
     "start_time": "2025-11-01T00:17:29.875115Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Running inference to collect top texts...\n",
      "   Processed 160/500 samples...\n",
      "   Processed 320/500 samples...\n",
      "   Processed 480/500 samples...\n",
      "âœ… Text collection completed!\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Run inference to collect top texts\n",
    "print(\"ğŸ” Running inference to collect top texts...\")\n",
    "\n",
    "batch_size = 16\n",
    "total_batches = (len(dataset) + batch_size - 1) // batch_size\n",
    "\n",
    "for i in range(0, len(dataset), batch_size):\n",
    "    batch_end = min(i + batch_size, len(dataset))\n",
    "    batch_texts = [dataset[j] for j in range(i, batch_end)]\n",
    "\n",
    "    # Run forward pass to trigger text tracking\n",
    "    model.forwards(batch_texts)\n",
    "\n",
    "    if (i // batch_size + 1) % 10 == 0:\n",
    "        print(f\"   Processed {batch_end}/{len(dataset)} samples...\")\n",
    "\n",
    "print(\"âœ… Text collection completed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-01T00:17:33.677901Z",
     "start_time": "2025-11-01T00:17:33.660076Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š Analyzing collected top texts...\n",
      "ğŸ§  Neuron 0: 10 texts\n",
      "   1. 'Mummy and Daddy were picking flowers in the garden. Mummy picked a red daisy, Daddy picked a purple thistle and the little girl picked a beautiful lily. The lily was her favorite because it was so fluffy and white and the aroma was heavenly. \n",
      "\n",
      "Daddy said, \"Let's bring this lily inside and put it on the windowsill.\" \n",
      "\n",
      "Mummy said, \"How about we make it a surprise?\" \n",
      "\n",
      "So the family all went inside and the little girl put the lily on the windowsill. \n",
      "\n",
      "When she stepped back to admire her work, she noticed a bright yellow butterfly that had landed on the lily. The little girl smiled. \n",
      "\n",
      "Mummy said, \"Oh my, that lily looks so warm and cozy with the butterfly on top.\"\n",
      "\n",
      "The little girl nodded, delighted with her surprise. And, from that day on, the warm lily became a happy reminder of the special family day.' (score: 0.0189)\n",
      "   2. 'Once there was a generous bear. He liked to help others and was always very kind. But he had one habit that no one really knew about: he loved to eat clay!\n",
      "\n",
      "Every day he would go outside and search for clay in the woods. Then he would find a quiet spot, sit down and take a bite of the delicious clay. \n",
      "\n",
      "One day, he stumbled across two little kittens. They were feeling scared and alone, so the bear was very generous. He shared some of his clay with them and the kittens were so happy.\n",
      "\n",
      "The bear and the kittens became fast friends, and they would go out into the woods every day searching for clay. Sure enough, they always seemed to find enough clay for everyone, and soon enough it became a daily ritual.\n",
      "\n",
      "It was a wonderful friendship that would last for years - and all because of the generous bear, who was always willing to share his clay with others.' (score: 0.0189)\n",
      "   3. 'Once upon a time, the ground was dry and hard. Granny was getting ready to go to the market to buy food. Little Jack asked, Ã¢â‚¬Å“Can I come with you, Granny?Ã¢â‚¬ Granny replied, Ã¢â‚¬Å“Yes, itÃ¢â‚¬â„¢s a lovely day. LetÃ¢â‚¬â„¢s go.Ã¢â‚¬\n",
      "\n",
      "They soon arrived at the market, and Granny bought a lot of food. She told Jack, Ã¢â‚¬Å“LetÃ¢â‚¬â„¢s take this food home and bury it in the ground. We can save it for later.Ã¢â‚¬ \n",
      "\n",
      "Little Jack asked, Ã¢â‚¬Å“Why?Ã¢â‚¬ Granny said, Ã¢â‚¬Å“So that it wonÃ¢â‚¬â„¢t get eaten.Ã¢â‚¬ Little Jack helped Granny to bury the food and soon enough, the ground was full of yummy food. \n",
      "\n",
      "The next day, Granny and Little Jack went back to their garden and Little Jack started digging. To his surprise, the food he buried yesterday was still there! Granny said, Ã¢â‚¬Å“Look, Jack, our plan was successful!Ã¢â‚¬  Little Jack smiled with happiness.  They enjoyed their yummy food and lived happily ever after.' (score: 0.0189)\n",
      "   ... and 7 more\n",
      "\n",
      "ğŸ§  Neuron 1: 10 texts\n",
      "   1. 'Mummy and Daddy were picking flowers in the garden. Mummy picked a red daisy, Daddy picked a purple thistle and the little girl picked a beautiful lily. The lily was her favorite because it was so fluffy and white and the aroma was heavenly. \n",
      "\n",
      "Daddy said, \"Let's bring this lily inside and put it on the windowsill.\" \n",
      "\n",
      "Mummy said, \"How about we make it a surprise?\" \n",
      "\n",
      "So the family all went inside and the little girl put the lily on the windowsill. \n",
      "\n",
      "When she stepped back to admire her work, she noticed a bright yellow butterfly that had landed on the lily. The little girl smiled. \n",
      "\n",
      "Mummy said, \"Oh my, that lily looks so warm and cozy with the butterfly on top.\"\n",
      "\n",
      "The little girl nodded, delighted with her surprise. And, from that day on, the warm lily became a happy reminder of the special family day.' (score: 0.0376)\n",
      "   2. 'Once there was a generous bear. He liked to help others and was always very kind. But he had one habit that no one really knew about: he loved to eat clay!\n",
      "\n",
      "Every day he would go outside and search for clay in the woods. Then he would find a quiet spot, sit down and take a bite of the delicious clay. \n",
      "\n",
      "One day, he stumbled across two little kittens. They were feeling scared and alone, so the bear was very generous. He shared some of his clay with them and the kittens were so happy.\n",
      "\n",
      "The bear and the kittens became fast friends, and they would go out into the woods every day searching for clay. Sure enough, they always seemed to find enough clay for everyone, and soon enough it became a daily ritual.\n",
      "\n",
      "It was a wonderful friendship that would last for years - and all because of the generous bear, who was always willing to share his clay with others.' (score: 0.0376)\n",
      "   3. 'Once upon a time, the ground was dry and hard. Granny was getting ready to go to the market to buy food. Little Jack asked, Ã¢â‚¬Å“Can I come with you, Granny?Ã¢â‚¬ Granny replied, Ã¢â‚¬Å“Yes, itÃ¢â‚¬â„¢s a lovely day. LetÃ¢â‚¬â„¢s go.Ã¢â‚¬\n",
      "\n",
      "They soon arrived at the market, and Granny bought a lot of food. She told Jack, Ã¢â‚¬Å“LetÃ¢â‚¬â„¢s take this food home and bury it in the ground. We can save it for later.Ã¢â‚¬ \n",
      "\n",
      "Little Jack asked, Ã¢â‚¬Å“Why?Ã¢â‚¬ Granny said, Ã¢â‚¬Å“So that it wonÃ¢â‚¬â„¢t get eaten.Ã¢â‚¬ Little Jack helped Granny to bury the food and soon enough, the ground was full of yummy food. \n",
      "\n",
      "The next day, Granny and Little Jack went back to their garden and Little Jack started digging. To his surprise, the food he buried yesterday was still there! Granny said, Ã¢â‚¬Å“Look, Jack, our plan was successful!Ã¢â‚¬  Little Jack smiled with happiness.  They enjoyed their yummy food and lived happily ever after.' (score: 0.0376)\n",
      "   ... and 7 more\n",
      "\n",
      "ğŸ§  Neuron 2: 10 texts\n",
      "   1. 'A mummy and her little girl called Sarah were getting ready to go on a trip. Sarah watched as her mummy packed a big sack with lots of things.\n",
      "\n",
      "\"What's in that sack, Mummy?\" asked Sarah.\n",
      "\n",
      "Mummy replied, \"It's full of lots of fun things that we can take with us on our trip.\"\n",
      "\n",
      "Sarah asked, \"Can I take my dolly?\"\n",
      "\n",
      "Mummy replied, \"Yes of course, but you will have to pack it into the sack yourself.\"\n",
      "\n",
      "Sarah was excited and put her dolly safely into the big sack. She looked up at her mummy and smiled.\n",
      "\n",
      "On the trip, Sarah met lots of friendly people and things she had not seen before. She was having a wonderful time. \n",
      "\n",
      "When it was time to go home, Sarah remembered that she had put her dolly in the sack and so she checked to make sure it was still there. It was! \n",
      "\n",
      "Mummy said to her, \"Isn't it nice when things are packed up neatly and safely?\"\n",
      "\n",
      "Sarah nodded and smiled.\n",
      "\n",
      "The moral of the story is to be careful to always pack up things neatly and safely, which helps us to take care of our possessions.' (score: 0.0075)\n",
      "   2. 'Jack was feeling a bit sad. He wanted some wine but he didn't have any. He walked up to a store and asked the shopkeeper, \"Do you have any wine?\" \n",
      "\n",
      "The shopkeeper replied, \"Yes, I have some. It's bad though. Are you sure you want it?\" \n",
      "\n",
      "Jack thought for a moment then said, \"Yes, I will take it.\" \n",
      "\n",
      "The shopkeeper counted out two bottles of wine and handed them to Jack. Jack thanked the shopkeeper and went home. \n",
      "\n",
      "When Jack got home he opened a bottle of the bad wine and took a sip - it tasted horrible! He thought to himself, \"Maybe I should have asked for something else!\"' (score: 0.0075)\n",
      "   3. 'Frank the frog was very troubled. His fountain had broken and he was sure no one could fix it.\n",
      "\n",
      "One day Frank's best friend Sam the snail came to visit him. Sam asked, \"What's wrong Frank?\"\n",
      "\n",
      "Frank said sadly, \"My fountain is broken and I can't fix it.\" \n",
      "\n",
      "But Sam had a plan! He said, \"If you come with me I might know someone who can help you fix your fountain.\"\n",
      "\n",
      "So Frank and Sam went out into the woods, looking for help. And soon they found Snail Bob!\n",
      "\n",
      "Snail Bob smiled at Frank and said, \"Don't worry, with a bit of hard work we can get your fountain running again.\"\n",
      "\n",
      "Frank was overjoyed! He and Snail Bob got to work and soon he had a beautiful working fountain.\n",
      "\n",
      "Frank was so happy and relieved, and he thanked Snail Bob for his help. From then on, Frank and Sam made sure to visit Snail Bob to say thank you.' (score: 0.0075)\n",
      "   ... and 7 more\n",
      "\n",
      "ğŸ§  Neuron 5: 10 texts\n",
      "   1. 'Mummy and Daddy were picking flowers in the garden. Mummy picked a red daisy, Daddy picked a purple thistle and the little girl picked a beautiful lily. The lily was her favorite because it was so fluffy and white and the aroma was heavenly. \n",
      "\n",
      "Daddy said, \"Let's bring this lily inside and put it on the windowsill.\" \n",
      "\n",
      "Mummy said, \"How about we make it a surprise?\" \n",
      "\n",
      "So the family all went inside and the little girl put the lily on the windowsill. \n",
      "\n",
      "When she stepped back to admire her work, she noticed a bright yellow butterfly that had landed on the lily. The little girl smiled. \n",
      "\n",
      "Mummy said, \"Oh my, that lily looks so warm and cozy with the butterfly on top.\"\n",
      "\n",
      "The little girl nodded, delighted with her surprise. And, from that day on, the warm lily became a happy reminder of the special family day.' (score: 0.0042)\n",
      "   2. 'Once there was a generous bear. He liked to help others and was always very kind. But he had one habit that no one really knew about: he loved to eat clay!\n",
      "\n",
      "Every day he would go outside and search for clay in the woods. Then he would find a quiet spot, sit down and take a bite of the delicious clay. \n",
      "\n",
      "One day, he stumbled across two little kittens. They were feeling scared and alone, so the bear was very generous. He shared some of his clay with them and the kittens were so happy.\n",
      "\n",
      "The bear and the kittens became fast friends, and they would go out into the woods every day searching for clay. Sure enough, they always seemed to find enough clay for everyone, and soon enough it became a daily ritual.\n",
      "\n",
      "It was a wonderful friendship that would last for years - and all because of the generous bear, who was always willing to share his clay with others.' (score: 0.0042)\n",
      "   3. 'Once upon a time, the ground was dry and hard. Granny was getting ready to go to the market to buy food. Little Jack asked, Ã¢â‚¬Å“Can I come with you, Granny?Ã¢â‚¬ Granny replied, Ã¢â‚¬Å“Yes, itÃ¢â‚¬â„¢s a lovely day. LetÃ¢â‚¬â„¢s go.Ã¢â‚¬\n",
      "\n",
      "They soon arrived at the market, and Granny bought a lot of food. She told Jack, Ã¢â‚¬Å“LetÃ¢â‚¬â„¢s take this food home and bury it in the ground. We can save it for later.Ã¢â‚¬ \n",
      "\n",
      "Little Jack asked, Ã¢â‚¬Å“Why?Ã¢â‚¬ Granny said, Ã¢â‚¬Å“So that it wonÃ¢â‚¬â„¢t get eaten.Ã¢â‚¬ Little Jack helped Granny to bury the food and soon enough, the ground was full of yummy food. \n",
      "\n",
      "The next day, Granny and Little Jack went back to their garden and Little Jack started digging. To his surprise, the food he buried yesterday was still there! Granny said, Ã¢â‚¬Å“Look, Jack, our plan was successful!Ã¢â‚¬  Little Jack smiled with happiness.  They enjoyed their yummy food and lived happily ever after.' (score: 0.0042)\n",
      "   ... and 7 more\n",
      "\n",
      "ğŸ“ˆ Summary: 10/24 neurons have collected texts\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Analyze collected top texts\n",
    "print(\"ğŸ“Š Analyzing collected top texts...\")\n",
    "\n",
    "# Get top texts for a few neurons as examples\n",
    "example_neurons = [0, 1, 2, 5, 10]  # Show first few neurons\n",
    "total_neurons_with_texts = 0\n",
    "\n",
    "for neuron_idx in example_neurons:\n",
    "    if neuron_idx < metadata[\"n_latents\"]:\n",
    "        top_texts = sae.concepts.get_top_texts_for_neuron(neuron_idx)\n",
    "        if top_texts:\n",
    "            total_neurons_with_texts += 1\n",
    "            print(f\"ğŸ§  Neuron {neuron_idx}: {len(top_texts)} texts\")\n",
    "            for j, nt in enumerate(top_texts[:3]):  # Show top 3\n",
    "                print(f\"   {j + 1}. '{nt.text}' (score: {nt.score:.4f})\")\n",
    "            if len(top_texts) > 3:\n",
    "                print(f\"   ... and {len(top_texts) - 3} more\")\n",
    "            print()\n",
    "\n",
    "# Count total neurons with texts\n",
    "for neuron_idx in range(metadata[\"n_latents\"]):\n",
    "    if sae.concepts.get_top_texts_for_neuron(neuron_idx):\n",
    "        total_neurons_with_texts += 1\n",
    "\n",
    "print(f\"ğŸ“ˆ Summary: {total_neurons_with_texts}/{metadata['n_latents']} neurons have collected texts\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-01T00:17:33.699474Z",
     "start_time": "2025-11-01T00:17:33.681228Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ’¾ Saving top texts...\n",
      "ğŸ“Š Saved texts for 10 neurons\n"
     ]
    }
   ],
   "source": [
    "# Step 7: Save top texts\n",
    "print(\"ğŸ’¾ Saving top texts...\")\n",
    "sae.concepts.export_top_texts_to_json(\"outputs/top_texts.json\")\n",
    "print(f\"ğŸ“Š Saved texts for {total_neurons_with_texts} neurons\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-01T00:17:33.721243Z",
     "start_time": "2025-11-01T00:17:33.702065Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‹ Attachment metadata saved to: outputs/attachment_metadata.json\n",
      "\n",
      "ğŸ‰ SAE attachment and text collection completed successfully!\n",
      "ğŸ“ Next: Run 03_load_and_manipulate_concepts.ipynb to load and manipulate the concepts\n"
     ]
    }
   ],
   "source": [
    "# Step 9: Save metadata for next example\n",
    "attachment_metadata = {\n",
    "    \"model_id\": MODEL_ID,\n",
    "    \"layer_signature\": LAYER_SIGNATURE,\n",
    "    \"n_latents\": metadata[\"n_latents\"],\n",
    "    \"top_k\": TOP_K,\n",
    "    \"negative_tracking\": NEGATIVE_TRACKING,\n",
    "    \"dataset\": HF_DATASET,\n",
    "    \"data_limit\": DATA_LIMIT,\n",
    "    \"total_neurons_with_texts\": total_neurons_with_texts,\n",
    "    \"top_texts_path\": \"outputs/top_texts.json\",\n",
    "    \"sae_model_path\": str(SAE_MODEL_PATH),\n",
    "}\n",
    "\n",
    "attachment_metadata_path = Path(\"outputs/attachment_metadata.json\")\n",
    "with open(attachment_metadata_path, \"w\") as f:\n",
    "    json.dump(attachment_metadata, f, indent=2)\n",
    "\n",
    "print(f\"ğŸ“‹ Attachment metadata saved to: {attachment_metadata_path}\")\n",
    "print()\n",
    "print(\"ğŸ‰ SAE attachment and text collection completed successfully!\")\n",
    "print(\"ğŸ“ Next: Run 03_load_and_manipulate_concepts.ipynb to load and manipulate the concepts\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
