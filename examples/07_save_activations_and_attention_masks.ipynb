{
<<<<<<< HEAD
 "cells": [],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
=======
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Example 7: Save Activations and Attention Masks Together\n",
        "\n",
        "This notebook demonstrates how to:\n",
        "1. Load Bielik model\n",
        "2. Attach two activation saver hooks:\n",
        "   - LayerActivationDetector for layer activations\n",
        "   - ModelInputDetector for attention masks\n",
        "3. Run inference on a small dataset in batches\n",
        "4. Save both activations and attention masks per batch\n",
        "5. Verify everything was saved correctly to disk\n",
        "\n",
        "This verifies that we can fulfill the user's request to have attention masks\n",
        "easily accessible for each batch of representations, matching the activation batch structure.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Volumes/SanDiskData/Inzynierka/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Imports completed\n"
          ]
        }
      ],
      "source": [
        "# Setup and imports\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "import torch\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "\n",
        "from amber.datasets import TextDataset\n",
        "from amber.language_model.language_model import LanguageModel\n",
        "from amber.hooks.implementations.layer_activation_detector import LayerActivationDetector\n",
        "from amber.hooks.implementations.model_input_detector import ModelInputDetector\n",
        "from amber.hooks import HookType\n",
        "from amber.store.local_store import LocalStore\n",
        "from datasets import load_dataset\n",
        "\n",
        "print(\"âœ… Imports completed\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âš™ï¸ Configuration:\n",
            "   Model: speakleash/Bielik-1.5B-v3.0-Instruct\n",
            "   Device: cpu\n",
            "   Batch size: 4\n",
            "   Max length: 128\n",
            "   Dataset: roneneldan/TinyStories\n",
            "   Data limit: 10 samples\n"
          ]
        }
      ],
      "source": [
        "# Configuration\n",
        "MODEL_ID = \"speakleash/Bielik-1.5B-v3.0-Instruct\"\n",
        "STORE_DIR = Path(\"store\")\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "BATCH_SIZE = 4\n",
        "MAX_LENGTH = 128\n",
        "DATA_LIMIT = 10\n",
        "\n",
        "HF_DATASET = \"roneneldan/TinyStories\"\n",
        "TEXT_FIELD = \"text\"\n",
        "DATA_SPLIT = \"train\"\n",
        "\n",
        "print(\"âš™ï¸ Configuration:\")\n",
        "print(f\"   Model: {MODEL_ID}\")\n",
        "print(f\"   Device: {DEVICE}\")\n",
        "print(f\"   Batch size: {BATCH_SIZE}\")\n",
        "print(f\"   Max length: {MAX_LENGTH}\")\n",
        "print(f\"   Dataset: {HF_DATASET}\")\n",
        "print(f\"   Data limit: {DATA_LIMIT} samples\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ“¥ Loading Bielik model...\n",
            "âœ… Model loaded: speakleash_Bielik-1.5B-v3.0-Instruct\n",
            "ðŸ“± Device: cpu\n",
            "ðŸ“ Store location: store\n"
          ]
        }
      ],
      "source": [
        "# Step 1: Load Bielik model\n",
        "print(\"ðŸ“¥ Loading Bielik model...\")\n",
        "\n",
        "store = LocalStore(STORE_DIR)\n",
        "lm = LanguageModel.from_huggingface(MODEL_ID, store=store)\n",
        "lm.model.to(DEVICE)\n",
        "\n",
        "print(f\"âœ… Model loaded: {lm.model_id}\")\n",
        "print(f\"ðŸ“± Device: {DEVICE}\")\n",
        "print(f\"ðŸ“ Store location: {lm.store.base_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ“Š Creating dataset...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Saving the dataset (1/1 shards): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:00<00:00, 575.15 examples/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Dataset created: 10 samples\n",
            "ðŸ“ Sample text: One day, a little girl named Lily found a needle in her room. She knew it was difficult to play with...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Step 2: Create small dataset\n",
        "print(\"ðŸ“Š Creating dataset...\")\n",
        "\n",
        "hf_dataset = load_dataset(HF_DATASET, split=DATA_SPLIT, streaming=False)\n",
        "if DATA_LIMIT > 0:\n",
        "    hf_dataset = hf_dataset.select(range(min(DATA_LIMIT, len(hf_dataset))))\n",
        "\n",
        "dataset = TextDataset(hf_dataset, store=store, text_field=TEXT_FIELD)\n",
        "\n",
        "print(f\"âœ… Dataset created: {len(dataset)} samples\")\n",
        "print(f\"ðŸ“ Sample text: {dataset[0][:100]}...\" if len(dataset[0]) > 100 else f\"ðŸ“ Sample text: {dataset[0]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ” Finding layers to attach activation detectors...\n",
            "ðŸ“‹ Found 422 layers\n",
            "âœ… Selected layer 1: llamaforcausallm_model_layers_0_self_attn\n",
            "âœ… Selected layer 2: llamaforcausallm_model_layers_0_self_attn_q_proj\n"
          ]
        }
      ],
      "source": [
        "# Step 3: Find two layers to attach activation detectors to\n",
        "print(\"ðŸ” Finding layers to attach activation detectors...\")\n",
        "\n",
        "layer_names = lm.layers.get_layer_names()\n",
        "print(f\"ðŸ“‹ Found {len(layer_names)} layers\")\n",
        "\n",
        "# Find transformer layers (usually contains 'transformer' or 'layer')\n",
        "transformer_layers = [name for name in layer_names if 'transformer' in name.lower() or 'layer' in name.lower()]\n",
        "if transformer_layers:\n",
        "    # Try to find attention layers\n",
        "    attention_layers = [name for name in transformer_layers if 'attn' in name.lower()]\n",
        "    if len(attention_layers) >= 2:\n",
        "        LAYER_SIGNATURE_1 = attention_layers[0]\n",
        "        LAYER_SIGNATURE_2 = attention_layers[1]\n",
        "    elif len(attention_layers) == 1:\n",
        "        LAYER_SIGNATURE_1 = attention_layers[0]\n",
        "        # Find another layer (maybe MLP or norm)\n",
        "        other_layers = [name for name in transformer_layers if name != LAYER_SIGNATURE_1]\n",
        "        if other_layers:\n",
        "            LAYER_SIGNATURE_2 = other_layers[0]\n",
        "        else:\n",
        "            LAYER_SIGNATURE_2 = transformer_layers[1] if len(transformer_layers) > 1 else None\n",
        "    else:\n",
        "        LAYER_SIGNATURE_1 = transformer_layers[0]\n",
        "        LAYER_SIGNATURE_2 = transformer_layers[1] if len(transformer_layers) > 1 else None\n",
        "else:\n",
        "    LAYER_SIGNATURE_1 = layer_names[0] if layer_names else None\n",
        "    LAYER_SIGNATURE_2 = layer_names[1] if len(layer_names) > 1 else None\n",
        "\n",
        "if LAYER_SIGNATURE_1 and LAYER_SIGNATURE_2:\n",
        "    print(f\"âœ… Selected layer 1: {LAYER_SIGNATURE_1}\")\n",
        "    print(f\"âœ… Selected layer 2: {LAYER_SIGNATURE_2}\")\n",
        "else:\n",
        "    raise ValueError(\"Could not find two suitable layers\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ”§ Attaching hooks...\n",
            "\n",
            "1ï¸âƒ£ Setting up ModelInputDetector for attention masks...\n",
            "   ðŸ“ Added 'attention_masks' to layers registry\n",
            "   âœ… Attached to root model\n",
            "   ðŸ†” Hook ID: attention_mask_detector\n",
            "\n",
            "2ï¸âƒ£ Setting up LayerActivationDetector for first layer...\n",
            "   âœ… Attached to layer: llamaforcausallm_model_layers_0_self_attn\n",
            "   ðŸ†” Hook ID: activation_detector_1\n",
            "\n",
            "3ï¸âƒ£ Setting up LayerActivationDetector for second layer...\n",
            "   âœ… Attached to layer: llamaforcausallm_model_layers_0_self_attn_q_proj\n",
            "   ðŸ†” Hook ID: activation_detector_2\n",
            "\n",
            "âœ… All hooks attached successfully!\n"
          ]
        }
      ],
      "source": [
        "# Step 4: Attach three hooks (one ModelInputDetector and two LayerActivationDetectors)\n",
        "print(\"ðŸ”§ Attaching hooks...\")\n",
        "print()\n",
        "\n",
        "# Hook 1: ModelInputDetector for attention masks\n",
        "print(\"1ï¸âƒ£ Setting up ModelInputDetector for attention masks...\")\n",
        "attention_mask_layer_sig = \"attention_masks\"\n",
        "root_model = lm.model\n",
        "\n",
        "# Add layer signature to registry for root model\n",
        "if attention_mask_layer_sig not in lm.layers.name_to_layer:\n",
        "    lm.layers.name_to_layer[attention_mask_layer_sig] = root_model\n",
        "    print(f\"   ðŸ“ Added '{attention_mask_layer_sig}' to layers registry\")\n",
        "\n",
        "attention_mask_detector = ModelInputDetector(\n",
        "    layer_signature=attention_mask_layer_sig,\n",
        "    hook_id=\"attention_mask_detector\",\n",
        "    save_input_ids=False,\n",
        "    save_attention_mask=True,\n",
        ")\n",
        "attention_mask_hook_id = lm.layers.register_hook(\n",
        "    attention_mask_layer_sig, attention_mask_detector, HookType.PRE_FORWARD\n",
        ")\n",
        "print(f\"   âœ… Attached to root model\")\n",
        "print(f\"   ðŸ†” Hook ID: {attention_mask_hook_id}\")\n",
        "print()\n",
        "\n",
        "# Hook 2: LayerActivationDetector for first layer activations\n",
        "print(\"2ï¸âƒ£ Setting up LayerActivationDetector for first layer...\")\n",
        "activation_detector_1 = LayerActivationDetector(\n",
        "    layer_signature=LAYER_SIGNATURE_1,\n",
        "    hook_id=\"activation_detector_1\"\n",
        ")\n",
        "activation_hook_id_1 = lm.layers.register_hook(LAYER_SIGNATURE_1, activation_detector_1, HookType.FORWARD)\n",
        "print(f\"   âœ… Attached to layer: {LAYER_SIGNATURE_1}\")\n",
        "print(f\"   ðŸ†” Hook ID: {activation_hook_id_1}\")\n",
        "print()\n",
        "\n",
        "# Hook 3: LayerActivationDetector for second layer activations\n",
        "print(\"3ï¸âƒ£ Setting up LayerActivationDetector for second layer...\")\n",
        "activation_detector_2 = LayerActivationDetector(\n",
        "    layer_signature=LAYER_SIGNATURE_2,\n",
        "    hook_id=\"activation_detector_2\"\n",
        ")\n",
        "activation_hook_id_2 = lm.layers.register_hook(LAYER_SIGNATURE_2, activation_detector_2, HookType.FORWARD)\n",
        "print(f\"   âœ… Attached to layer: {LAYER_SIGNATURE_2}\")\n",
        "print(f\"   ðŸ†” Hook ID: {activation_hook_id_2}\")\n",
        "print()\n",
        "print(\"âœ… All hooks attached successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸš€ Running inference on dataset in batches...\n",
            "   Batch size: 4\n",
            "   Total samples: 10\n",
            "\n",
            "ðŸ“ Run name: activations_with_masks_20251217_164006\n",
            "\n",
            "âœ… Saved batch 0 (4 samples)\n",
            "âœ… Saved batch 1 (4 samples)\n",
            "âœ… Saved batch 2 (2 samples)\n",
            "\n",
            "âœ… Completed! Saved 3 batches\n"
          ]
        }
      ],
      "source": [
        "# Step 5: Run inference on dataset in batches and save\n",
        "print(\"ðŸš€ Running inference on dataset in batches...\")\n",
        "print(f\"   Batch size: {BATCH_SIZE}\")\n",
        "print(f\"   Total samples: {len(dataset)}\")\n",
        "print()\n",
        "\n",
        "run_name = f\"activations_with_masks_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
        "print(f\"ðŸ“ Run name: {run_name}\")\n",
        "print()\n",
        "\n",
        "batch_counter = 0\n",
        "\n",
        "with torch.inference_mode():\n",
        "    for batch_index, batch in enumerate(dataset.iter_batches(BATCH_SIZE)):\n",
        "        # Extract texts from batch\n",
        "        texts = dataset.extract_texts_from_batch(batch)\n",
        "        \n",
        "        # Clear previous captures\n",
        "        attention_mask_detector.clear_captured()\n",
        "        activation_detector_1.clear_captured()\n",
        "        activation_detector_2.clear_captured()\n",
        "        \n",
        "        # Run inference\n",
        "        output, encodings = lm.forwards(\n",
        "            texts,\n",
        "            tok_kwargs={\n",
        "                \"max_length\": MAX_LENGTH,\n",
        "                \"padding\": True,\n",
        "                \"truncation\": True,\n",
        "                \"add_special_tokens\": True\n",
        "            },\n",
        "            autocast=False,\n",
        "        )\n",
        "        \n",
        "        # Save detector metadata for this batch\n",
        "        lm.save_detector_metadata(run_name, batch_index)\n",
        "        \n",
        "        batch_counter += 1\n",
        "        print(f\"âœ… Saved batch {batch_index} ({len(texts)} samples)\")\n",
        "\n",
        "print()\n",
        "print(f\"âœ… Completed! Saved {batch_counter} batches\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ” Verifying saved data...\n",
            "\n",
            "ðŸ“¦ Found 3 batches in store\n",
            "\n",
            "ðŸ“Š Batch 0 structure:\n",
            "   Layers with data: ['attention_masks', 'llamaforcausallm_model_layers_0_self_attn', 'llamaforcausallm_model_layers_0_self_attn_q_proj']\n",
            "\n",
            "âœ… Activations found:\n",
            "   Shape: torch.Size([4, 128, 1536])  # [batch_size, seq_len, d_model]\n",
            "   Dtype: torch.float32\n",
            "   Device: cpu\n",
            "\n",
            "âœ… Attention masks found:\n",
            "   Shape: torch.Size([4, 128])  # [batch_size, seq_len]\n",
            "   Dtype: torch.bool\n",
            "   Device: cpu\n",
            "   Sample values (first 5 tokens of first 3 samples):\n",
            "   [[False, True, True, True, True], [False, True, True, True, True], [False, True, True, True, True]]\n"
          ]
        }
      ],
      "source": [
        "# Step 6: Verify saved data\n",
        "print(\"ðŸ” Verifying saved data...\")\n",
        "print()\n",
        "\n",
        "# Get list of batches\n",
        "batches = lm.context.store.list_run_batches(run_name)\n",
        "print(f\"ðŸ“¦ Found {len(batches)} batches in store\")\n",
        "print()\n",
        "\n",
        "# Load first batch to inspect\n",
        "batch_idx = 0\n",
        "retrieved_metadata, retrieved_tensors = lm.context.store.get_detector_metadata(run_name, batch_idx)\n",
        "\n",
        "print(f\"ðŸ“Š Batch {batch_idx} structure:\")\n",
        "print(f\"   Layers with data: {list(retrieved_tensors.keys())}\")\n",
        "print()\n",
        "\n",
        "# Check activations\n",
        "if str(LAYER_SIGNATURE_1) in retrieved_tensors:\n",
        "    activations = retrieved_tensors[str(LAYER_SIGNATURE_1)].get(\"activations\")\n",
        "    if activations is not None:\n",
        "        print(f\"âœ… Activations found:\")\n",
        "        print(f\"   Shape: {activations.shape}  # [batch_size, seq_len, d_model]\")\n",
        "        print(f\"   Dtype: {activations.dtype}\")\n",
        "        print(f\"   Device: {activations.device}\")\n",
        "    else:\n",
        "        print(\"âŒ Activations not found\")\n",
        "else:\n",
        "    print(f\"âŒ Layer {LAYER_SIGNATURE_1} not found in saved data\")\n",
        "print()\n",
        "\n",
        "# Check attention masks\n",
        "if \"attention_masks\" in retrieved_tensors:\n",
        "    attention_mask = retrieved_tensors[\"attention_masks\"].get(\"attention_mask\")\n",
        "    if attention_mask is not None:\n",
        "        print(f\"âœ… Attention masks found:\")\n",
        "        print(f\"   Shape: {attention_mask.shape}  # [batch_size, seq_len]\")\n",
        "        print(f\"   Dtype: {attention_mask.dtype}\")\n",
        "        print(f\"   Device: {attention_mask.device}\")\n",
        "        print(f\"   Sample values (first 5 tokens of first 3 samples):\")\n",
        "        print(f\"   {attention_mask[:3, :5].tolist()}\")\n",
        "    else:\n",
        "        print(\"âŒ Attention mask not found\")\n",
        "else:\n",
        "    print(\"âŒ Attention masks layer not found in saved data\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ”— Verifying activation-attention mask matching...\n",
            "\n",
            "ðŸ“Š Shape comparison:\n",
            "   Activations: torch.Size([4, 128, 1536])  # [batch_size, seq_len, d_model]\n",
            "   Attention mask: torch.Size([4, 128])  # [batch_size, seq_len]\n",
            "\n",
            "âœ… Shapes match perfectly!\n",
            "\n",
            "ðŸ’¡ Example: Filtering activations for regular (non-padding) tokens:\n",
            "\n",
            "   Sample 0:\n",
            "      Total tokens: 128\n",
            "      Regular tokens (non-padding): 127\n",
            "      Padding tokens: 1\n",
            "\n",
            "      Filtered activations shape: torch.Size([127, 1536])\n",
            "      âœ… Successfully filtered to only regular tokens!\n"
          ]
        }
      ],
      "source": [
        "# Step 7: Verify shapes match and demonstrate usage\n",
        "print(\"ðŸ”— Verifying activation-attention mask matching...\")\n",
        "print()\n",
        "\n",
        "if str(LAYER_SIGNATURE_1) in retrieved_tensors and \"attention_masks\" in retrieved_tensors:\n",
        "    activations = retrieved_tensors[str(LAYER_SIGNATURE_1)][\"activations\"]\n",
        "    attention_mask = retrieved_tensors[\"attention_masks\"][\"attention_mask\"]\n",
        "    \n",
        "    batch_size, seq_len, d_model = activations.shape\n",
        "    mask_batch_size, mask_seq_len = attention_mask.shape\n",
        "    \n",
        "    print(f\"ðŸ“Š Shape comparison:\")\n",
        "    print(f\"   Activations: {activations.shape}  # [batch_size, seq_len, d_model]\")\n",
        "    print(f\"   Attention mask: {attention_mask.shape}  # [batch_size, seq_len]\")\n",
        "    print()\n",
        "    \n",
        "    if batch_size == mask_batch_size and seq_len == mask_seq_len:\n",
        "        print(\"âœ… Shapes match perfectly!\")\n",
        "        print()\n",
        "        \n",
        "        # Demonstrate filtering activations using attention mask\n",
        "        print(\"ðŸ’¡ Example: Filtering activations for regular (non-padding) tokens:\")\n",
        "        print()\n",
        "        \n",
        "        sample_idx = 0\n",
        "        sample_activations = activations[sample_idx]  # [seq_len, d_model]\n",
        "        sample_mask = attention_mask[sample_idx]  # [seq_len]\n",
        "        \n",
        "        num_regular_tokens = sample_mask.sum().item()\n",
        "        print(f\"   Sample {sample_idx}:\")\n",
        "        print(f\"      Total tokens: {seq_len}\")\n",
        "        print(f\"      Regular tokens (non-padding): {num_regular_tokens}\")\n",
        "        print(f\"      Padding tokens: {seq_len - num_regular_tokens}\")\n",
        "        print()\n",
        "        \n",
        "        # Filter activations to only regular tokens\n",
        "        regular_activations = sample_activations[sample_mask.bool()]  # [num_regular_tokens, d_model]\n",
        "        print(f\"      Filtered activations shape: {regular_activations.shape}\")\n",
        "        print(f\"      âœ… Successfully filtered to only regular tokens!\")\n",
        "    else:\n",
        "        print(\"âŒ Shape mismatch!\")\n",
        "        print(f\"   Batch size: {batch_size} vs {mask_batch_size}\")\n",
        "        print(f\"   Sequence length: {seq_len} vs {mask_seq_len}\")\n",
        "else:\n",
        "    print(\"âŒ Cannot verify - missing activations or attention masks\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ” Verifying all batches...\n",
            "\n",
            "âœ… Batch 0: layer1 torch.Size([4, 128, 1536]), layer2 torch.Size([4, 128, 1536]), mask torch.Size([4, 128])\n",
            "âœ… Batch 1: layer1 torch.Size([4, 128, 1536]), layer2 torch.Size([4, 128, 1536]), mask torch.Size([4, 128])\n",
            "âœ… Batch 2: layer1 torch.Size([2, 128, 1536]), layer2 torch.Size([2, 128, 1536]), mask torch.Size([2, 128])\n",
            "\n",
            "âœ… All batches verified successfully!\n",
            "ðŸ“ Run name: activations_with_masks_20251209_213113\n",
            "ðŸ“ Store location: store\n",
            "\n",
            "ðŸ’¡ Summary:\n",
            "   - Activations saved per batch: [batch_size, seq_len, d_model]\n",
            "   - Attention masks saved per batch: [batch_size, seq_len]\n",
            "   - Both are easily accessible and matched per batch\n",
            "   - No need to run separate inference for attention masks\n"
          ]
        }
      ],
      "source": [
        "# Step 8: Verify all batches\n",
        "print(\"ðŸ” Verifying all batches...\")\n",
        "print()\n",
        "\n",
        "all_batches_valid = True\n",
        "for batch_idx in range(len(batches)):\n",
        "    retrieved_metadata, retrieved_tensors = lm.store.get_detector_metadata(run_name, batch_idx)\n",
        "    \n",
        "    has_activations_1 = str(LAYER_SIGNATURE_1) in retrieved_tensors and \\\n",
        "                        \"activations\" in retrieved_tensors[str(LAYER_SIGNATURE_1)]\n",
        "    has_activations_2 = str(LAYER_SIGNATURE_2) in retrieved_tensors and \\\n",
        "                        \"activations\" in retrieved_tensors[str(LAYER_SIGNATURE_2)]\n",
        "    has_attention_mask = \"attention_masks\" in retrieved_tensors and \\\n",
        "                        \"attention_mask\" in retrieved_tensors[\"attention_masks\"]\n",
        "    \n",
        "    if has_activations_1 and has_activations_2 and has_attention_mask:\n",
        "        activations_1 = retrieved_tensors[str(LAYER_SIGNATURE_1)][\"activations\"]\n",
        "        activations_2 = retrieved_tensors[str(LAYER_SIGNATURE_2)][\"activations\"]\n",
        "        attention_mask = retrieved_tensors[\"attention_masks\"][\"attention_mask\"]\n",
        "        \n",
        "        # Verify shapes match\n",
        "        if (activations_1.shape[:2] == attention_mask.shape and\n",
        "            activations_2.shape[:2] == attention_mask.shape):\n",
        "            print(f\"âœ… Batch {batch_idx}: layer1 {activations_1.shape}, layer2 {activations_2.shape}, mask {attention_mask.shape}\")\n",
        "        else:\n",
        "            print(f\"âŒ Batch {batch_idx}: shape mismatch!\")\n",
        "            all_batches_valid = False\n",
        "    else:\n",
        "        print(f\"âŒ Batch {batch_idx}: missing data (layer1: {has_activations_1}, layer2: {has_activations_2}, mask: {has_attention_mask})\")\n",
        "        all_batches_valid = False\n",
        "\n",
        "print()\n",
        "if all_batches_valid:\n",
        "    print(\"âœ… All batches verified successfully!\")\n",
        "    print(f\"ðŸ“ Run name: {run_name}\")\n",
        "    print(f\"ðŸ“ Store location: {lm.context.store.base_path}\")\n",
        "    print()\n",
        "    print(\"ðŸ’¡ Summary:\")\n",
        "    print(f\"   - Activations saved per batch: [batch_size, seq_len, d_model]\")\n",
        "    print(f\"   - Attention masks saved per batch: [batch_size, seq_len]\")\n",
        "    print(f\"   - Both are easily accessible and matched per batch\")\n",
        "    print(f\"   - No need to run separate inference for attention masks\")\n",
        "else:\n",
        "    print(\"âŒ Some batches failed verification\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "This example demonstrated:\n",
        "\n",
        "1. âœ… **Loading Bielik model** - Successfully loaded from HuggingFace\n",
        "2. âœ… **Attaching two activation saver hooks** - LayerActivationDetector and ModelInputDetector\n",
        "3. âœ… **Running inference on dataset** - Processed dataset in batches\n",
        "4. âœ… **Saving both activations and attention masks** - Saved per batch, matching structure\n",
        "5. âœ… **Verification** - Confirmed all data saved correctly to disk\n",
        "\n",
        "**Key Benefits:**\n",
        "- Attention masks are saved per batch, matching activation batch structure\n",
        "- Both are easily accessible from the same batch using the store API\n",
        "- No need to run separate inference to get attention masks\n",
        "- Shapes match perfectly: activations `[batch_size, seq_len, d_model]` and masks `[batch_size, seq_len]`\n",
        "- Can easily filter activations to only regular (non-padding) tokens using attention masks\n",
        "\n",
        "**Conclusion:** âœ… The user's request can be fulfilled with the current tools!\n",
        "We can attach both LayerActivationDetector and ModelInputDetector, run inference once,\n",
        "and save both activations and attention masks together per batch."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    }
>>>>>>> 3075f09 (unimportant: run notebooks)
  },
  "language_info": {
   "name": "python",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
