{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Example 7: Save Activations and Attention Masks Together\n",
        "\n",
        "This notebook demonstrates how to:\n",
        "1. Load Bielik model\n",
        "2. Attach two activation saver hooks:\n",
        "   - LayerActivationDetector for layer activations\n",
        "   - ModelInputDetector for attention masks\n",
        "3. Run inference on a small dataset in batches\n",
        "4. Save both activations and attention masks per batch\n",
        "5. Verify everything was saved correctly to disk\n",
        "\n",
        "This verifies that we can fulfill the user's request to have attention masks\n",
        "easily accessible for each batch of representations, matching the activation batch structure.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n",
            "‚úÖ Imports completed\n"
          ]
        }
      ],
      "source": [
        "# Setup and imports\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "import torch\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "\n",
        "from amber.datasets import TextDataset\n",
        "from amber.language_model.language_model import LanguageModel\n",
        "from amber.hooks.implementations.layer_activation_detector import LayerActivationDetector\n",
        "from amber.hooks.implementations.model_input_detector import ModelInputDetector\n",
        "from amber.hooks import HookType\n",
        "from amber.store.local_store import LocalStore\n",
        "from datasets import load_dataset\n",
        "\n",
        "print(\"‚úÖ Imports completed\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚öôÔ∏è Configuration:\n",
            "   Model: speakleash/Bielik-1.5B-v3.0-Instruct\n",
            "   Device: cpu\n",
            "   Batch size: 4\n",
            "   Max length: 128\n",
            "   Dataset: roneneldan/TinyStories\n",
            "   Data limit: 10 samples\n"
          ]
        }
      ],
      "source": [
        "# Configuration\n",
        "MODEL_ID = \"speakleash/Bielik-1.5B-v3.0-Instruct\"\n",
        "STORE_DIR = Path(\"store\")\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "BATCH_SIZE = 4\n",
        "MAX_LENGTH = 128\n",
        "DATA_LIMIT = 10\n",
        "\n",
        "HF_DATASET = \"roneneldan/TinyStories\"\n",
        "TEXT_FIELD = \"text\"\n",
        "DATA_SPLIT = \"train\"\n",
        "\n",
        "print(\"‚öôÔ∏è Configuration:\")\n",
        "print(f\"   Model: {MODEL_ID}\")\n",
        "print(f\"   Device: {DEVICE}\")\n",
        "print(f\"   Batch size: {BATCH_SIZE}\")\n",
        "print(f\"   Max length: {MAX_LENGTH}\")\n",
        "print(f\"   Dataset: {HF_DATASET}\")\n",
        "print(f\"   Data limit: {DATA_LIMIT} samples\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üì• Loading Bielik model...\n",
            "‚úÖ Model loaded: speakleash_Bielik-1.5B-v3.0-Instruct\n",
            "üì± Device: cpu\n",
            "üìÅ Store location: store\n"
          ]
        }
      ],
      "source": [
        "# Step 1: Load Bielik model\n",
        "print(\"üì• Loading Bielik model...\")\n",
        "\n",
        "store = LocalStore(STORE_DIR)\n",
        "lm = LanguageModel.from_huggingface(MODEL_ID, store=store)\n",
        "lm.model.to(DEVICE)\n",
        "\n",
        "print(f\"‚úÖ Model loaded: {lm.model_id}\")\n",
        "print(f\"üì± Device: {DEVICE}\")\n",
        "print(f\"üìÅ Store location: {lm.store.base_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìä Creating dataset...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Saving the dataset (1/1 shards): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:00<00:00, 5252.07 examples/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Dataset created: 10 samples\n",
            "üìù Sample text: One day, a little girl named Lily found a needle in her room. She knew it was difficult to play with...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Step 2: Create small dataset\n",
        "print(\"üìä Creating dataset...\")\n",
        "\n",
        "hf_dataset = load_dataset(HF_DATASET, split=DATA_SPLIT, streaming=False)\n",
        "if DATA_LIMIT > 0:\n",
        "    hf_dataset = hf_dataset.select(range(min(DATA_LIMIT, len(hf_dataset))))\n",
        "\n",
        "dataset = TextDataset(hf_dataset, store=store, text_field=TEXT_FIELD)\n",
        "\n",
        "print(f\"‚úÖ Dataset created: {len(dataset)} samples\")\n",
        "print(f\"üìù Sample text: {dataset[0][:100]}...\" if len(dataset[0]) > 100 else f\"üìù Sample text: {dataset[0]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîç Finding layers to attach activation detectors...\n",
            "üìã Found 422 layers\n",
            "‚úÖ Selected layer 1: llamaforcausallm_model_layers_0_self_attn\n",
            "‚úÖ Selected layer 2: llamaforcausallm_model_layers_0_self_attn_q_proj\n"
          ]
        }
      ],
      "source": [
        "# Step 3: Find two layers to attach activation detectors to\n",
        "print(\"üîç Finding layers to attach activation detectors...\")\n",
        "\n",
        "layer_names = lm.layers.get_layer_names()\n",
        "print(f\"üìã Found {len(layer_names)} layers\")\n",
        "\n",
        "# Find transformer layers (usually contains 'transformer' or 'layer')\n",
        "transformer_layers = [name for name in layer_names if 'transformer' in name.lower() or 'layer' in name.lower()]\n",
        "if transformer_layers:\n",
        "    # Try to find attention layers\n",
        "    attention_layers = [name for name in transformer_layers if 'attn' in name.lower()]\n",
        "    if len(attention_layers) >= 2:\n",
        "        LAYER_SIGNATURE_1 = attention_layers[0]\n",
        "        LAYER_SIGNATURE_2 = attention_layers[1]\n",
        "    elif len(attention_layers) == 1:\n",
        "        LAYER_SIGNATURE_1 = attention_layers[0]\n",
        "        # Find another layer (maybe MLP or norm)\n",
        "        other_layers = [name for name in transformer_layers if name != LAYER_SIGNATURE_1]\n",
        "        if other_layers:\n",
        "            LAYER_SIGNATURE_2 = other_layers[0]\n",
        "        else:\n",
        "            LAYER_SIGNATURE_2 = transformer_layers[1] if len(transformer_layers) > 1 else None\n",
        "    else:\n",
        "        LAYER_SIGNATURE_1 = transformer_layers[0]\n",
        "        LAYER_SIGNATURE_2 = transformer_layers[1] if len(transformer_layers) > 1 else None\n",
        "else:\n",
        "    LAYER_SIGNATURE_1 = layer_names[0] if layer_names else None\n",
        "    LAYER_SIGNATURE_2 = layer_names[1] if len(layer_names) > 1 else None\n",
        "\n",
        "if LAYER_SIGNATURE_1 and LAYER_SIGNATURE_2:\n",
        "    print(f\"‚úÖ Selected layer 1: {LAYER_SIGNATURE_1}\")\n",
        "    print(f\"‚úÖ Selected layer 2: {LAYER_SIGNATURE_2}\")\n",
        "else:\n",
        "    raise ValueError(\"Could not find two suitable layers\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîß Attaching hooks...\n",
            "\n",
            "1Ô∏è‚É£ Setting up ModelInputDetector for attention masks...\n",
            "   üìù Added 'attention_masks' to layers registry\n",
            "   ‚úÖ Attached to root model\n",
            "   üÜî Hook ID: attention_mask_detector\n",
            "\n",
            "2Ô∏è‚É£ Setting up LayerActivationDetector for first layer...\n",
            "   ‚úÖ Attached to layer: llamaforcausallm_model_layers_0_self_attn\n",
            "   üÜî Hook ID: activation_detector_1\n",
            "\n",
            "3Ô∏è‚É£ Setting up LayerActivationDetector for second layer...\n",
            "   ‚úÖ Attached to layer: llamaforcausallm_model_layers_0_self_attn_q_proj\n",
            "   üÜî Hook ID: activation_detector_2\n",
            "\n",
            "‚úÖ All hooks attached successfully!\n"
          ]
        }
      ],
      "source": [
        "# Step 4: Attach three hooks (one ModelInputDetector and two LayerActivationDetectors)\n",
        "print(\"üîß Attaching hooks...\")\n",
        "print()\n",
        "\n",
        "# Hook 1: ModelInputDetector for attention masks\n",
        "print(\"1Ô∏è‚É£ Setting up ModelInputDetector for attention masks...\")\n",
        "attention_mask_layer_sig = \"attention_masks\"\n",
        "root_model = lm.model\n",
        "\n",
        "# Add layer signature to registry for root model\n",
        "if attention_mask_layer_sig not in lm.layers.name_to_layer:\n",
        "    lm.layers.name_to_layer[attention_mask_layer_sig] = root_model\n",
        "    print(f\"   üìù Added '{attention_mask_layer_sig}' to layers registry\")\n",
        "\n",
        "attention_mask_detector = ModelInputDetector(\n",
        "    layer_signature=attention_mask_layer_sig,\n",
        "    hook_id=\"attention_mask_detector\",\n",
        "    save_input_ids=False,\n",
        "    save_attention_mask=True,\n",
        ")\n",
        "attention_mask_hook_id = lm.layers.register_hook(\n",
        "    attention_mask_layer_sig, attention_mask_detector, HookType.PRE_FORWARD\n",
        ")\n",
        "print(f\"   ‚úÖ Attached to root model\")\n",
        "print(f\"   üÜî Hook ID: {attention_mask_hook_id}\")\n",
        "print()\n",
        "\n",
        "# Hook 2: LayerActivationDetector for first layer activations\n",
        "print(\"2Ô∏è‚É£ Setting up LayerActivationDetector for first layer...\")\n",
        "activation_detector_1 = LayerActivationDetector(\n",
        "    layer_signature=LAYER_SIGNATURE_1,\n",
        "    hook_id=\"activation_detector_1\"\n",
        ")\n",
        "activation_hook_id_1 = lm.layers.register_hook(LAYER_SIGNATURE_1, activation_detector_1, HookType.FORWARD)\n",
        "print(f\"   ‚úÖ Attached to layer: {LAYER_SIGNATURE_1}\")\n",
        "print(f\"   üÜî Hook ID: {activation_hook_id_1}\")\n",
        "print()\n",
        "\n",
        "# Hook 3: LayerActivationDetector for second layer activations\n",
        "print(\"3Ô∏è‚É£ Setting up LayerActivationDetector for second layer...\")\n",
        "activation_detector_2 = LayerActivationDetector(\n",
        "    layer_signature=LAYER_SIGNATURE_2,\n",
        "    hook_id=\"activation_detector_2\"\n",
        ")\n",
        "activation_hook_id_2 = lm.layers.register_hook(LAYER_SIGNATURE_2, activation_detector_2, HookType.FORWARD)\n",
        "print(f\"   ‚úÖ Attached to layer: {LAYER_SIGNATURE_2}\")\n",
        "print(f\"   üÜî Hook ID: {activation_hook_id_2}\")\n",
        "print()\n",
        "print(\"‚úÖ All hooks attached successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üöÄ Running inference on dataset in batches...\n",
            "   Batch size: 4\n",
            "   Total samples: 10\n",
            "\n",
            "üìÅ Run name: activations_with_masks_20251209_213113\n",
            "\n",
            "‚úÖ Saved batch 0 (4 samples)\n",
            "‚úÖ Saved batch 1 (4 samples)\n",
            "‚úÖ Saved batch 2 (2 samples)\n",
            "\n",
            "‚úÖ Completed! Saved 3 batches\n"
          ]
        }
      ],
      "source": [
        "# Step 5: Run inference on dataset in batches and save\n",
        "print(\"üöÄ Running inference on dataset in batches...\")\n",
        "print(f\"   Batch size: {BATCH_SIZE}\")\n",
        "print(f\"   Total samples: {len(dataset)}\")\n",
        "print()\n",
        "\n",
        "run_name = f\"activations_with_masks_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
        "print(f\"üìÅ Run name: {run_name}\")\n",
        "print()\n",
        "\n",
        "batch_counter = 0\n",
        "\n",
        "with torch.inference_mode():\n",
        "    for batch_index, batch in enumerate(dataset.iter_batches(BATCH_SIZE)):\n",
        "        # Extract texts from batch\n",
        "        texts = dataset.extract_texts_from_batch(batch)\n",
        "        \n",
        "        # Clear previous captures\n",
        "        attention_mask_detector.clear_captured()\n",
        "        activation_detector_1.clear_captured()\n",
        "        activation_detector_2.clear_captured()\n",
        "        \n",
        "        # Run inference\n",
        "        output, encodings = lm.forwards(\n",
        "            texts,\n",
        "            tok_kwargs={\n",
        "                \"max_length\": MAX_LENGTH,\n",
        "                \"padding\": True,\n",
        "                \"truncation\": True,\n",
        "                \"add_special_tokens\": True\n",
        "            },\n",
        "            autocast=False,\n",
        "        )\n",
        "        \n",
        "        # For HuggingFace models, we need to manually set attention masks from encodings\n",
        "        # because pre_forward hook doesn't receive kwargs\n",
        "        attention_mask_detector.set_inputs_from_encodings(encodings, module=lm.model)\n",
        "        \n",
        "        # Save detector metadata for this batch\n",
        "        lm.save_detector_metadata(run_name, batch_index)\n",
        "        \n",
        "        batch_counter += 1\n",
        "        print(f\"‚úÖ Saved batch {batch_index} ({len(texts)} samples)\")\n",
        "\n",
        "print()\n",
        "print(f\"‚úÖ Completed! Saved {batch_counter} batches\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîç Verifying saved data...\n",
            "\n",
            "üì¶ Found 3 batches in store\n",
            "\n",
            "üìä Batch 0 structure:\n",
            "   Layers with data: ['attention_masks', 'llamaforcausallm_model_layers_0_self_attn', 'llamaforcausallm_model_layers_0_self_attn_q_proj']\n",
            "\n",
            "‚úÖ Activations found:\n",
            "   Shape: torch.Size([4, 128, 1536])  # [batch_size, seq_len, d_model]\n",
            "   Dtype: torch.float32\n",
            "   Device: cpu\n",
            "\n",
            "‚úÖ Attention masks found:\n",
            "   Shape: torch.Size([4, 128])  # [batch_size, seq_len]\n",
            "   Dtype: torch.bool\n",
            "   Device: cpu\n",
            "   Sample values (first 5 tokens of first 3 samples):\n",
            "   [[False, True, True, True, True], [False, True, True, True, True], [False, True, True, True, True]]\n"
          ]
        }
      ],
      "source": [
        "# Step 6: Verify saved data\n",
        "print(\"üîç Verifying saved data...\")\n",
        "print()\n",
        "\n",
        "# Get list of batches\n",
        "batches = lm.context.store.list_run_batches(run_name)\n",
        "print(f\"üì¶ Found {len(batches)} batches in store\")\n",
        "print()\n",
        "\n",
        "# Load first batch to inspect\n",
        "batch_idx = 0\n",
        "retrieved_metadata, retrieved_tensors = lm.context.store.get_detector_metadata(run_name, batch_idx)\n",
        "\n",
        "print(f\"üìä Batch {batch_idx} structure:\")\n",
        "print(f\"   Layers with data: {list(retrieved_tensors.keys())}\")\n",
        "print()\n",
        "\n",
        "# Check activations\n",
        "if str(LAYER_SIGNATURE) in retrieved_tensors:\n",
        "    activations = retrieved_tensors[str(LAYER_SIGNATURE)].get(\"activations\")\n",
        "    if activations is not None:\n",
        "        print(f\"‚úÖ Activations found:\")\n",
        "        print(f\"   Shape: {activations.shape}  # [batch_size, seq_len, d_model]\")\n",
        "        print(f\"   Dtype: {activations.dtype}\")\n",
        "        print(f\"   Device: {activations.device}\")\n",
        "    else:\n",
        "        print(\"‚ùå Activations not found\")\n",
        "else:\n",
        "    print(f\"‚ùå Layer {LAYER_SIGNATURE} not found in saved data\")\n",
        "print()\n",
        "\n",
        "# Check attention masks\n",
        "if \"attention_masks\" in retrieved_tensors:\n",
        "    attention_mask = retrieved_tensors[\"attention_masks\"].get(\"attention_mask\")\n",
        "    if attention_mask is not None:\n",
        "        print(f\"‚úÖ Attention masks found:\")\n",
        "        print(f\"   Shape: {attention_mask.shape}  # [batch_size, seq_len]\")\n",
        "        print(f\"   Dtype: {attention_mask.dtype}\")\n",
        "        print(f\"   Device: {attention_mask.device}\")\n",
        "        print(f\"   Sample values (first 5 tokens of first 3 samples):\")\n",
        "        print(f\"   {attention_mask[:3, :5].tolist()}\")\n",
        "    else:\n",
        "        print(\"‚ùå Attention mask not found\")\n",
        "else:\n",
        "    print(\"‚ùå Attention masks layer not found in saved data\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîó Verifying activation-attention mask matching...\n",
            "\n",
            "üìä Shape comparison:\n",
            "   Activations: torch.Size([4, 128, 1536])  # [batch_size, seq_len, d_model]\n",
            "   Attention mask: torch.Size([4, 128])  # [batch_size, seq_len]\n",
            "\n",
            "‚úÖ Shapes match perfectly!\n",
            "\n",
            "üí° Example: Filtering activations for regular (non-padding) tokens:\n",
            "\n",
            "   Sample 0:\n",
            "      Total tokens: 128\n",
            "      Regular tokens (non-padding): 127\n",
            "      Padding tokens: 1\n",
            "\n",
            "      Filtered activations shape: torch.Size([127, 1536])\n",
            "      ‚úÖ Successfully filtered to only regular tokens!\n"
          ]
        }
      ],
      "source": [
        "# Step 7: Verify shapes match and demonstrate usage\n",
        "print(\"üîó Verifying activation-attention mask matching...\")\n",
        "print()\n",
        "\n",
        "if str(LAYER_SIGNATURE) in retrieved_tensors and \"attention_masks\" in retrieved_tensors:\n",
        "    activations = retrieved_tensors[str(LAYER_SIGNATURE)][\"activations\"]\n",
        "    attention_mask = retrieved_tensors[\"attention_masks\"][\"attention_mask\"]\n",
        "    \n",
        "    batch_size, seq_len, d_model = activations.shape\n",
        "    mask_batch_size, mask_seq_len = attention_mask.shape\n",
        "    \n",
        "    print(f\"üìä Shape comparison:\")\n",
        "    print(f\"   Activations: {activations.shape}  # [batch_size, seq_len, d_model]\")\n",
        "    print(f\"   Attention mask: {attention_mask.shape}  # [batch_size, seq_len]\")\n",
        "    print()\n",
        "    \n",
        "    if batch_size == mask_batch_size and seq_len == mask_seq_len:\n",
        "        print(\"‚úÖ Shapes match perfectly!\")\n",
        "        print()\n",
        "        \n",
        "        # Demonstrate filtering activations using attention mask\n",
        "        print(\"üí° Example: Filtering activations for regular (non-padding) tokens:\")\n",
        "        print()\n",
        "        \n",
        "        sample_idx = 0\n",
        "        sample_activations = activations[sample_idx]  # [seq_len, d_model]\n",
        "        sample_mask = attention_mask[sample_idx]  # [seq_len]\n",
        "        \n",
        "        num_regular_tokens = sample_mask.sum().item()\n",
        "        print(f\"   Sample {sample_idx}:\")\n",
        "        print(f\"      Total tokens: {seq_len}\")\n",
        "        print(f\"      Regular tokens (non-padding): {num_regular_tokens}\")\n",
        "        print(f\"      Padding tokens: {seq_len - num_regular_tokens}\")\n",
        "        print()\n",
        "        \n",
        "        # Filter activations to only regular tokens\n",
        "        regular_activations = sample_activations[sample_mask.bool()]  # [num_regular_tokens, d_model]\n",
        "        print(f\"      Filtered activations shape: {regular_activations.shape}\")\n",
        "        print(f\"      ‚úÖ Successfully filtered to only regular tokens!\")\n",
        "    else:\n",
        "        print(\"‚ùå Shape mismatch!\")\n",
        "        print(f\"   Batch size: {batch_size} vs {mask_batch_size}\")\n",
        "        print(f\"   Sequence length: {seq_len} vs {mask_seq_len}\")\n",
        "else:\n",
        "    print(\"‚ùå Cannot verify - missing activations or attention masks\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîç Verifying all batches...\n",
            "\n",
            "‚úÖ Batch 0: layer1 torch.Size([4, 128, 1536]), layer2 torch.Size([4, 128, 1536]), mask torch.Size([4, 128])\n",
            "‚úÖ Batch 1: layer1 torch.Size([4, 128, 1536]), layer2 torch.Size([4, 128, 1536]), mask torch.Size([4, 128])\n",
            "‚úÖ Batch 2: layer1 torch.Size([2, 128, 1536]), layer2 torch.Size([2, 128, 1536]), mask torch.Size([2, 128])\n",
            "\n",
            "‚úÖ All batches verified successfully!\n",
            "üìÅ Run name: activations_with_masks_20251209_213113\n",
            "üìÅ Store location: store\n",
            "\n",
            "üí° Summary:\n",
            "   - Activations saved per batch: [batch_size, seq_len, d_model]\n",
            "   - Attention masks saved per batch: [batch_size, seq_len]\n",
            "   - Both are easily accessible and matched per batch\n",
            "   - No need to run separate inference for attention masks\n"
          ]
        }
      ],
      "source": [
        "# Step 8: Verify all batches\n",
        "print(\"üîç Verifying all batches...\")\n",
        "print()\n",
        "\n",
        "all_batches_valid = True\n",
        "for batch_idx in range(len(batches)):\n",
        "    retrieved_metadata, retrieved_tensors = lm.store.get_detector_metadata(run_name, batch_idx)\n",
        "    \n",
        "    has_activations_1 = str(LAYER_SIGNATURE_1) in retrieved_tensors and \\\n",
        "                        \"activations\" in retrieved_tensors[str(LAYER_SIGNATURE_1)]\n",
        "    has_activations_2 = str(LAYER_SIGNATURE_2) in retrieved_tensors and \\\n",
        "                        \"activations\" in retrieved_tensors[str(LAYER_SIGNATURE_2)]\n",
        "    has_attention_mask = \"attention_masks\" in retrieved_tensors and \\\n",
        "                        \"attention_mask\" in retrieved_tensors[\"attention_masks\"]\n",
        "    \n",
        "    if has_activations_1 and has_activations_2 and has_attention_mask:\n",
        "        activations_1 = retrieved_tensors[str(LAYER_SIGNATURE_1)][\"activations\"]\n",
        "        activations_2 = retrieved_tensors[str(LAYER_SIGNATURE_2)][\"activations\"]\n",
        "        attention_mask = retrieved_tensors[\"attention_masks\"][\"attention_mask\"]\n",
        "        \n",
        "        # Verify shapes match\n",
        "        if (activations_1.shape[:2] == attention_mask.shape and\n",
        "            activations_2.shape[:2] == attention_mask.shape):\n",
        "            print(f\"‚úÖ Batch {batch_idx}: layer1 {activations_1.shape}, layer2 {activations_2.shape}, mask {attention_mask.shape}\")\n",
        "        else:\n",
        "            print(f\"‚ùå Batch {batch_idx}: shape mismatch!\")\n",
        "            all_batches_valid = False\n",
        "    else:\n",
        "        print(f\"‚ùå Batch {batch_idx}: missing data (layer1: {has_activations_1}, layer2: {has_activations_2}, mask: {has_attention_mask})\")\n",
        "        all_batches_valid = False\n",
        "\n",
        "print()\n",
        "if all_batches_valid:\n",
        "    print(\"‚úÖ All batches verified successfully!\")\n",
        "    print(f\"üìÅ Run name: {run_name}\")\n",
        "    print(f\"üìÅ Store location: {lm.context.store.base_path}\")\n",
        "    print()\n",
        "    print(\"üí° Summary:\")\n",
        "    print(f\"   - Activations saved per batch: [batch_size, seq_len, d_model]\")\n",
        "    print(f\"   - Attention masks saved per batch: [batch_size, seq_len]\")\n",
        "    print(f\"   - Both are easily accessible and matched per batch\")\n",
        "    print(f\"   - No need to run separate inference for attention masks\")\n",
        "else:\n",
        "    print(\"‚ùå Some batches failed verification\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "This example demonstrated:\n",
        "\n",
        "1. ‚úÖ **Loading Bielik model** - Successfully loaded from HuggingFace\n",
        "2. ‚úÖ **Attaching two activation saver hooks** - LayerActivationDetector and ModelInputDetector\n",
        "3. ‚úÖ **Running inference on dataset** - Processed dataset in batches\n",
        "4. ‚úÖ **Saving both activations and attention masks** - Saved per batch, matching structure\n",
        "5. ‚úÖ **Verification** - Confirmed all data saved correctly to disk\n",
        "\n",
        "**Key Benefits:**\n",
        "- Attention masks are saved per batch, matching activation batch structure\n",
        "- Both are easily accessible from the same batch using the store API\n",
        "- No need to run separate inference to get attention masks\n",
        "- Shapes match perfectly: activations `[batch_size, seq_len, d_model]` and masks `[batch_size, seq_len]`\n",
        "- Can easily filter activations to only regular (non-padding) tokens using attention masks\n",
        "\n",
        "**Conclusion:** ‚úÖ The user's request can be fulfilled with the current tools!\n",
        "We can attach both LayerActivationDetector and ModelInputDetector, run inference once,\n",
        "and save both activations and attention masks together per batch."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
