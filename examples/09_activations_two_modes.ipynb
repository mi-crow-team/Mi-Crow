{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 9: Activations in Two Modes\n",
    "\n",
    "This notebook demonstrates how to:\n",
    "1. Load Bielik model\n",
    "2. Mode 1: Save activations from texts using `save_activations()`\n",
    "3. Mode 2: Save activations from dataset using `save_activations_dataset()`\n",
    "4. Verify activations were saved correctly in both modes\n",
    "\n",
    "This shows the activations API that automatically attaches detectors and saves activations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adam/Projects/Inzynierka/codebase/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Imports completed\n"
     ]
    }
   ],
   "source": [
    "# Setup and imports\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "from amber.datasets import TextDataset\n",
    "from amber.language_model.language_model import LanguageModel\n",
    "from amber.store.local_store import LocalStore\n",
    "from datasets import load_dataset\n",
    "\n",
    "print(\"‚úÖ Imports completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚öôÔ∏è Configuration:\n",
      "   Model: speakleash/Bielik-1.5B-v3.0-Instruct\n",
      "   Device: cpu\n",
      "   Batch size: 4\n",
      "   Max length: 128\n",
      "   Dataset: roneneldan/TinyStories\n",
      "   Data limit: 10 samples\n"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "MODEL_ID = \"speakleash/Bielik-1.5B-v3.0-Instruct\"\n",
    "STORE_DIR = Path(\"store\")\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "BATCH_SIZE = 4\n",
    "MAX_LENGTH = 128\n",
    "DATA_LIMIT = 10\n",
    "\n",
    "HF_DATASET = \"roneneldan/TinyStories\"\n",
    "TEXT_FIELD = \"text\"\n",
    "DATA_SPLIT = \"train\"\n",
    "\n",
    "print(\"‚öôÔ∏è Configuration:\")\n",
    "print(f\"   Model: {MODEL_ID}\")\n",
    "print(f\"   Device: {DEVICE}\")\n",
    "print(f\"   Batch size: {BATCH_SIZE}\")\n",
    "print(f\"   Max length: {MAX_LENGTH}\")\n",
    "print(f\"   Dataset: {HF_DATASET}\")\n",
    "print(f\"   Data limit: {DATA_LIMIT} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì• Loading Bielik model...\n",
      "‚úÖ Model loaded: speakleash_Bielik-1.5B-v3.0-Instruct\n",
      "üì± Device: cpu\n",
      "üìÅ Store location: store\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Load Bielik model\n",
    "print(\"üì• Loading Bielik model...\")\n",
    "\n",
    "store = LocalStore(STORE_DIR)\n",
    "lm = LanguageModel.from_huggingface(MODEL_ID, store=store)\n",
    "lm.model.to(DEVICE)\n",
    "\n",
    "print(f\"‚úÖ Model loaded: {lm.model_id}\")\n",
    "print(f\"üì± Device: {DEVICE}\")\n",
    "print(f\"üìÅ Store location: {lm.store.base_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Finding layer to attach activation detector...\n",
      "üìã Found 422 layers\n",
      "‚úÖ Selected layer: llamaforcausallm_model_layers_0_self_attn\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Find a layer to capture activations from\n",
    "print(\"üîç Finding layer to attach activation detector...\")\n",
    "\n",
    "layer_names = lm.layers.get_layer_names()\n",
    "print(f\"üìã Found {len(layer_names)} layers\")\n",
    "\n",
    "transformer_layers = [name for name in layer_names if 'transformer' in name.lower() or 'layer' in name.lower()]\n",
    "if transformer_layers:\n",
    "    attention_layers = [name for name in transformer_layers if 'attn' in name.lower()]\n",
    "    if attention_layers:\n",
    "        LAYER_SIGNATURE = attention_layers[0]\n",
    "    else:\n",
    "        LAYER_SIGNATURE = transformer_layers[0]\n",
    "else:\n",
    "    LAYER_SIGNATURE = layer_names[0] if layer_names else None\n",
    "\n",
    "if LAYER_SIGNATURE:\n",
    "    print(f\"‚úÖ Selected layer: {LAYER_SIGNATURE}\")\n",
    "else:\n",
    "    raise ValueError(\"Could not find a suitable layer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Creating dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:00<00:00, 5098.84 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Dataset created: 10 samples\n",
      "üìù Sample text: One day, a little girl named Lily found a needle in her room. She knew it was difficult to play with...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Create small dataset\n",
    "print(\"üìä Creating dataset...\")\n",
    "\n",
    "hf_dataset = load_dataset(HF_DATASET, split=DATA_SPLIT, streaming=False)\n",
    "if DATA_LIMIT > 0:\n",
    "    hf_dataset = hf_dataset.select(range(min(DATA_LIMIT, len(hf_dataset))))\n",
    "\n",
    "dataset = TextDataset(hf_dataset, store=store, text_field=TEXT_FIELD)\n",
    "\n",
    "print(f\"‚úÖ Dataset created: {len(dataset)} samples\")\n",
    "print(f\"üìù Sample text: {dataset[0][:100]}...\" if len(dataset[0]) > 100 else f\"üìù Sample text: {dataset[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-09 22:07:26,763 [INFO] amber.language_model.activations: Starting save_activations: run=activations_texts_20251209_220726, layer=llamaforcausallm_model_layers_0_self_attn, batch_size=3, device=cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Mode 1: Save activations from texts using save_activations()\n",
      "============================================================\n",
      "\n",
      "üìù Processing 6 texts...\n",
      "   Layer: llamaforcausallm_model_layers_0_self_attn\n",
      "\n",
      "üìÅ Run name: activations_texts_20251209_220726\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-09 22:07:28,884 [INFO] amber.language_model.activations: Saved batch 0 for run=activations_texts_20251209_220726\n",
      "2025-12-09 22:07:29,674 [INFO] amber.language_model.activations: Saved batch 1 for run=activations_texts_20251209_220726\n",
      "2025-12-09 22:07:29,674 [INFO] amber.language_model.activations: Completed save_activations: run=activations_texts_20251209_220726, batches_saved=2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Activations saved!\n",
      "üìÅ Run name: activations_texts_20251209_220726\n",
      "\n",
      "üì¶ Saved 2 batches to store\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Mode 1 - Save activations from texts using save_activations()\n",
    "print(\"üöÄ Mode 1: Save activations from texts using save_activations()\")\n",
    "print(\"=\" * 60)\n",
    "print()\n",
    "\n",
    "texts = [dataset[i] for i in range(min(6, len(dataset)))]\n",
    "print(f\"üìù Processing {len(texts)} texts...\")\n",
    "print(f\"   Layer: {LAYER_SIGNATURE}\")\n",
    "print()\n",
    "\n",
    "run_name_texts = f\"activations_texts_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "print(f\"üìÅ Run name: {run_name_texts}\")\n",
    "print()\n",
    "\n",
    "run_name = lm.activations.save_activations(\n",
    "    texts,\n",
    "    layer_signature=LAYER_SIGNATURE,\n",
    "    run_name=run_name_texts,\n",
    "    batch_size=3,\n",
    "    max_length=MAX_LENGTH,\n",
    "    autocast=False,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "print()\n",
    "print(f\"‚úÖ Activations saved!\")\n",
    "print(f\"üìÅ Run name: {run_name}\")\n",
    "print()\n",
    "\n",
    "batches = lm.store.list_run_batches(run_name)\n",
    "print(f\"üì¶ Saved {len(batches)} batches to store\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Verifying saved activations from save_activations()...\n",
      "\n",
      "üìä Batch 0 structure:\n",
      "   Layers with data: ['llamaforcausallm_model_layers_0_self_attn']\n",
      "\n",
      "‚úÖ Activations found:\n",
      "   Shape: torch.Size([3, 128, 1536])\n",
      "   Dtype: torch.float32\n",
      "   Device: cpu\n",
      "\n",
      "‚úÖ Run metadata found:\n",
      "   Model: LlamaForCausalLM\n",
      "   Layer signatures: ['llamaforcausallm_model_layers_0_self_attn']\n",
      "   Batch size: 3\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Verify saved activations from save_activations()\n",
    "print(\"üîç Verifying saved activations from save_activations()...\")\n",
    "print()\n",
    "\n",
    "if len(batches) > 0:\n",
    "    batch_idx = 0\n",
    "    retrieved_metadata, retrieved_tensors = lm.store.get_detector_metadata(run_name, batch_idx)\n",
    "    \n",
    "    print(f\"üìä Batch {batch_idx} structure:\")\n",
    "    print(f\"   Layers with data: {list(retrieved_tensors.keys())}\")\n",
    "    print()\n",
    "    \n",
    "    if str(LAYER_SIGNATURE) in retrieved_tensors:\n",
    "        activations = retrieved_tensors[str(LAYER_SIGNATURE)].get(\"activations\")\n",
    "        if activations is not None:\n",
    "            print(f\"‚úÖ Activations found:\")\n",
    "            print(f\"   Shape: {activations.shape}\")\n",
    "            print(f\"   Dtype: {activations.dtype}\")\n",
    "            print(f\"   Device: {activations.device}\")\n",
    "        else:\n",
    "            print(\"‚ùå Activations not found\")\n",
    "    else:\n",
    "        print(f\"‚ùå Layer {LAYER_SIGNATURE} not found in saved data\")\n",
    "    \n",
    "    run_metadata = lm.store.get_run_metadata(run_name)\n",
    "    if run_metadata:\n",
    "        print()\n",
    "        print(f\"‚úÖ Run metadata found:\")\n",
    "        print(f\"   Model: {run_metadata.get('model', 'N/A')}\")\n",
    "        print(f\"   Layer signatures: {run_metadata.get('layer_signatures', 'N/A')}\")\n",
    "        print(f\"   Batch size: {run_metadata.get('options', {}).get('batch_size', 'N/A')}\")\n",
    "else:\n",
    "    print(\"‚ùå No batches found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-09 22:07:29,724 [INFO] amber.language_model.activations: Starting save_activations_dataset: run=activations_dataset_20251209_220729, layer=llamaforcausallm_model_layers_0_self_attn, batch_size=4, device=cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Mode 2: Save activations from dataset using save_activations_dataset()\n",
      "============================================================\n",
      "\n",
      "üìÅ Run name: activations_dataset_20251209_220729\n",
      "üìä Dataset size: 10 samples\n",
      "   Layer: llamaforcausallm_model_layers_0_self_attn\n",
      "üì¶ Batch size: 4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-09 22:07:30,775 [INFO] amber.language_model.activations: Saved batch 0 for run=activations_dataset_20251209_220729\n",
      "2025-12-09 22:07:31,832 [INFO] amber.language_model.activations: Saved batch 1 for run=activations_dataset_20251209_220729\n",
      "2025-12-09 22:07:32,405 [INFO] amber.language_model.activations: Saved batch 2 for run=activations_dataset_20251209_220729\n",
      "2025-12-09 22:07:32,405 [INFO] amber.language_model.activations: Completed save_activations_dataset: run=activations_dataset_20251209_220729, batches_saved=3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Activations saved!\n",
      "üìÅ Run name: activations_dataset_20251209_220729\n",
      "\n",
      "üì¶ Saved 3 batches to store\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Mode 2 - Save activations from dataset using save_activations_dataset()\n",
    "print(\"üöÄ Mode 2: Save activations from dataset using save_activations_dataset()\")\n",
    "print(\"=\" * 60)\n",
    "print()\n",
    "\n",
    "run_name_dataset = f\"activations_dataset_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "print(f\"üìÅ Run name: {run_name_dataset}\")\n",
    "print(f\"üìä Dataset size: {len(dataset)} samples\")\n",
    "print(f\"   Layer: {LAYER_SIGNATURE}\")\n",
    "print(f\"üì¶ Batch size: {BATCH_SIZE}\")\n",
    "print()\n",
    "\n",
    "run_name = lm.activations.save_activations_dataset(\n",
    "    dataset,\n",
    "    layer_signature=LAYER_SIGNATURE,\n",
    "    run_name=run_name_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    max_length=MAX_LENGTH,\n",
    "    autocast=False,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "print()\n",
    "print(f\"‚úÖ Activations saved!\")\n",
    "print(f\"üìÅ Run name: {run_name}\")\n",
    "print()\n",
    "\n",
    "batches = lm.store.list_run_batches(run_name)\n",
    "print(f\"üì¶ Saved {len(batches)} batches to store\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Verifying saved activations from save_activations_dataset()...\n",
      "\n",
      "üìä Batch 0 structure:\n",
      "   Layers with data: ['llamaforcausallm_model_layers_0_self_attn']\n",
      "\n",
      "‚úÖ Activations found:\n",
      "   Shape: torch.Size([4, 128, 1536])\n",
      "   Dtype: torch.float32\n",
      "   Device: cpu\n",
      "\n",
      "‚úÖ Run metadata found:\n",
      "   Model: LlamaForCausalLM\n",
      "   Layer signatures: ['llamaforcausallm_model_layers_0_self_attn']\n",
      "   Batch size: 4\n",
      "   Dataset length: 10\n",
      "\n",
      "üìä All batches summary:\n",
      "   Batch 0: activations shape torch.Size([4, 128, 1536])\n",
      "   Batch 1: activations shape torch.Size([4, 128, 1536])\n",
      "   Batch 2: activations shape torch.Size([2, 128, 1536])\n"
     ]
    }
   ],
   "source": [
    "# Step 7: Verify saved activations from save_activations_dataset()\n",
    "print(\"üîç Verifying saved activations from save_activations_dataset()...\")\n",
    "print()\n",
    "\n",
    "if len(batches) > 0:\n",
    "    batch_idx = 0\n",
    "    retrieved_metadata, retrieved_tensors = lm.store.get_detector_metadata(run_name, batch_idx)\n",
    "    \n",
    "    print(f\"üìä Batch {batch_idx} structure:\")\n",
    "    print(f\"   Layers with data: {list(retrieved_tensors.keys())}\")\n",
    "    print()\n",
    "    \n",
    "    if str(LAYER_SIGNATURE) in retrieved_tensors:\n",
    "        activations = retrieved_tensors[str(LAYER_SIGNATURE)].get(\"activations\")\n",
    "        if activations is not None:\n",
    "            print(f\"‚úÖ Activations found:\")\n",
    "            print(f\"   Shape: {activations.shape}\")\n",
    "            print(f\"   Dtype: {activations.dtype}\")\n",
    "            print(f\"   Device: {activations.device}\")\n",
    "        else:\n",
    "            print(\"‚ùå Activations not found\")\n",
    "    else:\n",
    "        print(f\"‚ùå Layer {LAYER_SIGNATURE} not found in saved data\")\n",
    "    \n",
    "    run_metadata = lm.store.get_run_metadata(run_name)\n",
    "    if run_metadata:\n",
    "        print()\n",
    "        print(f\"‚úÖ Run metadata found:\")\n",
    "        print(f\"   Model: {run_metadata.get('model', 'N/A')}\")\n",
    "        print(f\"   Layer signatures: {run_metadata.get('layer_signatures', 'N/A')}\")\n",
    "        print(f\"   Batch size: {run_metadata.get('options', {}).get('batch_size', 'N/A')}\")\n",
    "        print(f\"   Dataset length: {run_metadata.get('dataset', {}).get('length', 'N/A')}\")\n",
    "    \n",
    "    print()\n",
    "    print(f\"üìä All batches summary:\")\n",
    "    for i in range(min(3, len(batches))):\n",
    "        meta, tensors = lm.store.get_detector_metadata(run_name, i)\n",
    "        acts = tensors.get(str(LAYER_SIGNATURE), {}).get(\"activations\", None)\n",
    "        if acts is not None:\n",
    "            print(f\"   Batch {i}: activations shape {acts.shape}\")\n",
    "else:\n",
    "    print(\"‚ùå No batches found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Comparison of both modes\n",
      "============================================================\n",
      "\n",
      "Mode 1: save_activations() - for list of texts\n",
      "   Run name: activations_texts_20251209_220726\n",
      "   Batches saved: 2\n",
      "   Activations shape (batch 0): torch.Size([3, 128, 1536])\n",
      "\n",
      "Mode 2: save_activations_dataset() - for dataset\n",
      "   Run name: activations_dataset_20251209_220729\n",
      "   Batches saved: 3\n",
      "   Activations shape (batch 0): torch.Size([4, 128, 1536])\n",
      "\n",
      "‚úÖ Both modes work correctly and save activations in the same format!\n"
     ]
    }
   ],
   "source": [
    "# Step 8: Compare both modes\n",
    "print(\"üìä Comparison of both modes\")\n",
    "print(\"=\" * 60)\n",
    "print()\n",
    "\n",
    "print(\"Mode 1: save_activations() - for list of texts\")\n",
    "print(f\"   Run name: {run_name_texts}\")\n",
    "batches_texts = lm.store.list_run_batches(run_name_texts)\n",
    "print(f\"   Batches saved: {len(batches_texts)}\")\n",
    "if len(batches_texts) > 0:\n",
    "    meta_texts, tensors_texts = lm.store.get_detector_metadata(run_name_texts, 0)\n",
    "    acts_texts = tensors_texts.get(str(LAYER_SIGNATURE), {}).get(\"activations\", None)\n",
    "    if acts_texts is not None:\n",
    "        print(f\"   Activations shape (batch 0): {acts_texts.shape}\")\n",
    "print()\n",
    "\n",
    "print(\"Mode 2: save_activations_dataset() - for dataset\")\n",
    "print(f\"   Run name: {run_name_dataset}\")\n",
    "batches_dataset = lm.store.list_run_batches(run_name_dataset)\n",
    "print(f\"   Batches saved: {len(batches_dataset)}\")\n",
    "if len(batches_dataset) > 0:\n",
    "    meta_dataset, tensors_dataset = lm.store.get_detector_metadata(run_name_dataset, 0)\n",
    "    acts_dataset = tensors_dataset.get(str(LAYER_SIGNATURE), {}).get(\"activations\", None)\n",
    "    if acts_dataset is not None:\n",
    "        print(f\"   Activations shape (batch 0): {acts_dataset.shape}\")\n",
    "print()\n",
    "\n",
    "print(\"‚úÖ Both modes work correctly and save activations in the same format!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This example demonstrated:\n",
    "\n",
    "1. ‚úÖ **Loading Bielik model** - Successfully loaded from HuggingFace\n",
    "2. ‚úÖ **Mode 1: save_activations()** - Save activations from list of texts\n",
    "3. ‚úÖ **Mode 2: save_activations_dataset()** - Save activations from dataset\n",
    "4. ‚úÖ **Verification** - Confirmed activations saved correctly in both modes\n",
    "\n",
    "**Key Benefits:**\n",
    "- `save_activations()` - Simple activation saving for text lists with automatic detector management\n",
    "- `save_activations_dataset()` - Efficient batch processing of datasets with activation saving\n",
    "- Both methods automatically attach and cleanup detectors\n",
    "- Both methods save metadata consistently\n",
    "- Activations are saved in the same format regardless of input source\n",
    "\n",
    "**Conclusion:** ‚úÖ The activations API provides convenient methods for saving activations from both texts and datasets!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
